{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "076e2003",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pywt\n",
    "from scipy.signal import butter, filtfilt, find_peaks, peak_prominences\n",
    "from typing import Tuple\n",
    "\n",
    "from truth import IeeeGroundTruth\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = [18, 6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f8f818",
   "metadata": {},
   "outputs": [],
   "source": [
    "peak_height = 0.25\n",
    "CHROM_SETTINGS = {\n",
    "    'fr': 30,  # frame rate\n",
    "    'freq': (0.67, 3.0),  # bandpass frequency range\n",
    "    'bandpass_order': 4,  # bandpass filter order\n",
    "    'moving_avg_window': 6,  # moving average window size for smoothing\n",
    "    'peak_height': peak_height,  # min peak height for peak detection\n",
    "    'slice_filter_thresh': 2,  # min number of peaks allowed in a slice of the signal\n",
    "    'stringent_perc': 85,  # more stringent percentile for peak filtering\n",
    "    'non_stringent_perc': 75,  # less stringent percentile for peak filtering,\n",
    "    'prominence': 0.15\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ecbc261",
   "metadata": {},
   "source": [
    "## 0. Load raw RGB data and align it with its corresponding ground truth BVP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "296c093e",
   "metadata": {},
   "outputs": [],
   "source": [
    "truth = IeeeGroundTruth(5, 1, directory = 'channel_data3')\n",
    "truth.align_rgb_bvp()\n",
    "\n",
    "# define sample signal interval of interest\n",
    "interval = 15 * truth.rgb_freq  # 20s times the frame rate from the video\n",
    "first_frame = 3500\n",
    "rgb = truth.rgb[first_frame: first_frame + interval]\n",
    "# bvp has a higher sample rate so need to convert the rgb frames to the corresponding samples\n",
    "bvp = truth.bvp[truth.align_indices(first_frame): truth.align_indices(first_frame + interval)]\n",
    "\n",
    "plt.plot(bvp)\n",
    "plt.title('Ground Truth BVP')\n",
    "\n",
    "print('BVP Length:', len(bvp))\n",
    "print('RGB Length:', len(rgb))\n",
    "print('Length Ratio:', round(len(bvp) / len(rgb), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3e0568b",
   "metadata": {},
   "source": [
    "## 1. Signal Processing Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d126b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bandpass(signal: np.ndarray, fr: int, freq: Tuple[float, float], order: int):\n",
    "    \"\"\"\n",
    "    Apply bandpass filter to the given signal.\n",
    "\n",
    "    fr - frame rate\n",
    "    freq - tuple of low and high frequencies for the bandpass filter\n",
    "    order - order of the bandpass filter\n",
    "    \"\"\"\n",
    "\n",
    "    # nyquist frequency stays hardcoded at half the frame rate\n",
    "    nyquist_freq = 0.5 * fr\n",
    "    \n",
    "    # low and high values for butter created using nyquist\n",
    "    low = freq[0] / nyquist_freq\n",
    "    high = freq[1] / nyquist_freq\n",
    "    \n",
    "    # apply the filter\n",
    "    b, a = butter(order, [low, high], btype = 'band')\n",
    "    filtered = filtfilt(b, a, signal)\n",
    "    return filtered\n",
    "\n",
    "def detrend_w_poly(signal: np.ndarray, degree: int = 3):\n",
    "    \"\"\"\n",
    "    Detrend signal using nth degree polynomial.\n",
    "    \"\"\"\n",
    "\n",
    "    siglen = len(signal)\n",
    "    x = np.arange(siglen)\n",
    "    poly = np.polyfit(x, signal, degree)\n",
    "    curve = np.poly1d(poly)(x)\n",
    "    return signal - curve\n",
    "\n",
    "def normalize_signal(signal: np.ndarray):\n",
    "    \"\"\"\n",
    "    Normalize the given signal using mean and std.\n",
    "    \"\"\"\n",
    "\n",
    "    mn = np.mean(signal)\n",
    "    std = np.std(signal)\n",
    "    return (signal - mn) / std\n",
    "\n",
    "def n_moving_avg(signal: np.ndarray, window: int = 5):\n",
    "    \"\"\"\n",
    "    Simple moving window smoothing for a given signal.\n",
    "    \"\"\"\n",
    "\n",
    "    result = []\n",
    "    for i in range(len(signal) - (window - 1)):\n",
    "        result.append(\n",
    "            float(sum(signal[i: i + window])) / window\n",
    "        )\n",
    "    \n",
    "    return np.array(result)\n",
    "\n",
    "def normalize_amplitude_to_1(signal: np.ndarray):\n",
    "    \"\"\"\n",
    "    Normalize amplitude of given signal to 1.\n",
    "    \"\"\"\n",
    "    \n",
    "    # skip any None values at the beggining of the signal\n",
    "    first_index = None\n",
    "    for i in range(len(signal)):\n",
    "        if signal[i] is not None:\n",
    "            first_index = i\n",
    "            break\n",
    "    \n",
    "    first_part = list(signal[0: first_index])\n",
    "    signal = signal[first_index: ]\n",
    "\n",
    "    sigmax = abs(max(signal))\n",
    "    sigmin = abs(min(signal))\n",
    "    \n",
    "    return np.array(first_part + [\n",
    "        v / sigmax if v > 0 else v / sigmin\n",
    "        for v in signal\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f5a45e",
   "metadata": {},
   "source": [
    "## 2. Translate raw RGB data into rPPG signal, using chrominance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e3544c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chrominance(sig: str or np.array, settings: dict = CHROM_SETTINGS, \n",
    "                bounds: Tuple[int, int] = (0, -1), plot: bool = False):\n",
    "    \"\"\"\"\n",
    "    Apply the chrominance method to raw RGB data to extract and return\n",
    "    a raw rPPG signal.\n",
    "    \n",
    "    Taken from \"Robust Pulse Rate From Chrominance-Based rPPG\" by de Haan and Jeanne\n",
    "    \"\"\"\n",
    "\n",
    "    # make sure settings contain necessary info\n",
    "    for key in CHROM_SETTINGS:\n",
    "        if key not in settings:\n",
    "            raise ValueError(f'Settings must contain value for key {key}.')\n",
    "\n",
    "    # get raw RGB signals\n",
    "    if isinstance(sig, str):\n",
    "        r, g, b = _get_rgb_signals(sig, bounds)\n",
    "    else:\n",
    "        r = sig[:, 0]\n",
    "        g = sig[:, 1]\n",
    "        b = sig[:, 2]\n",
    "    if plot:\n",
    "        _plot_signals({'r': r, 'g': g, 'b': b}, 'Raw RGB Signals')\n",
    "    \n",
    "    # apply generic detrending and normalization to the raw signals\n",
    "    r = detrend_w_poly(r)\n",
    "    g = detrend_w_poly(g)\n",
    "    b = detrend_w_poly(b)\n",
    "    r = normalize_signal(r)\n",
    "    g = normalize_signal(g)\n",
    "    b = normalize_signal(b)\n",
    "    if plot:\n",
    "        _plot_signals({'r': r, 'g': g, 'b': b}, 'Detrended and Normalized RGB Signals')\n",
    "\n",
    "    # normalize skin tones\n",
    "    def _tonenorm(v):\n",
    "        return v / np.sqrt(pow(r, 2) + pow(g, 2) + pow(b, 2))\n",
    "    r_n, g_n, b_n = _tonenorm(r), _tonenorm(g), _tonenorm(b)\n",
    "    if plot:\n",
    "        _plot_signals({'r_n': r_n, 'g_n': g_n, 'b_n': b_n}, 'Normalized RGB Signals')\n",
    "\n",
    "    # combine the terms\n",
    "    xs = 3*r_n - 2*g_n\n",
    "    ys = 1.5*r_n - g_n - 1.5*b_n\n",
    "    \n",
    "    # apply bandpass filter to each signal\n",
    "    xf = bandpass(xs, settings['fr'], settings['freq'], settings['bandpass_order'])\n",
    "    yf = bandpass(ys, settings['fr'], settings['freq'], settings['bandpass_order'])\n",
    "    rf = bandpass(r_n, settings['fr'], settings['freq'], settings['bandpass_order'])\n",
    "    gf = bandpass(g_n, settings['fr'], settings['freq'], settings['bandpass_order'])\n",
    "    bf = bandpass(b_n, settings['fr'], settings['freq'], settings['bandpass_order'])\n",
    "\n",
    "    # apply final transformation from the paper\n",
    "    alpha = np.std(xf) / np.std(yf)\n",
    "    signal = (3 * (1 - alpha / 2) * rf) - 2 * (1 + alpha / 2) * gf + ((3 * alpha / 2) * bf)\n",
    "\n",
    "    return signal\n",
    "\n",
    "def _plot_signals(signals: dict, title: str):\n",
    "    \"\"\"\"\n",
    "    Plot the signals in a dictionary.\n",
    "    \"\"\"\n",
    "\n",
    "    for key in signals:\n",
    "        plt.plot(signals[key], label = key)\n",
    "    \n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8285e2b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "signal = chrominance(rgb, plot = True)\n",
    "plt.plot(signal)\n",
    "plt.title('Raw rPPG Signal')\n",
    "\n",
    "print('rPPG Signal Length:', len(signal))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd69cdb3",
   "metadata": {},
   "source": [
    "## 3. (Optional) Apply Wavelet filter to the signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae902c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_wavelet(signal, wave='db2', level=1, cutoff_low=0.7, cutoff_high=3.0, fs=30):\n",
    "    \"\"\"\n",
    "    Given a signal, apply wavelet transform to it and return a\n",
    "    resulting signal.\n",
    "    \"\"\"\n",
    "\n",
    "    # apply the wavelet transform, repeatedly according the the number of levels given\n",
    "    filtered_signal = _wavelet_denoise(signal, wave, level)\n",
    "\n",
    "    # interpolate the filtered signal to match the length of the original signal\n",
    "    x_old = np.linspace(0, 1, len(filtered_signal))\n",
    "    x_new = np.linspace(0, 1, len(signal))\n",
    "    filtered_signal = np.interp(x_new, x_old, filtered_signal)\n",
    "\n",
    "    # filter the interpolated signal to the desired frequency range\n",
    "    b, a = _butter_bandpass(cutoff_low, cutoff_high, fs)\n",
    "    filtered_signal = _filter_signal(filtered_signal, b, a)\n",
    "\n",
    "    return filtered_signal\n",
    "\n",
    "\n",
    "def _wavelet_denoise(signal, wavelet, level):\n",
    "    \n",
    "    # track signal at the end of each level\n",
    "    vs = []\n",
    "    sig = signal.copy()\n",
    "    for _ in range(level):\n",
    "        sig, cD = pywt.dwt(sig, wavelet)\n",
    "        vs.append(sig)\n",
    "\n",
    "    return vs[-1]\n",
    "\n",
    "\n",
    "def _filter_signal(signal, b, a):\n",
    "    \"\"\"\n",
    "    Filter a signal using a Butterworth filter with the given\n",
    "    coefficients b and a.\n",
    "    \"\"\"\n",
    "    filtered_signal = signal.copy()\n",
    "    if len(b) == len(a) == 1:\n",
    "        # if both b and a are of length 1, the filter is just a scalar multiplier\n",
    "        filtered_signal = b * signal\n",
    "    else:\n",
    "        # apply the filter\n",
    "        filtered_signal = filtfilt(b, a, signal)\n",
    "    return filtered_signal\n",
    "\n",
    "\n",
    "def _butter_bandpass(lowcut, highcut, fs, order=2):\n",
    "    \"\"\"\n",
    "    Create a Butterworth bandpass filter with the given parameters.\n",
    "    \"\"\"\n",
    "    nyq = 0.5 * fs\n",
    "    low = lowcut / nyq\n",
    "    high = highcut / nyq\n",
    "    b, a = butter(order, [low, high], btype='band')\n",
    "    return b, a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b8082b",
   "metadata": {},
   "outputs": [],
   "source": [
    "orig = signal.copy()\n",
    "signal = apply_wavelet(signal, wave = 'db2', level = 1)\n",
    "print('New Signal Length:', len(signal))\n",
    "plt.plot(orig, label = 'Original Signal')\n",
    "plt.plot(signal, label = 'Signal w/ Wavelet Applied')\n",
    "plt.legend()\n",
    "plt.title('Signal post-wavelet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43ab5c2f",
   "metadata": {},
   "source": [
    "## 4. Normalize amplitude to 1 to simplify later processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db2d7a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "signal = normalize_amplitude_to_1(signal)\n",
    "print('New Signal Length:', len(signal))\n",
    "plt.title('Signal with amplitude of 1')\n",
    "plt.plot(signal)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7900cf68",
   "metadata": {},
   "source": [
    "## 5. Apply n-moving average to the signal, and to the bvp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a8ec98",
   "metadata": {},
   "outputs": [],
   "source": [
    "window = CHROM_SETTINGS['moving_avg_window']\n",
    "window = 5\n",
    "\n",
    "# apply the moving average filter\n",
    "orig = signal.copy()\n",
    "signal = n_moving_avg(signal, window)\n",
    "\n",
    "# add empty elements to the beginning of the array to maintain proper\n",
    "# positioning of the elements\n",
    "signal = [None]*((window - 1) // 2) + list(signal)\n",
    "print('Length of signal:', len(signal))\n",
    "signal = np.array(signal)\n",
    "\n",
    "plt.plot(orig)\n",
    "plt.plot(signal)\n",
    "plt.title(f'Signal post moving average of {window}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d7bb6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "bvp_window = 15\n",
    "\n",
    "# apply the moving average filter\n",
    "orig = bvp.copy()\n",
    "bvp = n_moving_avg(bvp, bvp_window)\n",
    "\n",
    "# add empty elements to the beginning of the array to maintain proper\n",
    "# positioning of the elements\n",
    "bvp = [None]*((bvp_window - 1) // 2) + list(bvp)\n",
    "print('Length of BVP:', len(bvp))\n",
    "bvp = np.array(bvp)\n",
    "\n",
    "plt.plot(orig)\n",
    "plt.plot(bvp)\n",
    "plt.title(f'BVP post moving average of {bvp_window}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a84f8ac",
   "metadata": {},
   "source": [
    "## 6. Get peaks from smoothed rPPG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e81e786",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_peaks(signal: np.ndarray, fr: int, max_freq: float, peak_height: float,\n",
    "    slice_filter_thresh: int, perc1: float, perc2: float, prominence: float or None = None,\n",
    "    with_min_dist: bool = True, with_additional_filtering: bool = True):\n",
    "    \"\"\"\n",
    "    The current standard method for peak detection. Includes the option to use the _filter_peaks\n",
    "    method for even more aggressive filtering.\n",
    "    \"\"\"\n",
    "    \n",
    "    # skip any None values at the beggining of the signal\n",
    "    first_index = None\n",
    "    for i in range(len(signal)):\n",
    "        if signal[i] is not None:\n",
    "            first_index = i\n",
    "            break\n",
    "    signal = signal[first_index: ]\n",
    "    \n",
    "    # apply a min distance if its given, otherwise just make it 1\n",
    "    if with_min_dist:\n",
    "        min_dist = fr // max_freq\n",
    "    else:\n",
    "        min_dist = 1\n",
    "    \n",
    "    # if prominence is None, make it 0\n",
    "    if prominence is None:\n",
    "        prominence = 0\n",
    "    \n",
    "    peaks, _ = find_peaks(signal, height = peak_height, prominence = prominence, distance = min_dist)\n",
    "\n",
    "    if with_additional_filtering:\n",
    "        peaks = _filter_peaks(signal, peaks, fr, slice_filter_thresh, perc1, perc2)\n",
    "    \n",
    "    prominences = {p + first_index: prom for p, prom in zip(peaks, peak_prominences(signal, peaks)[0])}\n",
    "    return [p + first_index for p in peaks], prominences\n",
    "\n",
    "\n",
    "def _filter_peaks(signal: np.ndarray, peaks: np.ndarray, fr: int,\n",
    "    slice_filter_thresh: int, perc1: float, perc2: float):\n",
    "    \"\"\"\n",
    "    Filter peaks with the intent of trying to peaks that are \"definitely\" noise.\n",
    "    \"\"\"\n",
    "\n",
    "    # first, remove peaks that aren't sufficienrtly above the perc2 percentile. I intentionally\n",
    "    # am comparing the peaks to the entire array, and not just the set of peaks, because I'm not\n",
    "    # making the assumption that a certain percentage of peaks will inherently be noisy. However,\n",
    "    # I am making the assumption that if the peak is insufficiently clear of a certain baseline of\n",
    "    # the entire signal, then it must be noise.\n",
    "    peaks = np.array([p for p in peaks if signal[p] >= np.percentile(signal, perc2)])   \n",
    "    \n",
    "    # Peak Walk: remove peaks that are close together, that aren't sufficiently large relative to the\n",
    "    # entire signal. This percentile (perc1) is more stringent than the one used in the first step.\n",
    "    for i in range(0, len(signal) - fr, fr):\n",
    "        \n",
    "        j = i + fr\n",
    "        slce = peaks[(peaks >= i) & (peaks < j)]\n",
    "        \n",
    "        if len(slce) > slice_filter_thresh:\n",
    "            to_remove = [i for i in range(len(slce)) if signal[slce[i]] < np.percentile(signal[slce], perc1)]\n",
    "            peaks = peaks[~np.isin(peaks, [slce[i] for i in to_remove])]\n",
    "            # removed += len(to_remove)\n",
    "    \n",
    "    return peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9269d68f",
   "metadata": {},
   "outputs": [],
   "source": [
    "peaks, peak_proms = get_peaks(\n",
    "        signal,\n",
    "        CHROM_SETTINGS['fr'],\n",
    "        CHROM_SETTINGS['freq'][1],\n",
    "#         CHROM_SETTINGS['peak_height'],\n",
    "        -1,\n",
    "        CHROM_SETTINGS['slice_filter_thresh'],\n",
    "        CHROM_SETTINGS['stringent_perc'],\n",
    "        CHROM_SETTINGS['non_stringent_perc'],\n",
    "        with_min_dist = True,\n",
    "        with_additional_filtering = False,\n",
    "        prominence = CHROM_SETTINGS['prominence']\n",
    ")\n",
    "\n",
    "print('Len Signal:', len(signal))\n",
    "plt.plot(signal)\n",
    "plt.scatter([p for p in peaks], [signal[p] for p in peaks], marker='x', color='r')\n",
    "plt.title('Detected peaks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce8ca96a",
   "metadata": {},
   "outputs": [],
   "source": [
    "signal_neg = [None if v is None else -v for v in signal]\n",
    "valleys, valley_proms = get_peaks(\n",
    "        signal_neg,\n",
    "        CHROM_SETTINGS['fr'],\n",
    "        CHROM_SETTINGS['freq'][1],\n",
    "#         CHROM_SETTINGS['peak_height'],\n",
    "        -1,\n",
    "        CHROM_SETTINGS['slice_filter_thresh'],\n",
    "        CHROM_SETTINGS['stringent_perc'],\n",
    "        CHROM_SETTINGS['non_stringent_perc'],\n",
    "        with_min_dist = True,\n",
    "        with_additional_filtering = False,\n",
    "        prominence = CHROM_SETTINGS['prominence']\n",
    ")\n",
    "\n",
    "print('Len Signal:', len(signal))\n",
    "plt.plot(signal_neg)\n",
    "plt.scatter([v for v in valleys], [signal_neg[v] for v in valleys], marker='x', color='r')\n",
    "plt.title('Detected Valleys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23fdbe6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine peaks and valleys\n",
    "peaks_valleys_comb = sorted(\n",
    "    [(p, 'p') for p in peaks] + [(v, 'v') for v in valleys],\n",
    "    key = lambda t: t[0]\n",
    ")\n",
    "\n",
    "\n",
    "def valley_filler(pv, fr, max_freq, peak_proms, valley_proms, prominence_threshold = 0.3):\n",
    "\n",
    "    min_dist = 0.75 * (fr // max_freq)\n",
    "\n",
    "    peaks = []\n",
    "    i = 0\n",
    "    while i < len(pv):\n",
    "\n",
    "        # case where we are at the last peak in the sequence\n",
    "        if i == len(pv) - 1:\n",
    "            if pv[i][1] == 'p':\n",
    "                peaks.append(pv[i][0])\n",
    "                break\n",
    "            elif pv[i][1] == 'v' and valley_proms[pv[i][0]] >= prominence_threshold:\n",
    "                peaks.append(pv[i][0])\n",
    "                break\n",
    "    \n",
    "        # case where the peak is a valley and the valley meets the prominence threshold\n",
    "        if pv[i][1] == 'v' and valley_proms[pv[i][0]] >= prominence_threshold:\n",
    "            peaks.append(pv[i][0])\n",
    "            i += 1\n",
    "            continue\n",
    "        \n",
    "        # case where the next peak is a peak (and not a valley), and thus no comparison needs to be done\n",
    "        if pv[i + 1][1] == 'p':\n",
    "            peaks.append(pv[i][0])\n",
    "            i += 1\n",
    "            continue\n",
    "\n",
    "        # case where the next peak is a valley, and thus a comparison needs to be done\n",
    "        else:\n",
    "            if valley_proms[pv[i + 1][0]] >= prominence_threshold:\n",
    "\n",
    "                if pv[i + 1][0] - pv[i][0] >= min_dist:\n",
    "                    \n",
    "                    peaks.append(pv[i][0])\n",
    "                    peaks.append(pv[i + 1][0])\n",
    "                    i += 2\n",
    "                    continue\n",
    "                \n",
    "                else:\n",
    "                    \n",
    "                    if peak_proms[pv[i][0]] > valley_proms[pv[i + 1][0]]:\n",
    "                        peaks.append(pv[i][0])\n",
    "                        i += 2\n",
    "                        continue\n",
    "                    else:\n",
    "                        peaks.append(pv[i + 1][0])\n",
    "                        i += 2\n",
    "                        continue\n",
    "            \n",
    "            else:\n",
    "                peaks.append(pv[i][0])\n",
    "                i += 2\n",
    "                continue\n",
    "            \n",
    "    return peaks\n",
    "\n",
    "\n",
    "peaks_enhanced = valley_filler(\n",
    "    peaks_valleys_comb,\n",
    "    CHROM_SETTINGS['fr'],\n",
    "    CHROM_SETTINGS['freq'][1],\n",
    "    peak_proms,\n",
    "    valley_proms,\n",
    "    prominence_threshold = 0.6\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3897704b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bvp_index = np.array(list(range(len(bvp)))) / 64\n",
    "signal_index = np.array(list(range(len(signal)))) / 30\n",
    "adjusted_peaks = [p / 30 for p in peaks]\n",
    "adjusted_valleys = [[v / 30 for v in valleys]]\n",
    "\n",
    "bvp = normalize_amplitude_to_1(bvp)\n",
    "signal = normalize_amplitude_to_1(signal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "babcbb9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Lengths:', f'BVP {len(bvp)}', f'rPPG {len(signal)}')\n",
    "plt.plot(bvp_index, bvp, label = 'Ground Truth')\n",
    "plt.plot(signal_index, signal, label = 'rPPG')\n",
    "plt.plot(signal_index, [0 for _ in range(len(signal_index))])\n",
    "plt.scatter(adjusted_peaks, [signal[p] for p in peaks], color = 'red', marker = 'x')\n",
    "plt.scatter(adjusted_valleys, [signal[v] for v in valleys], color = 'red', marker = 'o')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a33d1549",
   "metadata": {},
   "source": [
    "## 7. Get peaks for ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46cb19cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_peaks, _ = get_peaks(\n",
    "        bvp,\n",
    "        CHROM_SETTINGS['fr'],\n",
    "        CHROM_SETTINGS['freq'][1],\n",
    "        0,\n",
    "        CHROM_SETTINGS['slice_filter_thresh'],\n",
    "        CHROM_SETTINGS['stringent_perc'],\n",
    "        CHROM_SETTINGS['non_stringent_perc'],\n",
    "        with_min_dist = False,\n",
    "        with_additional_filtering = False\n",
    ")\n",
    "\n",
    "proms = peak_prominences(bvp, true_peaks)[0]\n",
    "true_peaks = [true_peaks[i] for i in range(len(true_peaks)) if proms[i] >= 0.6]\n",
    "\n",
    "print('Len BVP:', len(bvp))\n",
    "plt.plot(bvp)\n",
    "plt.scatter([p for p in true_peaks], [bvp[p] for p in true_peaks], marker = 'x', color = 'r')\n",
    "plt.title('Detected peaks')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "548e585e",
   "metadata": {},
   "source": [
    "# Calculate and compare the HR estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a2b5011",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ibis(peaks, fr = 30, with_valleys = False):\n",
    "    ibis = []\n",
    "    for i in range(1, len(peaks)):\n",
    "\n",
    "        if with_valleys:\n",
    "            peak_diff = peaks[i][0] - peaks[i - 1][0]\n",
    "        else: \n",
    "            peak_diff = peaks[i] - peaks[i - 1]\n",
    "        \n",
    "        ibi = peak_diff / fr\n",
    "\n",
    "        if with_valleys and peaks[i][1] != peaks[i - 1][1]:\n",
    "            ibi *= 2\n",
    "        \n",
    "        ibis.append(ibi)\n",
    "\n",
    "    return ibis\n",
    "\n",
    "def get_hr(ibis):\n",
    "    return 60 / np.mean(ibis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e9eb4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Num true peaks:', len(true_peaks))\n",
    "print('Num estimated peaks:', len(peaks))\n",
    "print('Num valleys', len(valleys))\n",
    "print('Num peaks enhanced with valleys', len(peaks_enhanced))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0aabc88",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_ibis = get_ibis(true_peaks, fr = 64)\n",
    "peak_ibis = get_ibis(peaks, fr = 30)\n",
    "valley_ibis = get_ibis(valleys, fr = 30)\n",
    "ibis_peaks_valleys_comb = get_ibis(peaks_valleys_comb, CHROM_SETTINGS['fr'], with_valleys = True)\n",
    "ibis_peaks_enhanced = get_ibis(peaks_enhanced, CHROM_SETTINGS['fr'])\n",
    "\n",
    "\n",
    "print('Ground Truth Heart Rate:', get_hr(true_ibis))\n",
    "print('Estimated Heart Rate from Peaks:', get_hr(peak_ibis))\n",
    "print('Estimated Heart Rate from Valleys:', get_hr(valley_ibis))\n",
    "print('Estimated Heart Rate from Peaks/Valleys Combined', get_hr(ibis_peaks_valleys_comb))\n",
    "print('Estimated Heart Rate from Peaks enhanced with Valleys', get_hr(ibis_peaks_enhanced))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
