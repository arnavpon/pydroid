{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "from datetime import datetime\n",
    "from joblib import Parallel, delayed\n",
    "import lightgbm as lgb\n",
    "from lightgbm.callback import early_stopping, log_evaluation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from scipy.signal import resample\n",
    "from sdtw import SoftDTW\n",
    "from sdtw.distance import SquaredEuclidean\n",
    "\n",
    "from skopt import gp_minimize\n",
    "from skopt.space import Real, Integer\n",
    "from skopt.utils import use_named_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = [18, 6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext memory_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from truth import IeeeGroundTruth\n",
    "from wavelet import apply_wavelet\n",
    "from peaks import get_peaks_v2\n",
    "from signal_pross import (\n",
    "    normalize_signal,\n",
    "    detrend_w_poly,\n",
    "    normalize_amplitude_to_1,\n",
    "    n_moving_avg,\n",
    "    min_max_scale,\n",
    "    bandpass,\n",
    "    get_hr,\n",
    "    get_hrv\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LossFactory:\n",
    "\n",
    "    def __init__(self, split_size, loss_type = 'mse', gamma = 1.0, mse_weight = None, dtw_weight = None):\n",
    "        \n",
    "        if loss_type not in ['mse', 'dtw', 'combined']:\n",
    "            raise ValueError(f'Loss type [{loss_type}] not supported')\n",
    "        \n",
    "        self.split_size = split_size\n",
    "        self.gamma = gamma\n",
    "        self.mse_weight = mse_weight\n",
    "        self.dtw_weight = dtw_weight\n",
    "\n",
    "        if loss_type == 'mse':\n",
    "            self.loss_function = self.mse_loss\n",
    "        elif loss_type == 'dtw':\n",
    "            self.loss_function = self.soft_dtw_loss\n",
    "        elif loss_type == 'combined':\n",
    "            self.loss_function = self.combined_loss\n",
    "        \n",
    "    def __call__(self, y_pred, data):\n",
    "        return self.loss_function(y_pred, data)\n",
    "\n",
    "    def get_func(self):\n",
    "        return self.loss_function\n",
    "\n",
    "    def mse_loss(self, y_pred, data):\n",
    "        \n",
    "        y_true = data.get_label()\n",
    "        num_batches = int(len(y_pred) / self.split_size)\n",
    "        errs = np.zeros_like(y_true)\n",
    "\n",
    "        for i in range(num_batches):\n",
    "\n",
    "            y_true_curr = y_true[i * self.split_size: (i + 1) * self.split_size]\n",
    "            y_pred_curr = y_pred[i * self.split_size: (i + 1) * self.split_size]\n",
    "            \n",
    "            err = y_true_curr - y_pred_curr\n",
    "            errs[i * self.split_size: (i + 1) * self.split_size] = err\n",
    "\n",
    "        grad = -2 * errs\n",
    "        hess = 2 * np.ones_like(y_true)\n",
    "        return grad, hess\n",
    "\n",
    "    # def soft_dtw_loss(self, y_pred, data):\n",
    "\n",
    "    #     y_true = data.get_label()\n",
    "    #     num_batches = int(len(y_pred) / self.split_size)\n",
    "    #     grads = np.zeros_like(y_true)\n",
    "    #     hesses = np.zeros_like(y_true)\n",
    "\n",
    "    #     for i in range(num_batches):\n",
    "\n",
    "    #         y_true_curr = y_true[i * self.split_size: (i + 1) * self.split_size]\n",
    "    #         y_pred_curr = y_pred[i * self.split_size: (i + 1) * self.split_size]\n",
    "            \n",
    "    #         grad_curr, hess_curr = self.soft_dtw_loss_helper(y_true_curr, y_pred_curr)\n",
    "    #         grad_curr = grad_curr.flatten()\n",
    "    #         hess_curr = hess_curr.flatten()\n",
    "\n",
    "    #         grads[i * self.split_size: (i + 1) * self.split_size] = grad_curr\n",
    "    #         hesses[i * self.split_size: (i + 1) * self.split_size] = hess_curr\n",
    "\n",
    "    #     return grads, hesses\n",
    "    def soft_dtw_loss(self, y_pred, data):\n",
    "\n",
    "        def batch_loss_helper(i, y_true, y_pred, split_size):\n",
    "            \n",
    "            y_true_curr = y_true[i * split_size: (i + 1) * split_size]\n",
    "            y_pred_curr = y_pred[i * split_size: (i + 1) * split_size]\n",
    "\n",
    "            grad_curr, hess_curr = self.soft_dtw_loss_helper(y_true_curr, y_pred_curr)\n",
    "            grad_curr = grad_curr.flatten()\n",
    "            hess_curr = hess_curr.flatten()\n",
    "\n",
    "            return grad_curr, hess_curr\n",
    "\n",
    "        y_true = data.get_label()\n",
    "        num_batches = int(len(y_pred) / self.split_size)\n",
    "        grads = np.zeros_like(y_true)\n",
    "        hesses = np.zeros_like(y_true)\n",
    "\n",
    "        results = Parallel(n_jobs = -1)(\n",
    "            delayed(batch_loss_helper)(\n",
    "                i, y_true, y_pred, self.split_size\n",
    "            ) for i in range(num_batches)\n",
    "        )\n",
    "\n",
    "        for i, (grad_curr, hess_curr) in enumerate(results):\n",
    "            grads[i * self.split_size: (i + 1) * self.split_size] = grad_curr\n",
    "            hesses[i * self.split_size: (i + 1) * self.split_size] = hess_curr\n",
    "\n",
    "        return grads, hesses\n",
    "    \n",
    "    def soft_dtw_loss_helper(self, y_true, y_pred):\n",
    "        x = y_true.reshape(-1, 1)\n",
    "        y = y_pred.reshape(-1, 1)\n",
    "        D = SquaredEuclidean(x, y)\n",
    "        sdtw = SoftDTW(D, gamma = self.gamma)\n",
    "        sdtw.compute()\n",
    "        E = sdtw.grad()\n",
    "        G = D.jacobian_product(E)\n",
    "        return G, np.ones(len(G))\n",
    "    \n",
    "    def combined_loss(self, y_pred, data):\n",
    "\n",
    "        if self.mse_weight is None or self.dtw_weight is None:\n",
    "            raise ValueError('mse_weight and dtw_weight must be set before calling combined_loss')\n",
    "\n",
    "        mse_grads, mse_hesses = self.mse_loss(y_pred, data)\n",
    "        dtw_grads, dtw_hesses = self.soft_dtw_loss(y_pred, data)\n",
    "\n",
    "        combined_grad = self.mse_weight * mse_grads + self.dtw_weight * dtw_grads\n",
    "        combined_hess = self.mse_weight * mse_hesses + self.dtw_weight * dtw_hesses\n",
    "\n",
    "        return combined_grad, combined_hess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "class LonePineGBM:\n",
    "    \n",
    "    def __init__(self, truths, label_col = 'bvp', subject_col = 'subject',\n",
    "                # model customization\n",
    "                model_type = 'gbdt', random_state = None, loss_type = 'mse', excluded_subject = None,\n",
    "                # hyperparameters\n",
    "                n_estimators = 100, split_size = 1280, learning_rate = 0.1, test_size = 0.3, early_stopping_rounds = 50,\n",
    "                mse_weight = None, dtw_weight = None, data_beg = 1000, data_end = 10000, batches = 1, finetune = True,\n",
    "                min_bandpass_freq = 0.67, max_bandpass_freq = 3.0, bandpass_order = 4,\n",
    "                predicted_peaks_prominence = 0.22, true_peaks_prominence = 0.15,\n",
    "                # hyperparams from LightGBM docs\n",
    "                max_depth = 7, num_leaves = 75, max_bin = 255,\n",
    "                num_feats_per_channel = 3, skip_amount = 15):\n",
    "        \n",
    "        if model_type not in ['gbdt', 'rf']:\n",
    "            raise ValueError(f'Model type [{model_type}] not supported')\n",
    "        \n",
    "        self.label_col = label_col\n",
    "        self.subject_col = subject_col\n",
    "\n",
    "        self.model_type = model_type\n",
    "        self.random_state = random_state\n",
    "        self.excluded_subject = excluded_subject\n",
    "\n",
    "        self.n_estimators = n_estimators\n",
    "        self.split_size = split_size\n",
    "        self.learning_rate = learning_rate\n",
    "        self.test_size = test_size\n",
    "        self.early_stopping_rounds = early_stopping_rounds\n",
    "\n",
    "        self.data_beg = data_beg\n",
    "        self.data_end = data_end\n",
    "        self.finetune = finetune\n",
    "\n",
    "        self.min_bandpass_freq = min_bandpass_freq\n",
    "        self.max_bandpass_freq = max_bandpass_freq\n",
    "        self.bandpass_order = bandpass_order\n",
    "        self.predicted_peaks_prominence = predicted_peaks_prominence\n",
    "        self.true_peaks_prominence = true_peaks_prominence\n",
    "\n",
    "        self.max_depth = max_depth\n",
    "        self.num_leaves = num_leaves\n",
    "        self.max_bin = max_bin\n",
    "\n",
    "        self.num_feats_per_channel = num_feats_per_channel\n",
    "        self.skip_amount = skip_amount\n",
    "\n",
    "        self.gbm = None\n",
    "        self.training_loss = None\n",
    "        self.test_loss = None\n",
    "\n",
    "        self.given_data = self.prepare_dataset_from_subjects(truths, data_beg = data_beg, data_end = data_end)\n",
    "        self.features = list(self.given_data.drop(columns = [self.label_col, self.subject_col]).columns)\n",
    "        if self.excluded_subject is not None:\n",
    "            self.given_data = self.given_data[self.given_data[self.subject_col] != self.excluded_subject]\n",
    "\n",
    "        if self.random_state is not None:\n",
    "            random.seed(self.random_state)\n",
    "        splits = self.split_data()\n",
    "        self.train_split_indices = random.sample(range(len(splits)), int(len(splits) * (1 - self.test_size)))\n",
    "        self.train_splits = [splits[i] for i in self.train_split_indices]\n",
    "        self.test_splits = [splits[i] for i in range(len(splits)) if i not in self.train_split_indices]\n",
    "        \n",
    "        self.train_data = []\n",
    "        self.train_data_just_data = []\n",
    "        batch_size = len(self.train_splits) // batches\n",
    "        print(f'Rows per batch: {batch_size * self.split_size}')\n",
    "        for batch_num in range(batches):\n",
    "            batch_split_idxs = random.sample(range(len(self.train_splits)), batch_size)\n",
    "            batch_splits = [self.train_splits[i] for i in batch_split_idxs]\n",
    "            self.train_splits = [self.train_splits[i] for i in range(len(self.train_splits)) if i not in batch_split_idxs]\n",
    "\n",
    "            train_indices = [idx for split in batch_splits for idx in split]\n",
    "            training_rows = self.given_data.iloc[train_indices].drop(columns = [self.subject_col])\n",
    "            train_X = training_rows.drop(columns = [self.label_col]).to_numpy()\n",
    "            train_y = training_rows[self.label_col].to_numpy()\n",
    "\n",
    "            # batch_data = lgb.Dataset(train_X, train_y, free_raw_data = False)\n",
    "            batch_data = xgb.DMatrix(train_X, train_y)\n",
    "            self.train_data.append(batch_data)\n",
    "            self.train_data_just_data.append(train_X)\n",
    "\n",
    "        test_indices = [idx for split in self.test_splits for idx in split]\n",
    "        test_rows = self.given_data.iloc[test_indices].drop(columns = [self.subject_col])\n",
    "        test_X = test_rows.drop(columns = [self.label_col]).to_numpy()\n",
    "        test_y = test_rows[self.label_col].to_numpy()\n",
    "        # self.test_data = lgb.Dataset(test_X, test_y, free_raw_data = False)\n",
    "        self.test_data = xgb.DMatrix(test_X, test_y)\n",
    "        self.test_X = test_X\n",
    "        self.test_y = test_y\n",
    "\n",
    "        self.loss = LossFactory(self.split_size, loss_type = loss_type, mse_weight = mse_weight, dtw_weight = dtw_weight)\n",
    "    \n",
    "    def split_data(self, to_exclude = None):\n",
    "        \n",
    "        data_in_use = self.given_data if to_exclude is None else self.given_data[~self.given_data[self.subject_col].isin(to_exclude)]\n",
    "\n",
    "        subject_indices = data_in_use.groupby(self.subject_col).indices\n",
    "        splits = []\n",
    "        for _, indices in subject_indices.items():\n",
    "            \n",
    "            n_splits = len(indices) // self.split_size\n",
    "            if n_splits > 0:\n",
    "\n",
    "                subject_splits = []\n",
    "                for i in range(n_splits):\n",
    "                    split_start = i * self.split_size\n",
    "                    split_end = (i + 1) * self.split_size\n",
    "                    subject_split = indices[split_start: split_end]\n",
    "                    subject_splits.append(subject_split)\n",
    "                \n",
    "                splits.extend(subject_splits)\n",
    "        \n",
    "        return splits\n",
    "\n",
    "    def fit(self):\n",
    "        t1 = datetime.today()\n",
    "        \n",
    "        self.params = {\n",
    "            'metric': 'None',\n",
    "            'verbosity': -1,\n",
    "            'learning_rate': self.learning_rate,\n",
    "            'objective': 'regression',\n",
    "            'boosting': self.model_type,\n",
    "            'max_depth': self.max_depth,\n",
    "            'num_leaves': self.num_leaves,\n",
    "            'max_bin': self.max_bin,\n",
    "        }\n",
    "    \n",
    "        if self.model_type == 'rf':\n",
    "            self.params['bagging_freq'] = 1\n",
    "            self.params['bagging_fraction'] = 0.8\n",
    "\n",
    "\n",
    "        training_loss_key = 'hr_err'\n",
    "        feval = self.hr_error_eval_metric\n",
    "        print('loss is loss')\n",
    "        \n",
    "        training_meta = {}\n",
    "\n",
    "        for train_data in self.train_data:\n",
    "            \n",
    "            if self.model_type == 'gbdt':\n",
    "                self.gbm = lgb.train(\n",
    "                    self.params,\n",
    "                    train_data,\n",
    "                    valid_sets = [train_data, self.test_data],\n",
    "                    valid_names=['train', 'test'],\n",
    "                    fobj = self.loss,\n",
    "                    num_boost_round = self.n_estimators,\n",
    "                    feval=feval,\n",
    "                    callbacks=[\n",
    "                        early_stopping(stopping_rounds = self.early_stopping_rounds),\n",
    "                        log_evaluation(period=5)\n",
    "                    ],\n",
    "                    evals_result = training_meta,\n",
    "                    init_model = self.gbm\n",
    "                )\n",
    "            else:\n",
    "                self.gbm = lgb.train(\n",
    "                    self.params,\n",
    "                    train_data,\n",
    "                    valid_sets = [train_data, self.test_data],\n",
    "                    valid_names=['train', 'test'],\n",
    "                    num_boost_round = self.n_estimators,\n",
    "                    feval=feval,\n",
    "                    callbacks=[\n",
    "                        early_stopping(stopping_rounds = self.early_stopping_rounds),\n",
    "                        log_evaluation(period=5)\n",
    "                    ],\n",
    "                    evals_result = training_meta,\n",
    "                )\n",
    "\n",
    "            mse, hr_err, hr_err_sq = self.eval()\n",
    "            print(f'Before fine-tuning: MSE = {mse}, HR error = {hr_err}, HR error (squared) = {hr_err_sq}')\n",
    "\n",
    "            if self.model_type == 'gbdt' and self.finetune:\n",
    "                \n",
    "                print('\\n\\nFine-tuning...')\n",
    "                gbm_copy = copy.deepcopy(self.gbm)\n",
    "                pred = gbm_copy.predict(train_data.get_data())\n",
    "                \n",
    "                # new_targ = train_data.get_label() - pred\n",
    "                new_targ = np.ones(len(pred))\n",
    "                nsplits = len(pred) // self.split_size\n",
    "                labels = train_data.get_label()\n",
    "                for i in range(nsplits):\n",
    "                    pred_curr = pred[i * self.split_size: (i + 1) * self.split_size]\n",
    "                    label_curr = labels[i * self.split_size: (i + 1) * self.split_size]\n",
    "                    hr_err = self.get_hr_error(pred_curr, label_curr, square = True)\n",
    "                    new_targ[i * self.split_size: (i + 1) * self.split_size] = hr_err\n",
    "                \n",
    "                new_train_data = lgb.Dataset(train_data.get_data(), label = new_targ)\n",
    "\n",
    "                self.gbm = lgb.train(\n",
    "                    self.params,\n",
    "                    new_train_data,\n",
    "                    valid_sets = [new_train_data, self.test_data],\n",
    "                    valid_names=['train', 'test'],\n",
    "                    fobj = self.loss,\n",
    "                    num_boost_round = self.n_estimators // 2,\n",
    "                    feval=feval,\n",
    "                    callbacks=[\n",
    "                        early_stopping(stopping_rounds = self.early_stopping_rounds // 2),\n",
    "                        log_evaluation(period=5)\n",
    "                    ],\n",
    "                    evals_result = training_meta,\n",
    "                    init_model = gbm_copy\n",
    "                )\n",
    "\n",
    "            \n",
    "\n",
    "        self.training_loss = training_meta['train'][training_loss_key]\n",
    "        self.test_loss = training_meta['test'][training_loss_key]\n",
    "        print(f'Finished training in {datetime.today() - t1}')\n",
    "    \n",
    "    def fit_xgb(self):\n",
    "        t1 = datetime.today()\n",
    "\n",
    "        self.params = {\n",
    "            'learning_rate': self.learning_rate,\n",
    "            'booster': 'gbtree',\n",
    "            'max_depth': self.max_depth,\n",
    "            'num_leaves': self.num_leaves,\n",
    "            'max_bin': self.max_bin,\n",
    "        }\n",
    "\n",
    "        feval = self.hr_error_eval_metric_xgb\n",
    "\n",
    "        for train_data, train_data_just_data in zip(self.train_data, self.train_data_just_data):\n",
    "\n",
    "            self.gbm = xgb.train(\n",
    "                self.params,\n",
    "                train_data,\n",
    "                num_boost_round=self.n_estimators,\n",
    "                early_stopping_rounds=self.early_stopping_rounds,\n",
    "                feval=feval,\n",
    "                verbose_eval=5,\n",
    "                evals=[(train_data, 'train'), (self.test_data, 'test')],\n",
    "                xgb_model=self.gbm,\n",
    "                obj = self.loss.get_func()\n",
    "            )\n",
    "\n",
    "            # mse, hr_err, hr_err_sq = self.eval()\n",
    "            # print(f'Before fine-tuning: MSE = {mse}, HR error = {hr_err}, HR error (squared) = {hr_err_sq}')\n",
    "\n",
    "            if self.finetune:\n",
    "\n",
    "                print('\\n\\nFine-tuning...')\n",
    "                gbm_copy = self.gbm.copy()\n",
    "                pred = gbm_copy.predict(train_data)\n",
    "\n",
    "                new_targ = np.ones(len(pred))\n",
    "                nsplits = len(pred) // self.split_size\n",
    "                labels = train_data.get_label()\n",
    "                for i in range(nsplits):\n",
    "                    pred_curr = pred[i * self.split_size: (i + 1) * self.split_size]\n",
    "                    label_curr = labels[i * self.split_size: (i + 1) * self.split_size]\n",
    "                    new_targ[i * self.split_size: (i + 1) * self.split_size] = label_curr - pred_curr\n",
    "\n",
    "                new_train_data = xgb.DMatrix(train_data_just_data, label=new_targ)\n",
    "\n",
    "                self.gbm = xgb.train(\n",
    "                    self.params,\n",
    "                    new_train_data,\n",
    "                    num_boost_round=self.n_estimators // 2,\n",
    "                    early_stopping_rounds=self.early_stopping_rounds // 2,\n",
    "                    feval=feval,\n",
    "                    verbose_eval=5,\n",
    "                    evals=[(new_train_data, 'train'), (self.test_data, 'test')],\n",
    "                    xgb_model=gbm_copy,\n",
    "                    obj = self.loss.get_func()\n",
    "                )\n",
    "\n",
    "        print(f'Finished training in {datetime.today() - t1}')\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.gbm.predict(X)\n",
    "    \n",
    "    def save(self, model_file = 'lonePineGBM.xgb'):\n",
    "\n",
    "        # new_params = copy.deepcopy(self.params)\n",
    "        # new_params['learning_rate'] = 0.0000001\n",
    "        # new_gbm = lgb.train(self.params, self.train_data[0], num_boost_round=1, init_model = self.gbm)\n",
    "\n",
    "        # # import onnxmltools\n",
    "        # # from onnxconverter_common.data_types import FloatTensorType\n",
    "\n",
    "        # # initial_types = [('input', FloatTensorType([None, new_gbm.num_feature()]))]\n",
    "        # # onnx_model = onnxmltools.convert_lightgbm(new_gbm, initial_types=initial_types)\n",
    "        # # onnxmltools.utils.save_model(onnx_model, model_file)\n",
    "\n",
    "        # import onnxmltools\n",
    "        # from onnxconverter_common.data_types import FloatTensorType\n",
    "        # onnx_model = onnxmltools.convert_lightgbm(new_gbm, initial_types=[('input', FloatTensorType([None, new_gbm.num_feature()]))])\n",
    "\n",
    "        # # Save as protobuf\n",
    "        # onnxmltools.utils.save_model(onnx_model, model_file)\n",
    "\n",
    "        self.gbm.save_model(model_file)\n",
    "\n",
    "    \n",
    "    def load_from_file(self, model_file):\n",
    "        self.gbm = lgb.model_from_string(model_file)\n",
    "\n",
    "    def eval(self):\n",
    "        \n",
    "        test_X = self.test_data.get_data()\n",
    "        test_y = self.test_data.get_label()\n",
    "        nsplits = int(len(test_X) / self.split_size)\n",
    "        errs = []\n",
    "        mses = np.zeros(len(test_X))\n",
    "        \n",
    "        for i in range(nsplits):\n",
    "\n",
    "            curr_pred = self.predict(test_X[i * self.split_size: (i + 1) * self.split_size, :])\n",
    "            curr_true = test_y[i * self.split_size: (i + 1) * self.split_size]\n",
    "            curr_true, curr_pred = self.process_signal(curr_true, curr_pred, smoothing_window = 5, use_bandpass = True)\n",
    "            \n",
    "            mses[i * self.split_size: (i + 1) * self.split_size] = curr_true - curr_pred\n",
    "            hr_err = self.get_hr_error(curr_true, curr_pred, square = False)\n",
    "            errs.append(hr_err)\n",
    "        \n",
    "        return np.mean(np.square(mses)), np.mean(errs), np.mean(np.square(errs))\n",
    "\n",
    "    def xgb_eval(self):\n",
    "        \n",
    "        nsplits = int(len(self.test_X) / self.split_size)\n",
    "        errs = []\n",
    "        mses = np.zeros(len(self.test_X))\n",
    "        \n",
    "        for i in range(nsplits):\n",
    "\n",
    "            curr_pred = self.predict(xgb.DMatrix(self.test_X[i * self.split_size: (i + 1) * self.split_size, :]))\n",
    "            curr_true = self.test_y[i * self.split_size: (i + 1) * self.split_size]\n",
    "            curr_true, curr_pred = self.process_signal(curr_true, curr_pred, smoothing_window = 5, use_bandpass = True)\n",
    "            \n",
    "            mses[i * self.split_size: (i + 1) * self.split_size] = curr_true - curr_pred\n",
    "            hr_err = self.get_hr_error(curr_true, curr_pred, square = False)\n",
    "            errs.append(hr_err)\n",
    "        \n",
    "        return np.mean(np.square(mses)), np.mean(errs), np.mean(np.square(errs))\n",
    "    \n",
    "    def validate(self):\n",
    "\n",
    "        test_X = self.test_data.get_data()\n",
    "        test_y = self.test_data.get_label()\n",
    "        nsplits = int(len(test_X) / self.split_size)\n",
    "        \n",
    "        errors = []\n",
    "        for i in range(nsplits):\n",
    "\n",
    "            curr_pred = self.predict(test_X[i * self.split_size: (i + 1) * self.split_size, :])\n",
    "            curr_true = test_y[i * self.split_size: (i + 1) * self.split_size]\n",
    "            curr_true, curr_pred = self.process_signal(curr_true, curr_pred, smoothing_window = 5, use_bandpass = True)\n",
    "            \n",
    "            mse = np.mean(np.square(curr_true - curr_pred))\n",
    "            hr_err = self.get_hr_error(curr_true, curr_pred, square = False)\n",
    "            hrv_err = self.get_hrv_error(curr_true, curr_pred, square = False)\n",
    "            peaks_err = self.get_peaks_error(curr_true, curr_pred, square = False)\n",
    "            errors.append({\n",
    "                'mse': mse,\n",
    "                'hr_err': hr_err,\n",
    "                'hrv_err': hrv_err,\n",
    "                'peaks_err': peaks_err\n",
    "            })\n",
    "\n",
    "        return errors\n",
    "\n",
    "    def xgb_validate(self):\n",
    "\n",
    "        test_X = self.test_X\n",
    "        test_y = self.test_y\n",
    "        nsplits = int(len(test_X) / self.split_size)\n",
    "        \n",
    "        errors = []\n",
    "        for i in range(nsplits):\n",
    "            curr_X = xgb.DMatrix(test_X[i * self.split_size: (i + 1) * self.split_size, :])\n",
    "            curr_pred = self.predict(curr_X)\n",
    "            curr_true = test_y[i * self.split_size: (i + 1) * self.split_size]\n",
    "            curr_true, curr_pred = self.process_signal(curr_true, curr_pred, smoothing_window = 5, use_bandpass = True)\n",
    "            \n",
    "            mse = np.mean(np.square(curr_true - curr_pred))\n",
    "            hr_err = self.get_hr_error(curr_true, curr_pred, square = False)\n",
    "            hrv_err = self.get_hrv_error(curr_true, curr_pred, square = False)\n",
    "            peaks_err = self.get_peaks_error(curr_true, curr_pred, square = False)\n",
    "            errors.append({\n",
    "                'mse': mse,\n",
    "                'hr_err': hr_err,\n",
    "                'hrv_err': hrv_err,\n",
    "                'peaks_err': peaks_err\n",
    "            })\n",
    "\n",
    "        return errors\n",
    "\n",
    "    def plot_loss(self):\n",
    "        if self.training_loss is not None and self.test_loss is not None:\n",
    "            training_loss_normed = min_max_scale(self.training_loss)\n",
    "            test_loss_normed = min_max_scale(self.test_loss)\n",
    "            plt.plot(training_loss_normed, label = 'training loss')\n",
    "            plt.plot(test_loss_normed, label = 'test loss')\n",
    "            plt.legend()\n",
    "        \n",
    "    def get_model_stats(self):\n",
    "\n",
    "        model_info = self.gbm.dump_model()\n",
    "        tree_depths = []\n",
    "\n",
    "        for tree_info in model_info['tree_info']:\n",
    "            tree_structure = tree_info['tree_structure']\n",
    "            \n",
    "            # Recursive function to compute the depth of a tree\n",
    "            def calculate_depth(node, current_depth=0):\n",
    "                if 'leaf_value' in node:\n",
    "                    return current_depth\n",
    "                else:\n",
    "                    left_depth = calculate_depth(node['left_child'], current_depth + 1)\n",
    "                    right_depth = calculate_depth(node['right_child'], current_depth + 1)\n",
    "                    return max(left_depth, right_depth)\n",
    "\n",
    "            tree_depth = calculate_depth(tree_structure)\n",
    "            tree_depths.append(tree_depth)\n",
    "        \n",
    "\n",
    "        print(f'Best test loss: {min(self.test_loss)}\\n')\n",
    "        print('Tree depth stats:')\n",
    "        print('Min tree depth:', min(tree_depths))\n",
    "        print('Max tree depth:', max(tree_depths))\n",
    "        print('Avg tree depth:', np.mean(tree_depths))\n",
    "        print('\\nFeature importances:')\n",
    "        display(self.get_feature_importances())\n",
    "    \n",
    "    def get_feature_importances(self):\n",
    "        importances = self.gbm.feature_importance(importance_type='gain')\n",
    "        feature_importances = pd.DataFrame({'feature': self.features, 'importance': importances})\n",
    "        feature_importances = feature_importances.sort_values('importance', ascending=False)\n",
    "        return feature_importances\n",
    "    \n",
    "    def hr_error_eval_metric(self, y_pred, eval_data):\n",
    "        y_true = eval_data.get_label()\n",
    "        nsplits = int(len(y_pred) / self.split_size)\n",
    "        hr_err = []\n",
    "        for i in range(nsplits):\n",
    "            curr_pred = y_pred[i * self.split_size: (i + 1) * self.split_size]\n",
    "            curr_true = y_true[i * self.split_size: (i + 1) * self.split_size]\n",
    "            curr_true, curr_pred = self.process_signal(curr_true, curr_pred, smoothing_window = 10, use_bandpass = True)\n",
    "            hr_err.append(self.get_hr_error(curr_true, curr_pred, square = False))\n",
    "        return 'hr_err', np.mean(hr_err), False\n",
    "    \n",
    "    def hr_error_eval_metric_xgb(self, y_pred, eval_data):\n",
    "        y_true = eval_data.get_label()\n",
    "        nsplits = int(len(y_pred) / self.split_size)\n",
    "        hr_err = []\n",
    "        for i in range(nsplits):\n",
    "            curr_pred = y_pred[i * self.split_size: (i + 1) * self.split_size]\n",
    "            curr_true = y_true[i * self.split_size: (i + 1) * self.split_size]\n",
    "            curr_true, curr_pred = self.process_signal(curr_true, curr_pred, smoothing_window = 10, use_bandpass = True)\n",
    "            hr_err.append(self.get_hr_error(curr_true, curr_pred, square = False))\n",
    "        return 'hr_err', np.mean(hr_err)\n",
    "    \n",
    "    def get_hr_error(self, y_true, y_pred, square = True):\n",
    "\n",
    "        true_peaks, _ = self.get_true_peaks(y_true)\n",
    "        pred_peaks, _ = self.get_predicted_peaks(y_pred)\n",
    "\n",
    "        if len(true_peaks) >= 2:\n",
    "            true_ibis = np.diff(true_peaks) / 64\n",
    "            true_hr = 60 / np.mean(true_ibis)\n",
    "        else:\n",
    "            true_hr = 0\n",
    "\n",
    "        if len(pred_peaks) >= 2:\n",
    "            pred_ibis = np.diff(pred_peaks) / 64\n",
    "            pred_hr = 60 / np.mean(pred_ibis)\n",
    "        else:\n",
    "            pred_hr = 0\n",
    "        \n",
    "        if square:\n",
    "            return np.power(true_hr - pred_hr, 2)\n",
    "        return abs(true_hr - pred_hr)\n",
    "    \n",
    "    def get_peaks_error(self, y_true, y_pred, square = True):\n",
    "        true_peaks, _ = self.get_true_peaks(y_true)\n",
    "        pred_peaks, _ = self.get_predicted_peaks(y_pred)\n",
    "        if square:\n",
    "            return np.power(len(true_peaks) - len(pred_peaks), 2)\n",
    "        return abs(len(true_peaks) - len(pred_peaks))\n",
    "    \n",
    "    def get_hrv_error(self, y_true, y_pred, square = True):\n",
    "\n",
    "        true_peaks, _ = self.get_true_peaks(y_true)\n",
    "        pred_peaks, _ = self.get_predicted_peaks(y_pred)\n",
    "\n",
    "        if len(true_peaks) >= 2:\n",
    "            true_ibis = np.diff(true_peaks) / 64\n",
    "            true_hrv = get_hrv(true_ibis)\n",
    "        else:\n",
    "            true_hrv = 0\n",
    "\n",
    "        if len(pred_peaks) >= 2:\n",
    "            pred_ibis = np.diff(pred_peaks) / 64\n",
    "            pred_hrv = get_hrv(pred_ibis)\n",
    "        else:\n",
    "            pred_hrv = 0\n",
    "        \n",
    "        if square:\n",
    "            return np.power(true_hrv - pred_hrv, 2)\n",
    "        return abs(true_hrv - pred_hrv)\n",
    "    \n",
    "    def process_signal(self, y_true, y_pred, smoothing_window = 10, use_bandpass = False):\n",
    "    \n",
    "        orig_len = len(y_pred)\n",
    "        y_pred = n_moving_avg(y_pred, smoothing_window)\n",
    "        y_pred = resample(y_pred, orig_len)\n",
    "        if use_bandpass:\n",
    "            y_pred = bandpass(y_pred, 64, [self.min_bandpass_freq, self.max_bandpass_freq], self.bandpass_order)\n",
    "        y_pred = min_max_scale(y_pred)\n",
    "        \n",
    "        y_true = n_moving_avg(y_true, 20)\n",
    "        y_true = resample(y_true, orig_len)\n",
    "        if use_bandpass:\n",
    "            y_true = bandpass(y_true, 64, [self.min_bandpass_freq, self.max_bandpass_freq], self.bandpass_order)\n",
    "        y_true = min_max_scale(y_true)\n",
    "        \n",
    "        return y_true, y_pred\n",
    "    \n",
    "    def get_predicted_peaks(self, signal):\n",
    "        return get_peaks_v2(signal, 64, 3.0, -1, prominence = self.predicted_peaks_prominence, with_min_dist = True, with_valleys = False)\n",
    "    def get_true_peaks(self, signal):\n",
    "        return get_peaks_v2(signal, 64, 3.0, -1, prominence = self.true_peaks_prominence, with_min_dist = True, with_valleys = False)\n",
    "\n",
    "    def prepare_dataset_from_subjects(self, truths, data_beg = 1000, data_end = 2000):\n",
    "        data_arr = []\n",
    "        for i in range(len(truths)):    \n",
    "            truth = truths[i]\n",
    "            data = truth.prepare_data_for_ml(self.num_feats_per_channel, self.skip_amount)\n",
    "            data = data.iloc[data_beg: data_end, :]\n",
    "            data['subject'] = i + 1\n",
    "            data_arr.append(data)\n",
    "        return pd.concat(data_arr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subjectwise_kfold(truths, model_type = 'gbdt', random_state = None, loss_type = 'mse',\n",
    "                    n_estimators = 100, split_size = 1280, learning_rate = 0.1, test_size = 0.3, early_stopping_rounds = 50,\n",
    "                    mse_weight = None, dtw_weight = None, data_beg = 1000, data_end = 10000, batches = 1, finetune = True, \n",
    "                    min_bandpass_freq = 0.67, max_bandpass_freq = 3.0, bandpass_order = 4,\n",
    "                    predicted_peaks_prominence = 0.22, true_peaks_prominence = 0.15,\n",
    "                    max_depth = 7, num_leaves = 75, max_bin = 255, num_feats_per_channel = 3, skip_amount = 15,\n",
    "                    rounds_per_model = 1, collect = False):\n",
    "        \n",
    "        models = {}\n",
    "        for subj_idx in range(len(truths)):\n",
    "            models[subj_idx + 1] = []\n",
    "            for i in range(rounds_per_model):\n",
    "                \n",
    "                print(f'\\n\\nTraining excluding subject {subj_idx + 1}...\\n')\n",
    "                mod = LonePineGBM(\n",
    "                    truths = truths,\n",
    "                    model_type = model_type,\n",
    "                    random_state = random_state,\n",
    "                    loss_type = loss_type,\n",
    "                    n_estimators = n_estimators,\n",
    "                    split_size = split_size,\n",
    "                    learning_rate = learning_rate,\n",
    "                    test_size = test_size,\n",
    "                    early_stopping_rounds = early_stopping_rounds,\n",
    "                    mse_weight = mse_weight,\n",
    "                    dtw_weight = dtw_weight,\n",
    "                    data_beg = data_beg,\n",
    "                    data_end = data_end,\n",
    "                    batches = batches,\n",
    "                    finetune = finetune,\n",
    "                    min_bandpass_freq = min_bandpass_freq,\n",
    "                    max_bandpass_freq = max_bandpass_freq,\n",
    "                    bandpass_order = bandpass_order,\n",
    "                    predicted_peaks_prominence = predicted_peaks_prominence,\n",
    "                    true_peaks_prominence = true_peaks_prominence,\n",
    "                    max_depth = max_depth,\n",
    "                    num_leaves = num_leaves,\n",
    "                    max_bin = max_bin,\n",
    "                    num_feats_per_channel = num_feats_per_channel,\n",
    "                    skip_amount = skip_amount,\n",
    "                    excluded_subject = subj_idx + 1\n",
    "                )\n",
    "                mod.fit_xgb()\n",
    "                models[subj_idx + 1].append(mod)\n",
    "        \n",
    "        model_performances = {}\n",
    "        for subj_idx in models:\n",
    "            model_performances[subj_idx] = []\n",
    "            for i in range(rounds_per_model):\n",
    "                mod = models[subj_idx][i]\n",
    "                \n",
    "                if collect:\n",
    "                    model_performances[subj_idx].append(mod.xgb_validate())\n",
    "                else:\n",
    "                    model_performances[subj_idx].append(mod.xgb_eval())\n",
    "\n",
    "                \n",
    "        if collect:\n",
    "            return model_performances\n",
    "\n",
    "        mean_hr_score = np.mean([model_performances[subj_idx][i][1] for subj_idx in model_performances for i in range(rounds_per_model)])\n",
    "        return mean_hr_score, models, model_performances\n",
    "    \n",
    "\n",
    "class LonePineOptimizer:\n",
    "\n",
    "    def __init__(self, truths):\n",
    "        self.truths = truths\n",
    "    \n",
    "    def objective(self, n_estimators = 100, split_size = 1280, learning_rate = 0.1, test_size = 0.3, early_stopping_rounds = 50,\n",
    "                    mse_weight = None, dtw_weight = None, data_beg = 1000, data_end = 2000, batches = 1, finetune = True, \n",
    "                    min_bandpass_freq = 0.67, max_bandpass_freq = 3.0, bandpass_order = 4,\n",
    "                    predicted_peaks_prominence = 0.22, true_peaks_prominence = 0.15,\n",
    "                    max_depth = 7, num_leaves = 75, max_bin = 255, num_feats_per_channel = 3, skip_amount = 15):\n",
    "\n",
    "        try:\n",
    "            hr_score, _, _ = subjectwise_kfold(\n",
    "                self.truths,\n",
    "                model_type = 'gbdt',\n",
    "                random_state = None,\n",
    "                loss_type = 'combined',\n",
    "                n_estimators = n_estimators,\n",
    "                split_size = split_size,\n",
    "                learning_rate = learning_rate,\n",
    "                early_stopping_rounds = 50,\n",
    "                mse_weight = mse_weight,\n",
    "                dtw_weight = dtw_weight,\n",
    "                data_beg = data_beg,\n",
    "                data_end = data_end,\n",
    "                batches = batches,\n",
    "                finetune = finetune,\n",
    "                min_bandpass_freq = min_bandpass_freq,\n",
    "                max_bandpass_freq = max_bandpass_freq,\n",
    "                bandpass_order = bandpass_order,\n",
    "                predicted_peaks_prominence = predicted_peaks_prominence,\n",
    "                true_peaks_prominence = true_peaks_prominence,\n",
    "                max_depth = max_depth,\n",
    "                num_leaves = num_leaves,\n",
    "                max_bin = max_bin,\n",
    "                num_feats_per_channel = num_feats_per_channel,\n",
    "                skip_amount = skip_amount,\n",
    "            )\n",
    "            return hr_score\n",
    "        except:\n",
    "            return 1000\n",
    "    \n",
    "    def optimize(self, n_calls = 50):\n",
    "\n",
    "        space = [\n",
    "            Integer(50, 300, name = \"n_estimators\"),\n",
    "            Integer(640, 1280, name = \"split_size\"),\n",
    "            Real(0.002, 0.5, name = \"learning_rate\"),\n",
    "            Integer(10, 100, name = \"early_stopping_rounds\"),\n",
    "            Real(0.0, 1.0, name = \"mse_weight\"),\n",
    "            Real(0.0, 1.0, name = \"dtw_weight\"),\n",
    "            Integer(1000, 4000, name = \"data_beg\"),\n",
    "            Integer(6000, 10000, name = \"data_end\"),\n",
    "            Integer(1, 8, name = \"batches\"),\n",
    "            Real(0.4, 1.0, name = \"min_bandpass_freq\"),\n",
    "            Real(2.5, 4.0, name = \"max_bandpass_freq\"),\n",
    "            Integer(2, 6, name = \"bandpass_order\"),\n",
    "            Real(0.1, 0.75, name = \"predicted_peaks_prominence\"),\n",
    "            Real(0.1, 0.5, name = \"true_peaks_prominence\"),\n",
    "            Integer(3, 10, name = \"max_depth\"),\n",
    "            Integer(30, 140, name = \"num_leaves\"),\n",
    "            Integer(100, 300, name = \"max_bin\"),\n",
    "            Integer(3, 10, name = \"num_feats_per_channel\"),\n",
    "            Integer(5, 25, name = \"skip_amount\"),\n",
    "        ]\n",
    "\n",
    "        @use_named_args(space)\n",
    "        def wrapped_objective(**params):\n",
    "            return self.objective(**params)\n",
    "        \n",
    "        result = gp_minimize(\n",
    "            wrapped_objective, space, n_calls=n_calls, random_state=42, verbose=1\n",
    "        )\n",
    "\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = LonePineOptimizer(truths)\n",
    "result = optimizer.optimize(n_calls = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# space = [\n",
    "#             Integer(50, 300, name = \"n_estimators\"),\n",
    "#             Integer(640, 1280, name = \"split_size\"),\n",
    "#             Real(0.002, 0.5, name = \"learning_rate\"),\n",
    "#             Integer(10, 100, name = \"early_stopping_rounds\"),\n",
    "#             Real(0.0, 1.0, name = \"mse_weight\"),\n",
    "#             Real(0.0, 1.0, name = \"dtw_weight\"),\n",
    "#             Integer(1000, 4000, name = \"data_beg\"),\n",
    "#             Integer(6000, 10000, name = \"data_end\"),\n",
    "#             Integer(1, 8, name = \"batches\"),\n",
    "#             Real(0.4, 1.0, name = \"min_bandpass_freq\"),\n",
    "#             Real(2.5, 4.0, name = \"max_bandpass_freq\"),\n",
    "#             Integer(2, 6, name = \"bandpass_order\"),\n",
    "#             Real(0.1, 0.75, name = \"predicted_peaks_prominence\"),\n",
    "#             Real(0.1, 0.5, name = \"true_peaks_prominence\"),\n",
    "#             Integer(3, 10, name = \"max_depth\"),\n",
    "#             Integer(30, 140, name = \"num_leaves\"),\n",
    "#             Integer(100, 300, name = \"max_bin\"),\n",
    "#             Integer(3, 10, name = \"num_feats_per_channel\"),\n",
    "#             Integer(5, 25, name = \"skip_amount\"),\n",
    "#         ]\n",
    "\n",
    "optimization_res2 = [198,  # estimators\n",
    " 652,  # split size\n",
    " 0.13420232759443168,  learning rate\n",
    " 65,  # eary stopping rounds\n",
    " 0.6077211141678971, # mse weight\n",
    " 0.7044252128526859, # dtw weight\n",
    " 3747, # data beg\n",
    " 6000, # data end\n",
    " 1, # batches\n",
    " 0.8352220930795105, # min bandpass freq\n",
    " 2.8301370404787782, # max bandpass freq\n",
    " 6, # bandpass order\n",
    " 0.1, # predicted peaks prominence\n",
    " 0.1, # true peaks prominence\n",
    " 5, # max depth\n",
    " 30, # num leaves\n",
    " 300, # max bin\n",
    " 5, # num feats per channel\n",
    " 5] # skip amount\n",
    "\n",
    "optimization_res = [188,\n",
    " 993,\n",
    " 0.22844583483861589,\n",
    " 16,\n",
    " 0.913467044583398,\n",
    " 1.0,\n",
    " 3909,\n",
    " 7474,\n",
    " 5,\n",
    " 0.9421772128909808,\n",
    " 3.6351090994830813,\n",
    " 4,\n",
    " 0.17087564911262462,\n",
    " 0.322741927274642,\n",
    " 6,\n",
    " 34,\n",
    " 235,\n",
    " 8,\n",
    " 12]\n",
    "\n",
    "result.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.mean([model_performances[sub][i][1] for sub in model_performances for i in range(3)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "truths = []\n",
    "for subject in range(1, 8):\n",
    "\n",
    "    truth = IeeeGroundTruth(subject, 1, directory = 'channel_data3')\n",
    "    truth.align_rgb_bvp()\n",
    "    truth.fill_nans()\n",
    "    truth.process_rgb(\n",
    "        minmax = False,\n",
    "        use_wavelet = True,\n",
    "        use_bandpass = False\n",
    "    )\n",
    "    truth.process_bvp()\n",
    "    truths.append(truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training excluding subject 1...\n",
      "\n",
      "Rows per batch: 960\n",
      "[17:55:26] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:0.95523\ttrain-hr_err:11.89876\ttest-rmse:0.93408\ttest-hr_err:23.07807\n",
      "[5]\ttrain-rmse:0.95882\ttrain-hr_err:11.89876\ttest-rmse:0.93558\ttest-hr_err:21.52302\n",
      "[10]\ttrain-rmse:0.96245\ttrain-hr_err:16.19248\ttest-rmse:0.93711\ttest-hr_err:21.75408\n",
      "[15]\ttrain-rmse:0.96612\ttrain-hr_err:16.19248\ttest-rmse:0.93872\ttest-hr_err:23.22492\n",
      "[20]\ttrain-rmse:0.96980\ttrain-hr_err:16.19248\ttest-rmse:0.94038\ttest-hr_err:21.70469\n",
      "[21]\ttrain-rmse:0.97054\ttrain-hr_err:16.19248\ttest-rmse:0.94072\ttest-hr_err:21.70469\n",
      "\n",
      "\n",
      "Fine-tuning...\n",
      "[17:55:30] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:1.32435\ttrain-hr_err:16.19248\ttest-rmse:0.94112\ttest-hr_err:21.70469\n",
      "[5]\ttrain-rmse:1.33066\ttrain-hr_err:16.19248\ttest-rmse:0.94321\ttest-hr_err:23.28131\n",
      "[10]\ttrain-rmse:1.33701\ttrain-hr_err:16.19248\ttest-rmse:0.94537\ttest-hr_err:25.14425\n",
      "[17:55:33] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:0.62604\ttrain-hr_err:15.19014\ttest-rmse:0.94623\ttest-hr_err:26.67116\n",
      "[5]\ttrain-rmse:0.63015\ttrain-hr_err:13.51766\ttest-rmse:0.94836\ttest-hr_err:26.58877\n",
      "[10]\ttrain-rmse:0.63429\ttrain-hr_err:13.43031\ttest-rmse:0.95051\ttest-hr_err:29.84822\n",
      "[15]\ttrain-rmse:0.63845\ttrain-hr_err:13.51766\ttest-rmse:0.95270\ttest-hr_err:29.83890\n",
      "[17]\ttrain-rmse:0.64013\ttrain-hr_err:13.51766\ttest-rmse:0.95359\ttest-hr_err:29.82002\n",
      "\n",
      "\n",
      "Fine-tuning...\n",
      "[17:55:37] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:1.13077\ttrain-hr_err:18.10548\ttest-rmse:0.95493\ttest-hr_err:28.11336\n",
      "[5]\ttrain-rmse:1.13840\ttrain-hr_err:18.10548\ttest-rmse:0.95947\ttest-hr_err:28.11336\n",
      "[10]\ttrain-rmse:1.14607\ttrain-hr_err:18.10548\ttest-rmse:0.96407\ttest-hr_err:27.71311\n",
      "[14]\ttrain-rmse:1.15223\ttrain-hr_err:3.41160\ttest-rmse:0.96781\ttest-hr_err:27.73865\n",
      "[17:55:41] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:0.56665\ttrain-hr_err:0.77692\ttest-rmse:0.96917\ttest-hr_err:29.44532\n",
      "[5]\ttrain-rmse:0.57129\ttrain-hr_err:0.77692\ttest-rmse:0.97129\ttest-hr_err:29.85578\n",
      "[10]\ttrain-rmse:0.57596\ttrain-hr_err:0.77692\ttest-rmse:0.97345\ttest-hr_err:31.47603\n",
      "[15]\ttrain-rmse:0.58067\ttrain-hr_err:0.77692\ttest-rmse:0.97562\ttest-hr_err:32.90461\n",
      "[16]\ttrain-rmse:0.58162\ttrain-hr_err:0.77692\ttest-rmse:0.97606\ttest-hr_err:32.88066\n",
      "\n",
      "\n",
      "Fine-tuning...\n",
      "[17:55:44] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:1.12702\ttrain-hr_err:0.37107\ttest-rmse:0.97711\ttest-hr_err:32.88066\n",
      "[5]\ttrain-rmse:1.13583\ttrain-hr_err:0.37107\ttest-rmse:0.98243\ttest-hr_err:32.88066\n",
      "[8]\ttrain-rmse:1.14114\ttrain-hr_err:0.37107\ttest-rmse:0.98567\ttest-hr_err:32.88066\n",
      "[17:55:46] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:0.60249\ttrain-hr_err:38.71848\ttest-rmse:0.98621\ttest-hr_err:32.88066\n",
      "[5]\ttrain-rmse:0.60723\ttrain-hr_err:37.45208\ttest-rmse:0.98894\ttest-hr_err:31.45050\n",
      "[10]\ttrain-rmse:0.61201\ttrain-hr_err:35.47460\ttest-rmse:0.99170\ttest-hr_err:29.83024\n",
      "[15]\ttrain-rmse:0.61683\ttrain-hr_err:35.57398\ttest-rmse:0.99449\ttest-hr_err:29.83024\n",
      "[20]\ttrain-rmse:0.62168\ttrain-hr_err:35.57398\ttest-rmse:0.99728\ttest-hr_err:26.84479\n",
      "[25]\ttrain-rmse:0.62658\ttrain-hr_err:35.57398\ttest-rmse:1.00011\ttest-hr_err:23.66925\n",
      "[30]\ttrain-rmse:0.63151\ttrain-hr_err:35.57398\ttest-rmse:1.00298\ttest-hr_err:23.64205\n",
      "[35]\ttrain-rmse:0.63649\ttrain-hr_err:35.62351\ttest-rmse:1.00589\ttest-hr_err:20.65500\n",
      "[40]\ttrain-rmse:0.64151\ttrain-hr_err:35.62351\ttest-rmse:1.00885\ttest-hr_err:20.65500\n",
      "[45]\ttrain-rmse:0.64657\ttrain-hr_err:35.62351\ttest-rmse:1.01185\ttest-hr_err:19.25569\n",
      "[50]\ttrain-rmse:0.65167\ttrain-hr_err:35.62351\ttest-rmse:1.01488\ttest-hr_err:19.03475\n",
      "[55]\ttrain-rmse:0.65682\ttrain-hr_err:35.62351\ttest-rmse:1.01796\ttest-hr_err:22.02180\n",
      "[60]\ttrain-rmse:0.66200\ttrain-hr_err:31.46766\ttest-rmse:1.02109\ttest-hr_err:22.02180\n",
      "[65]\ttrain-rmse:0.66722\ttrain-hr_err:32.50542\ttest-rmse:1.02426\ttest-hr_err:22.04850\n",
      "[66]\ttrain-rmse:0.66827\ttrain-hr_err:32.50542\ttest-rmse:1.02489\ttest-hr_err:22.04850\n",
      "\n",
      "\n",
      "Fine-tuning...\n",
      "[17:56:01] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:1.31439\ttrain-hr_err:32.59620\ttest-rmse:1.02612\ttest-hr_err:22.04850\n",
      "[5]\ttrain-rmse:1.32393\ttrain-hr_err:31.55844\ttest-rmse:1.03230\ttest-hr_err:22.24275\n",
      "[8]\ttrain-rmse:1.32967\ttrain-hr_err:31.55844\ttest-rmse:1.03605\ttest-hr_err:22.24275\n",
      "[17:56:04] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:0.96331\ttrain-hr_err:1.23351\ttest-rmse:1.03781\ttest-hr_err:21.99517\n",
      "[5]\ttrain-rmse:0.96787\ttrain-hr_err:3.21183\ttest-rmse:1.04037\ttest-hr_err:22.04445\n",
      "[10]\ttrain-rmse:0.97246\ttrain-hr_err:3.93411\ttest-rmse:1.04299\ttest-hr_err:18.31888\n",
      "[15]\ttrain-rmse:0.97706\ttrain-hr_err:6.94493\ttest-rmse:1.04565\ttest-hr_err:15.24067\n",
      "[20]\ttrain-rmse:0.98167\ttrain-hr_err:2.23904\ttest-rmse:1.04837\ttest-hr_err:15.32862\n",
      "[25]\ttrain-rmse:0.98629\ttrain-hr_err:2.16417\ttest-rmse:1.05111\ttest-hr_err:19.87697\n",
      "[30]\ttrain-rmse:0.99091\ttrain-hr_err:2.53596\ttest-rmse:1.05384\ttest-hr_err:16.91255\n",
      "\n",
      "\n",
      "Fine-tuning...\n",
      "[17:56:12] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:1.57595\ttrain-hr_err:1.55812\ttest-rmse:1.05555\ttest-hr_err:15.48434\n",
      "[5]\ttrain-rmse:1.58457\ttrain-hr_err:2.71395\ttest-rmse:1.06147\ttest-hr_err:15.48434\n",
      "[10]\ttrain-rmse:1.59325\ttrain-hr_err:2.57287\ttest-rmse:1.06746\ttest-hr_err:13.96459\n",
      "[15]\ttrain-rmse:1.60195\ttrain-hr_err:2.50257\ttest-rmse:1.07373\ttest-hr_err:13.90836\n",
      "[20]\ttrain-rmse:1.61068\ttrain-hr_err:2.43244\ttest-rmse:1.08018\ttest-hr_err:15.44032\n",
      "[22]\ttrain-rmse:1.61417\ttrain-hr_err:2.43244\ttest-rmse:1.08279\ttest-hr_err:15.44032\n",
      "Finished training in 0:00:52.663290\n",
      "\n",
      "\n",
      "Training excluding subject 1...\n",
      "\n",
      "Rows per batch: 960\n",
      "[17:56:23] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:0.95691\ttrain-hr_err:1.37726\ttest-rmse:0.65741\ttest-hr_err:25.31853\n",
      "[5]\ttrain-rmse:0.96127\ttrain-hr_err:1.37726\ttest-rmse:0.65714\ttest-hr_err:25.31853\n",
      "[10]\ttrain-rmse:0.96564\ttrain-hr_err:1.37726\ttest-rmse:0.65693\ttest-hr_err:25.31853\n",
      "[15]\ttrain-rmse:0.96999\ttrain-hr_err:1.25917\ttest-rmse:0.65673\ttest-hr_err:26.80254\n",
      "\n",
      "\n",
      "Fine-tuning...\n",
      "[17:56:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:1.32364\ttrain-hr_err:1.25917\ttest-rmse:0.65738\ttest-hr_err:25.33633\n",
      "[5]\ttrain-rmse:1.33009\ttrain-hr_err:1.25917\ttest-rmse:0.66097\ttest-hr_err:21.75352\n",
      "[10]\ttrain-rmse:1.33657\ttrain-hr_err:1.14134\ttest-rmse:0.66471\ttest-hr_err:16.26073\n",
      "[15]\ttrain-rmse:1.34307\ttrain-hr_err:1.14134\ttest-rmse:0.66851\ttest-hr_err:19.79137\n",
      "[19]\ttrain-rmse:1.34829\ttrain-hr_err:1.25917\ttest-rmse:0.67158\ttest-hr_err:21.55635\n",
      "[17:56:34] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:0.97037\ttrain-hr_err:29.56422\ttest-rmse:0.67206\ttest-hr_err:21.55635\n",
      "[5]\ttrain-rmse:0.97465\ttrain-hr_err:17.34789\ttest-rmse:0.67449\ttest-hr_err:20.39931\n",
      "[10]\ttrain-rmse:0.97893\ttrain-hr_err:5.35563\ttest-rmse:0.67695\ttest-hr_err:20.15046\n",
      "[15]\ttrain-rmse:0.98321\ttrain-hr_err:1.29214\ttest-rmse:0.67943\ttest-hr_err:21.16154\n",
      "[20]\ttrain-rmse:0.98749\ttrain-hr_err:2.77135\ttest-rmse:0.68193\ttest-hr_err:21.84492\n",
      "[25]\ttrain-rmse:0.99181\ttrain-hr_err:2.77135\ttest-rmse:0.68417\ttest-hr_err:23.45904\n",
      "[28]\ttrain-rmse:0.99442\ttrain-hr_err:3.05298\ttest-rmse:0.68542\ttest-hr_err:23.89120\n",
      "\n",
      "\n",
      "Fine-tuning...\n",
      "[17:56:43] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:1.38471\ttrain-hr_err:3.05298\ttest-rmse:0.68676\ttest-hr_err:23.89120\n",
      "[5]\ttrain-rmse:1.39136\ttrain-hr_err:1.17144\ttest-rmse:0.69136\ttest-hr_err:23.75072\n",
      "[10]\ttrain-rmse:1.39807\ttrain-hr_err:1.17144\ttest-rmse:0.69609\ttest-hr_err:28.24659\n",
      "[12]\ttrain-rmse:1.40077\ttrain-hr_err:1.17144\ttest-rmse:0.69800\ttest-hr_err:26.67704\n",
      "[17:56:47] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:0.62006\ttrain-hr_err:15.72965\ttest-rmse:0.69928\ttest-hr_err:26.55156\n",
      "[5]\ttrain-rmse:0.62410\ttrain-hr_err:20.15361\ttest-rmse:0.70150\ttest-hr_err:26.58265\n",
      "[10]\ttrain-rmse:0.62816\ttrain-hr_err:24.57757\ttest-rmse:0.70376\ttest-hr_err:26.61382\n",
      "[15]\ttrain-rmse:0.63220\ttrain-hr_err:24.57757\ttest-rmse:0.70547\ttest-hr_err:25.10661\n",
      "[20]\ttrain-rmse:0.63627\ttrain-hr_err:24.57757\ttest-rmse:0.70724\ttest-hr_err:25.10661\n",
      "[25]\ttrain-rmse:0.64035\ttrain-hr_err:24.48594\ttest-rmse:0.70908\ttest-hr_err:26.63725\n",
      "[26]\ttrain-rmse:0.64117\ttrain-hr_err:24.48594\ttest-rmse:0.70947\ttest-hr_err:26.63725\n",
      "\n",
      "\n",
      "Fine-tuning...\n",
      "[17:56:55] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:1.12884\ttrain-hr_err:23.74049\ttest-rmse:0.71103\ttest-hr_err:26.63725\n",
      "[5]\ttrain-rmse:1.13643\ttrain-hr_err:23.74049\ttest-rmse:0.71774\ttest-hr_err:26.74714\n",
      "[10]\ttrain-rmse:1.14404\ttrain-hr_err:28.25609\ttest-rmse:0.72561\ttest-hr_err:26.74714\n",
      "[17:56:59] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:0.91156\ttrain-hr_err:2.64237\ttest-rmse:0.72634\ttest-hr_err:26.72643\n",
      "[5]\ttrain-rmse:0.91575\ttrain-hr_err:2.64237\ttest-rmse:0.73002\ttest-hr_err:25.21903\n",
      "[10]\ttrain-rmse:0.91995\ttrain-hr_err:0.56065\ttest-rmse:0.73374\ttest-hr_err:25.16381\n",
      "[15]\ttrain-rmse:0.92418\ttrain-hr_err:0.48998\ttest-rmse:0.73751\ttest-hr_err:26.64083\n",
      "[20]\ttrain-rmse:0.92842\ttrain-hr_err:0.48998\ttest-rmse:0.74132\ttest-hr_err:25.18729\n",
      "[25]\ttrain-rmse:0.93266\ttrain-hr_err:0.48998\ttest-rmse:0.74515\ttest-hr_err:22.97520\n",
      "[30]\ttrain-rmse:0.93695\ttrain-hr_err:0.48998\ttest-rmse:0.74903\ttest-hr_err:25.88515\n",
      "[35]\ttrain-rmse:0.94126\ttrain-hr_err:0.48998\ttest-rmse:0.75296\ttest-hr_err:28.05126\n",
      "[39]\ttrain-rmse:0.94471\ttrain-hr_err:4.19104\ttest-rmse:0.75612\ttest-hr_err:31.10622\n",
      "\n",
      "\n",
      "Fine-tuning...\n",
      "[17:57:10] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:1.45283\ttrain-hr_err:4.19104\ttest-rmse:0.75842\ttest-hr_err:29.69497\n",
      "[5]\ttrain-rmse:1.46073\ttrain-hr_err:4.19104\ttest-rmse:0.76599\ttest-hr_err:29.69497\n",
      "[7]\ttrain-rmse:1.46389\ttrain-hr_err:6.80013\ttest-rmse:0.76904\ttest-hr_err:29.69497\n",
      "[17:57:13] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:1.04422\ttrain-hr_err:7.30577\ttest-rmse:0.77105\ttest-hr_err:29.66793\n",
      "[5]\ttrain-rmse:1.04802\ttrain-hr_err:11.68751\ttest-rmse:0.77331\ttest-hr_err:28.02601\n",
      "[10]\ttrain-rmse:1.05184\ttrain-hr_err:11.68751\ttest-rmse:0.77562\ttest-hr_err:26.49124\n",
      "[15]\ttrain-rmse:1.05569\ttrain-hr_err:4.99299\ttest-rmse:0.77758\ttest-hr_err:26.45549\n",
      "[20]\ttrain-rmse:1.05959\ttrain-hr_err:0.39418\ttest-rmse:0.77898\ttest-hr_err:26.19034\n",
      "[25]\ttrain-rmse:1.06414\ttrain-hr_err:0.39418\ttest-rmse:0.78161\ttest-hr_err:24.78065\n",
      "[30]\ttrain-rmse:1.06870\ttrain-hr_err:0.39418\ttest-rmse:0.78427\ttest-hr_err:23.16653\n",
      "[35]\ttrain-rmse:1.07328\ttrain-hr_err:0.39418\ttest-rmse:0.78667\ttest-hr_err:22.43333\n",
      "[40]\ttrain-rmse:1.07787\ttrain-hr_err:0.28941\ttest-rmse:0.78865\ttest-hr_err:22.39766\n",
      "[45]\ttrain-rmse:1.08248\ttrain-hr_err:3.90936\ttest-rmse:0.79050\ttest-hr_err:22.37248\n",
      "[50]\ttrain-rmse:1.08711\ttrain-hr_err:3.90936\ttest-rmse:0.79256\ttest-hr_err:19.52696\n",
      "[55]\ttrain-rmse:1.09178\ttrain-hr_err:0.50443\ttest-rmse:0.79606\ttest-hr_err:22.34325\n",
      "[60]\ttrain-rmse:1.09644\ttrain-hr_err:0.50443\ttest-rmse:0.80040\ttest-hr_err:20.67547\n",
      "[64]\ttrain-rmse:1.10019\ttrain-hr_err:0.50443\ttest-rmse:0.80392\ttest-hr_err:20.64700\n",
      "\n",
      "\n",
      "Fine-tuning...\n",
      "[17:57:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:1.65795\ttrain-hr_err:0.60602\ttest-rmse:0.80623\ttest-hr_err:20.61861\n",
      "[5]\ttrain-rmse:1.66606\ttrain-hr_err:0.60602\ttest-rmse:0.81339\ttest-hr_err:21.09782\n",
      "[8]\ttrain-rmse:1.67096\ttrain-hr_err:0.60602\ttest-rmse:0.81770\ttest-hr_err:21.10328\n",
      "Finished training in 0:01:10.869008\n",
      "\n",
      "\n",
      "Training excluding subject 1...\n",
      "\n",
      "Rows per batch: 960\n",
      "[17:57:37] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:0.52866\ttrain-hr_err:2.76335\ttest-rmse:0.92626\ttest-hr_err:48.75495\n",
      "[5]\ttrain-rmse:0.53299\ttrain-hr_err:2.76335\ttest-rmse:0.92843\ttest-hr_err:48.75495\n",
      "[10]\ttrain-rmse:0.53735\ttrain-hr_err:2.76335\ttest-rmse:0.93063\ttest-hr_err:48.75495\n",
      "[15]\ttrain-rmse:0.54175\ttrain-hr_err:2.76335\ttest-rmse:0.93288\ttest-hr_err:48.75495\n",
      "[16]\ttrain-rmse:0.54263\ttrain-hr_err:2.76335\ttest-rmse:0.93334\ttest-hr_err:48.75495\n",
      "\n",
      "\n",
      "Fine-tuning...\n",
      "[17:57:42] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:1.04299\ttrain-hr_err:2.70112\ttest-rmse:0.93428\ttest-hr_err:48.75495\n",
      "[5]\ttrain-rmse:1.05128\ttrain-hr_err:2.70112\ttest-rmse:0.93905\ttest-hr_err:48.75495\n",
      "[8]\ttrain-rmse:1.05628\ttrain-hr_err:2.70112\ttest-rmse:0.94195\ttest-hr_err:48.75495\n",
      "[17:57:44] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:0.54141\ttrain-hr_err:55.70876\ttest-rmse:0.94242\ttest-hr_err:50.31024\n",
      "[5]\ttrain-rmse:0.54564\ttrain-hr_err:42.72156\ttest-rmse:0.94475\ttest-hr_err:48.64701\n",
      "[10]\ttrain-rmse:0.54991\ttrain-hr_err:33.99537\ttest-rmse:0.94711\ttest-hr_err:41.92717\n",
      "[15]\ttrain-rmse:0.55421\ttrain-hr_err:29.61754\ttest-rmse:0.94951\ttest-hr_err:43.43011\n",
      "[20]\ttrain-rmse:0.55855\ttrain-hr_err:29.61754\ttest-rmse:0.95194\ttest-hr_err:43.40545\n",
      "[24]\ttrain-rmse:0.56205\ttrain-hr_err:29.61754\ttest-rmse:0.95391\ttest-hr_err:48.09187\n",
      "\n",
      "\n",
      "Fine-tuning...\n",
      "[17:57:51] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:1.09337\ttrain-hr_err:29.61754\ttest-rmse:0.95491\ttest-hr_err:48.09187\n",
      "[5]\ttrain-rmse:1.10179\ttrain-hr_err:29.61754\ttest-rmse:0.96000\ttest-hr_err:48.09187\n",
      "[7]\ttrain-rmse:1.10517\ttrain-hr_err:29.61754\ttest-rmse:0.96205\ttest-hr_err:48.09187\n",
      "[17:57:53] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:0.60157\ttrain-hr_err:15.52675\ttest-rmse:0.96364\ttest-hr_err:46.50967\n",
      "[5]\ttrain-rmse:0.60636\ttrain-hr_err:15.52675\ttest-rmse:0.96644\ttest-hr_err:41.78619\n",
      "[10]\ttrain-rmse:0.61118\ttrain-hr_err:11.19266\ttest-rmse:0.96928\ttest-hr_err:40.22712\n",
      "[15]\ttrain-rmse:0.61604\ttrain-hr_err:11.12426\ttest-rmse:0.97220\ttest-hr_err:33.46622\n",
      "[20]\ttrain-rmse:0.62093\ttrain-hr_err:11.12426\ttest-rmse:0.97518\ttest-hr_err:33.48712\n",
      "[25]\ttrain-rmse:0.62587\ttrain-hr_err:11.12426\ttest-rmse:0.97824\ttest-hr_err:28.83936\n",
      "[30]\ttrain-rmse:0.63083\ttrain-hr_err:11.19266\ttest-rmse:0.98131\ttest-hr_err:30.22764\n",
      "[35]\ttrain-rmse:0.63584\ttrain-hr_err:11.19266\ttest-rmse:0.98442\ttest-hr_err:30.22764\n",
      "[40]\ttrain-rmse:0.64089\ttrain-hr_err:11.19266\ttest-rmse:0.98757\ttest-hr_err:31.78862\n",
      "[42]\ttrain-rmse:0.64292\ttrain-hr_err:11.19266\ttest-rmse:0.98884\ttest-hr_err:35.07362\n",
      "\n",
      "\n",
      "Fine-tuning...\n",
      "[17:58:05] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:1.23905\ttrain-hr_err:11.25635\ttest-rmse:0.99066\ttest-hr_err:35.07362\n",
      "[5]\ttrain-rmse:1.24837\ttrain-hr_err:11.25635\ttest-rmse:0.99661\ttest-hr_err:35.07362\n",
      "[8]\ttrain-rmse:1.25398\ttrain-hr_err:11.25635\ttest-rmse:1.00022\ttest-hr_err:35.07362\n",
      "[17:58:08] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:0.71071\ttrain-hr_err:19.79201\ttest-rmse:1.00082\ttest-hr_err:36.66320\n",
      "[5]\ttrain-rmse:0.71560\ttrain-hr_err:12.52393\ttest-rmse:1.00385\ttest-hr_err:35.67181\n",
      "[10]\ttrain-rmse:0.72052\ttrain-hr_err:7.47724\ttest-rmse:1.00693\ttest-hr_err:33.42390\n",
      "[15]\ttrain-rmse:0.72547\ttrain-hr_err:7.20381\ttest-rmse:1.01006\ttest-hr_err:33.44791\n",
      "[20]\ttrain-rmse:0.73046\ttrain-hr_err:16.93765\ttest-rmse:1.01323\ttest-hr_err:34.82267\n",
      "[25]\ttrain-rmse:0.73549\ttrain-hr_err:16.98694\ttest-rmse:1.01645\ttest-hr_err:33.66660\n",
      "[30]\ttrain-rmse:0.74055\ttrain-hr_err:21.84770\ttest-rmse:1.01971\ttest-hr_err:35.09706\n",
      "[32]\ttrain-rmse:0.74258\ttrain-hr_err:21.84770\ttest-rmse:1.02103\ttest-hr_err:36.50365\n",
      "\n",
      "\n",
      "Fine-tuning...\n",
      "[17:58:17] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:1.35969\ttrain-hr_err:16.76833\ttest-rmse:1.02282\ttest-hr_err:36.50365\n",
      "[5]\ttrain-rmse:1.36810\ttrain-hr_err:18.02915\ttest-rmse:1.02850\ttest-hr_err:35.09706\n",
      "[10]\ttrain-rmse:1.37654\ttrain-hr_err:0.92352\ttest-rmse:1.03424\ttest-hr_err:35.09706\n",
      "[11]\ttrain-rmse:1.37823\ttrain-hr_err:13.39105\ttest-rmse:1.03539\ttest-hr_err:35.09706\n",
      "[17:58:21] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:1.08802\ttrain-hr_err:11.62824\ttest-rmse:1.03693\ttest-hr_err:36.50365\n",
      "[5]\ttrain-rmse:1.09284\ttrain-hr_err:11.96390\ttest-rmse:1.03878\ttest-hr_err:36.52842\n",
      "[10]\ttrain-rmse:1.09766\ttrain-hr_err:12.04734\ttest-rmse:1.04053\ttest-hr_err:30.11179\n",
      "[15]\ttrain-rmse:1.10250\ttrain-hr_err:3.46243\ttest-rmse:1.04229\ttest-hr_err:30.91863\n",
      "[20]\ttrain-rmse:1.10738\ttrain-hr_err:3.36938\ttest-rmse:1.04362\ttest-hr_err:33.39354\n",
      "[25]\ttrain-rmse:1.11226\ttrain-hr_err:3.46243\ttest-rmse:1.04499\ttest-hr_err:30.21854\n",
      "\n",
      "\n",
      "Fine-tuning...\n",
      "[17:58:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:1.65965\ttrain-hr_err:0.87166\ttest-rmse:1.04608\ttest-hr_err:31.89174\n",
      "[5]\ttrain-rmse:1.66804\ttrain-hr_err:0.87166\ttest-rmse:1.05156\ttest-hr_err:31.69132\n",
      "[10]\ttrain-rmse:1.67650\ttrain-hr_err:0.87166\ttest-rmse:1.05706\ttest-hr_err:30.54644\n",
      "Finished training in 0:00:54.082026\n",
      "\n",
      "\n",
      "Training excluding subject 1...\n",
      "\n",
      "Rows per batch: 960\n",
      "[17:58:35] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:0.54015\ttrain-hr_err:1.47072\ttest-rmse:0.67642\ttest-hr_err:14.39623\n",
      "[5]\ttrain-rmse:0.54444\ttrain-hr_err:1.47072\ttest-rmse:0.67962\ttest-hr_err:14.39623\n",
      "[10]\ttrain-rmse:0.54878\ttrain-hr_err:1.47072\ttest-rmse:0.68286\ttest-hr_err:14.39623\n",
      "[15]\ttrain-rmse:0.55314\ttrain-hr_err:1.47072\ttest-rmse:0.68614\ttest-hr_err:14.39623\n",
      "\n",
      "\n",
      "Fine-tuning...\n",
      "[17:58:40] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:1.05055\ttrain-hr_err:1.47072\ttest-rmse:0.68803\ttest-hr_err:14.39623\n",
      "[5]\ttrain-rmse:1.05878\ttrain-hr_err:1.47072\ttest-rmse:0.69427\ttest-hr_err:14.39623\n",
      "[8]\ttrain-rmse:1.06374\ttrain-hr_err:1.47072\ttest-rmse:0.69804\ttest-hr_err:14.39623\n",
      "[17:58:43] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:0.97235\ttrain-hr_err:29.59965\ttest-rmse:0.69830\ttest-hr_err:15.74454\n",
      "[5]\ttrain-rmse:0.97706\ttrain-hr_err:1.25917\ttest-rmse:0.70103\ttest-hr_err:19.19928\n",
      "[10]\ttrain-rmse:0.98177\ttrain-hr_err:1.14134\ttest-rmse:0.70378\ttest-hr_err:21.51570\n",
      "[15]\ttrain-rmse:0.98647\ttrain-hr_err:1.14134\ttest-rmse:0.70658\ttest-hr_err:25.93533\n",
      "[18]\ttrain-rmse:0.98929\ttrain-hr_err:1.14134\ttest-rmse:0.70828\ttest-hr_err:24.46744\n",
      "\n",
      "\n",
      "Fine-tuning...\n",
      "[17:58:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:1.37604\ttrain-hr_err:1.14134\ttest-rmse:0.70919\ttest-hr_err:25.88494\n",
      "[5]\ttrain-rmse:1.38286\ttrain-hr_err:1.14134\ttest-rmse:0.71338\ttest-hr_err:22.76471\n",
      "[10]\ttrain-rmse:1.38969\ttrain-hr_err:1.02376\ttest-rmse:0.71707\ttest-hr_err:27.04317\n",
      "[11]\ttrain-rmse:1.39106\ttrain-hr_err:1.02376\ttest-rmse:0.71782\ttest-hr_err:25.86993\n",
      "[17:58:52] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:0.99920\ttrain-hr_err:5.78571\ttest-rmse:0.71819\ttest-hr_err:27.46793\n",
      "[5]\ttrain-rmse:1.00343\ttrain-hr_err:5.69370\ttest-rmse:0.71996\ttest-hr_err:21.12790\n",
      "[10]\ttrain-rmse:1.00764\ttrain-hr_err:5.60149\ttest-rmse:0.72181\ttest-hr_err:16.56166\n",
      "[15]\ttrain-rmse:1.01194\ttrain-hr_err:7.20557\ttest-rmse:0.72415\ttest-hr_err:18.84519\n",
      "[20]\ttrain-rmse:1.01616\ttrain-hr_err:11.67589\ttest-rmse:0.72619\ttest-hr_err:16.28804\n",
      "[25]\ttrain-rmse:1.02034\ttrain-hr_err:11.58732\ttest-rmse:0.72806\ttest-hr_err:16.23472\n",
      "[30]\ttrain-rmse:1.02453\ttrain-hr_err:7.11179\ttest-rmse:0.72997\ttest-hr_err:15.03485\n",
      "[35]\ttrain-rmse:1.02872\ttrain-hr_err:7.20557\ttest-rmse:0.73191\ttest-hr_err:13.52434\n",
      "[40]\ttrain-rmse:1.03292\ttrain-hr_err:2.73526\ttest-rmse:0.73388\ttest-hr_err:12.04154\n",
      "[45]\ttrain-rmse:1.03713\ttrain-hr_err:2.73526\ttest-rmse:0.73588\ttest-hr_err:12.04154\n",
      "[50]\ttrain-rmse:1.04113\ttrain-hr_err:2.73526\ttest-rmse:0.73784\ttest-hr_err:10.60977\n",
      "[55]\ttrain-rmse:1.04509\ttrain-hr_err:2.73526\ttest-rmse:0.73983\ttest-hr_err:10.60977\n",
      "[60]\ttrain-rmse:1.04909\ttrain-hr_err:2.83402\ttest-rmse:0.74189\ttest-hr_err:11.63516\n",
      "[65]\ttrain-rmse:1.05304\ttrain-hr_err:2.83402\ttest-rmse:0.74406\ttest-hr_err:11.63516\n",
      "[70]\ttrain-rmse:1.05706\ttrain-hr_err:4.19297\ttest-rmse:0.74615\ttest-hr_err:14.59802\n",
      "[71]\ttrain-rmse:1.05792\ttrain-hr_err:4.19297\ttest-rmse:0.74646\ttest-hr_err:14.56923\n",
      "\n",
      "\n",
      "Fine-tuning...\n",
      "[17:59:13] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:1.52923\ttrain-hr_err:2.93256\ttest-rmse:0.74784\ttest-hr_err:14.56923\n",
      "[5]\ttrain-rmse:1.53657\ttrain-hr_err:7.39249\ttest-rmse:0.75308\ttest-hr_err:13.06308\n",
      "[10]\ttrain-rmse:1.54382\ttrain-hr_err:11.85242\ttest-rmse:0.75874\ttest-hr_err:14.62298\n",
      "[11]\ttrain-rmse:1.54527\ttrain-hr_err:11.85242\ttest-rmse:0.75989\ttest-hr_err:14.90278\n",
      "[17:59:17] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:0.90899\ttrain-hr_err:19.18939\ttest-rmse:0.76027\ttest-hr_err:13.09187\n",
      "[5]\ttrain-rmse:0.91328\ttrain-hr_err:19.23490\ttest-rmse:0.76189\ttest-hr_err:14.79259\n",
      "[10]\ttrain-rmse:0.91759\ttrain-hr_err:19.23490\ttest-rmse:0.76357\ttest-hr_err:14.82473\n",
      "[15]\ttrain-rmse:0.92192\ttrain-hr_err:14.88167\ttest-rmse:0.76528\ttest-hr_err:10.22681\n",
      "[20]\ttrain-rmse:0.92627\ttrain-hr_err:10.48305\ttest-rmse:0.76702\ttest-hr_err:10.25194\n",
      "[25]\ttrain-rmse:0.93061\ttrain-hr_err:6.08442\ttest-rmse:0.76870\ttest-hr_err:10.27920\n",
      "[26]\ttrain-rmse:0.93148\ttrain-hr_err:6.08442\ttest-rmse:0.76906\ttest-hr_err:10.30438\n",
      "\n",
      "\n",
      "Fine-tuning...\n",
      "[17:59:25] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:1.42562\ttrain-hr_err:6.08442\ttest-rmse:0.77068\ttest-hr_err:10.93979\n",
      "[5]\ttrain-rmse:1.43334\ttrain-hr_err:1.68579\ttest-rmse:0.77726\ttest-hr_err:11.82277\n",
      "[8]\ttrain-rmse:1.43799\ttrain-hr_err:1.68579\ttest-rmse:0.78125\ttest-hr_err:11.82277\n",
      "[17:59:27] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:1.03956\ttrain-hr_err:37.45819\ttest-rmse:0.78321\ttest-hr_err:11.82277\n",
      "[5]\ttrain-rmse:1.04411\ttrain-hr_err:33.35563\ttest-rmse:0.78625\ttest-hr_err:11.25286\n",
      "[10]\ttrain-rmse:1.04876\ttrain-hr_err:21.04794\ttest-rmse:0.78924\ttest-hr_err:11.28024\n",
      "[15]\ttrain-rmse:1.05333\ttrain-hr_err:16.84445\ttest-rmse:0.79175\ttest-hr_err:12.73575\n",
      "[20]\ttrain-rmse:1.05790\ttrain-hr_err:18.46918\ttest-rmse:0.79426\ttest-hr_err:12.74114\n",
      "[25]\ttrain-rmse:1.06249\ttrain-hr_err:19.03890\ttest-rmse:0.79685\ttest-hr_err:11.30133\n",
      "[27]\ttrain-rmse:1.06433\ttrain-hr_err:23.53292\ttest-rmse:0.79793\ttest-hr_err:11.30133\n",
      "\n",
      "\n",
      "Fine-tuning...\n",
      "[17:59:36] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:1.56845\ttrain-hr_err:23.65714\ttest-rmse:0.79894\ttest-hr_err:11.30133\n",
      "[5]\ttrain-rmse:1.57629\ttrain-hr_err:23.65714\ttest-rmse:0.80400\ttest-hr_err:11.36475\n",
      "[8]\ttrain-rmse:1.58101\ttrain-hr_err:23.75734\ttest-rmse:0.80706\ttest-hr_err:11.39453\n",
      "Finished training in 0:01:03.074554\n",
      "\n",
      "\n",
      "Training excluding subject 1...\n",
      "\n",
      "Rows per batch: 960\n",
      "[17:59:42] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:0.98008\ttrain-hr_err:1.03982\ttest-rmse:0.92570\ttest-hr_err:20.70141\n",
      "[5]\ttrain-rmse:0.98455\ttrain-hr_err:1.03982\ttest-rmse:0.92644\ttest-hr_err:20.70141\n",
      "[10]\ttrain-rmse:0.98902\ttrain-hr_err:1.03982\ttest-rmse:0.92719\ttest-hr_err:20.70141\n",
      "[15]\ttrain-rmse:0.99349\ttrain-hr_err:1.03982\ttest-rmse:0.92802\ttest-hr_err:20.60979\n",
      "[20]\ttrain-rmse:0.99795\ttrain-hr_err:1.03982\ttest-rmse:0.92898\ttest-hr_err:20.33767\n",
      "[25]\ttrain-rmse:1.00240\ttrain-hr_err:1.03982\ttest-rmse:0.93001\ttest-hr_err:24.01149\n",
      "[27]\ttrain-rmse:1.00404\ttrain-hr_err:1.03982\ttest-rmse:0.93051\ttest-hr_err:21.47669\n",
      "\n",
      "\n",
      "Fine-tuning...\n",
      "[17:59:50] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:1.35519\ttrain-hr_err:1.03982\ttest-rmse:0.93117\ttest-hr_err:19.30883\n",
      "[5]\ttrain-rmse:1.36149\ttrain-hr_err:1.03982\ttest-rmse:0.93327\ttest-hr_err:20.91636\n",
      "[10]\ttrain-rmse:1.36781\ttrain-hr_err:1.03982\ttest-rmse:0.93542\ttest-hr_err:22.87196\n",
      "[15]\ttrain-rmse:1.37416\ttrain-hr_err:1.03982\ttest-rmse:0.93761\ttest-hr_err:19.59969\n",
      "[16]\ttrain-rmse:1.37543\ttrain-hr_err:1.03982\ttest-rmse:0.93805\ttest-hr_err:20.95822\n",
      "[17:59:55] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:0.87076\ttrain-hr_err:0.13950\ttest-rmse:0.93833\ttest-hr_err:19.49201\n",
      "[5]\ttrain-rmse:0.87476\ttrain-hr_err:0.05699\ttest-rmse:0.93972\ttest-hr_err:20.98630\n",
      "[10]\ttrain-rmse:0.87876\ttrain-hr_err:6.33469\ttest-rmse:0.94111\ttest-hr_err:20.68119\n",
      "[15]\ttrain-rmse:0.88278\ttrain-hr_err:6.26910\ttest-rmse:0.94264\ttest-hr_err:15.52784\n",
      "[20]\ttrain-rmse:0.88680\ttrain-hr_err:13.70774\ttest-rmse:0.94422\ttest-hr_err:11.23002\n",
      "[25]\ttrain-rmse:0.89082\ttrain-hr_err:9.24331\ttest-rmse:0.94580\ttest-hr_err:5.63675\n",
      "[30]\ttrain-rmse:0.89485\ttrain-hr_err:9.24331\ttest-rmse:0.94745\ttest-hr_err:8.54584\n",
      "[35]\ttrain-rmse:0.89888\ttrain-hr_err:12.33548\ttest-rmse:0.94940\ttest-hr_err:7.14540\n",
      "[37]\ttrain-rmse:0.90048\ttrain-hr_err:12.27886\ttest-rmse:0.95024\ttest-hr_err:5.68920\n",
      "\n",
      "\n",
      "Fine-tuning...\n",
      "[18:00:06] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:1.33962\ttrain-hr_err:12.27886\ttest-rmse:0.95139\ttest-hr_err:5.68920\n",
      "[5]\ttrain-rmse:1.34667\ttrain-hr_err:12.22210\ttest-rmse:0.95504\ttest-hr_err:4.39161\n",
      "[10]\ttrain-rmse:1.35375\ttrain-hr_err:12.22210\ttest-rmse:0.95880\ttest-hr_err:4.17023\n",
      "[15]\ttrain-rmse:1.36088\ttrain-hr_err:12.22210\ttest-rmse:0.96264\ttest-hr_err:4.28854\n",
      "[18]\ttrain-rmse:1.36517\ttrain-hr_err:12.22210\ttest-rmse:0.96501\ttest-hr_err:4.28854\n",
      "[18:00:11] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:0.64837\ttrain-hr_err:20.74670\ttest-rmse:0.96550\ttest-hr_err:4.60925\n",
      "[5]\ttrain-rmse:0.65268\ttrain-hr_err:20.74670\ttest-rmse:0.96800\ttest-hr_err:5.72191\n",
      "[10]\ttrain-rmse:0.65703\ttrain-hr_err:20.74670\ttest-rmse:0.97053\ttest-hr_err:7.22420\n",
      "[15]\ttrain-rmse:0.66140\ttrain-hr_err:16.32440\ttest-rmse:0.97310\ttest-hr_err:7.22420\n",
      "[16]\ttrain-rmse:0.66228\ttrain-hr_err:16.32440\ttest-rmse:0.97362\ttest-hr_err:7.22420\n",
      "\n",
      "\n",
      "Fine-tuning...\n",
      "[18:00:16] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:1.17971\ttrain-hr_err:21.40376\ttest-rmse:0.97476\ttest-hr_err:7.22420\n",
      "[5]\ttrain-rmse:1.18766\ttrain-hr_err:21.40376\ttest-rmse:0.98051\ttest-hr_err:7.22420\n",
      "[8]\ttrain-rmse:1.19245\ttrain-hr_err:21.40376\ttest-rmse:0.98401\ttest-hr_err:7.22420\n",
      "[18:00:19] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:0.63323\ttrain-hr_err:40.72000\ttest-rmse:0.98463\ttest-hr_err:7.22420\n",
      "[5]\ttrain-rmse:0.63825\ttrain-hr_err:40.72000\ttest-rmse:0.98774\ttest-hr_err:7.22420\n",
      "[10]\ttrain-rmse:0.64331\ttrain-hr_err:40.72000\ttest-rmse:0.99090\ttest-hr_err:7.22420\n",
      "[15]\ttrain-rmse:0.64841\ttrain-hr_err:40.72000\ttest-rmse:0.99411\ttest-hr_err:7.22420\n",
      "[16]\ttrain-rmse:0.64944\ttrain-hr_err:40.72000\ttest-rmse:0.99475\ttest-hr_err:7.22420\n",
      "\n",
      "\n",
      "Fine-tuning...\n",
      "[18:00:24] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:1.25255\ttrain-hr_err:40.72000\ttest-rmse:0.99595\ttest-hr_err:7.22420\n",
      "[5]\ttrain-rmse:1.26193\ttrain-hr_err:40.72000\ttest-rmse:1.00197\ttest-hr_err:7.22420\n",
      "[7]\ttrain-rmse:1.26570\ttrain-hr_err:40.72000\ttest-rmse:1.00440\ttest-hr_err:7.22420\n",
      "[18:00:26] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:0.63248\ttrain-hr_err:16.04469\ttest-rmse:1.00625\ttest-hr_err:7.22420\n",
      "[5]\ttrain-rmse:0.63744\ttrain-hr_err:16.04469\ttest-rmse:1.00945\ttest-hr_err:7.22420\n",
      "[10]\ttrain-rmse:0.64244\ttrain-hr_err:16.12455\ttest-rmse:1.01270\ttest-hr_err:6.99525\n",
      "[15]\ttrain-rmse:0.64749\ttrain-hr_err:20.80177\ttest-rmse:1.01598\ttest-hr_err:6.99525\n",
      "[20]\ttrain-rmse:0.65258\ttrain-hr_err:20.80177\ttest-rmse:1.01928\ttest-hr_err:6.96639\n",
      "[25]\ttrain-rmse:0.65770\ttrain-hr_err:20.80177\ttest-rmse:1.02260\ttest-hr_err:6.96639\n",
      "[30]\ttrain-rmse:0.66287\ttrain-hr_err:20.80177\ttest-rmse:1.02598\ttest-hr_err:6.96639\n",
      "[35]\ttrain-rmse:0.66809\ttrain-hr_err:20.80177\ttest-rmse:1.02943\ttest-hr_err:5.53302\n",
      "[40]\ttrain-rmse:0.67336\ttrain-hr_err:20.80177\ttest-rmse:1.03296\ttest-hr_err:6.96639\n",
      "[45]\ttrain-rmse:0.67868\ttrain-hr_err:20.80177\ttest-rmse:1.03654\ttest-hr_err:6.96639\n",
      "[46]\ttrain-rmse:0.67975\ttrain-hr_err:20.80177\ttest-rmse:1.03726\ttest-hr_err:6.96639\n",
      "\n",
      "\n",
      "Fine-tuning...\n",
      "[18:00:40] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:1.34472\ttrain-hr_err:11.73447\ttest-rmse:1.03927\ttest-hr_err:6.96639\n",
      "[5]\ttrain-rmse:1.35438\ttrain-hr_err:11.73447\ttest-rmse:1.04577\ttest-hr_err:6.96639\n",
      "[7]\ttrain-rmse:1.35825\ttrain-hr_err:11.73447\ttest-rmse:1.04839\ttest-hr_err:6.96639\n",
      "Finished training in 0:01:00.459559\n",
      "\n",
      "\n",
      "Training excluding subject 2...\n",
      "\n",
      "Rows per batch: 960\n",
      "[18:00:47] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:0.84576\ttrain-hr_err:0.65934\ttest-rmse:0.79340\ttest-hr_err:28.70790\n",
      "[5]\ttrain-rmse:0.85032\ttrain-hr_err:0.57623\ttest-rmse:0.79478\ttest-hr_err:27.28205\n",
      "[10]\ttrain-rmse:0.85488\ttrain-hr_err:0.57623\ttest-rmse:0.79633\ttest-hr_err:25.80909\n",
      "[15]\ttrain-rmse:0.85942\ttrain-hr_err:0.49332\ttest-rmse:0.79821\ttest-hr_err:25.78768\n",
      "[20]\ttrain-rmse:0.86386\ttrain-hr_err:0.32809\ttest-rmse:0.80138\ttest-hr_err:31.66094\n",
      "[25]\ttrain-rmse:0.86832\ttrain-hr_err:0.61776\ttest-rmse:0.80439\ttest-hr_err:24.37284\n",
      "[30]\ttrain-rmse:0.87279\ttrain-hr_err:0.61776\ttest-rmse:0.80743\ttest-hr_err:19.17818\n",
      "[35]\ttrain-rmse:0.87722\ttrain-hr_err:0.61776\ttest-rmse:0.81068\ttest-hr_err:19.15149\n",
      "[40]\ttrain-rmse:0.88163\ttrain-hr_err:0.61776\ttest-rmse:0.81396\ttest-hr_err:17.67684\n",
      "[45]\ttrain-rmse:0.88602\ttrain-hr_err:0.61776\ttest-rmse:0.81730\ttest-hr_err:18.45422\n",
      "[50]\ttrain-rmse:0.89041\ttrain-hr_err:0.61776\ttest-rmse:0.82067\ttest-hr_err:18.48367\n",
      "[55]\ttrain-rmse:0.89480\ttrain-hr_err:0.61776\ttest-rmse:0.82407\ttest-hr_err:18.48367\n",
      "[58]\ttrain-rmse:0.89743\ttrain-hr_err:0.61776\ttest-rmse:0.82610\ttest-hr_err:18.45422\n",
      "\n",
      "\n",
      "Fine-tuning...\n",
      "[18:01:03] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:1.31996\ttrain-hr_err:0.61776\ttest-rmse:0.82747\ttest-hr_err:18.45422\n",
      "[5]\ttrain-rmse:1.32671\ttrain-hr_err:0.61776\ttest-rmse:0.83103\ttest-hr_err:17.00902\n",
      "[10]\ttrain-rmse:1.33346\ttrain-hr_err:0.69576\ttest-rmse:0.83474\ttest-hr_err:11.47594\n",
      "[15]\ttrain-rmse:1.34023\ttrain-hr_err:0.69576\ttest-rmse:0.83855\ttest-hr_err:11.37904\n",
      "[20]\ttrain-rmse:1.34705\ttrain-hr_err:0.69576\ttest-rmse:0.84237\ttest-hr_err:9.56232\n",
      "[25]\ttrain-rmse:1.35390\ttrain-hr_err:0.69576\ttest-rmse:0.84626\ttest-hr_err:8.05182\n",
      "[30]\ttrain-rmse:1.36079\ttrain-hr_err:0.69576\ttest-rmse:0.85047\ttest-hr_err:8.02223\n",
      "[31]\ttrain-rmse:1.36218\ttrain-hr_err:0.69576\ttest-rmse:0.85140\ttest-hr_err:8.02223\n",
      "[18:01:13] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:1.02339\ttrain-hr_err:37.57764\ttest-rmse:0.85265\ttest-hr_err:10.81699\n",
      "[5]\ttrain-rmse:1.02832\ttrain-hr_err:26.20609\ttest-rmse:0.85417\ttest-hr_err:10.14066\n",
      "[10]\ttrain-rmse:1.03327\ttrain-hr_err:26.20609\ttest-rmse:0.85554\ttest-hr_err:8.74504\n",
      "[15]\ttrain-rmse:1.03822\ttrain-hr_err:29.39258\ttest-rmse:0.85703\ttest-hr_err:11.00088\n",
      "[20]\ttrain-rmse:1.04313\ttrain-hr_err:12.00772\ttest-rmse:0.85881\ttest-hr_err:8.17977\n",
      "[25]\ttrain-rmse:1.04806\ttrain-hr_err:3.24207\ttest-rmse:0.86073\ttest-hr_err:8.17977\n",
      "[30]\ttrain-rmse:1.05302\ttrain-hr_err:3.24207\ttest-rmse:0.86279\ttest-hr_err:7.83934\n",
      "[35]\ttrain-rmse:1.05796\ttrain-hr_err:3.24207\ttest-rmse:0.86472\ttest-hr_err:7.78491\n",
      "[40]\ttrain-rmse:1.06290\ttrain-hr_err:3.24207\ttest-rmse:0.86670\ttest-hr_err:4.95812\n",
      "[45]\ttrain-rmse:1.06784\ttrain-hr_err:3.12480\ttest-rmse:0.86876\ttest-hr_err:5.04998\n",
      "[50]\ttrain-rmse:1.07277\ttrain-hr_err:1.26105\ttest-rmse:0.87100\ttest-hr_err:2.16337\n",
      "[55]\ttrain-rmse:1.07770\ttrain-hr_err:1.26105\ttest-rmse:0.87327\ttest-hr_err:5.08911\n",
      "[60]\ttrain-rmse:1.08260\ttrain-hr_err:1.26105\ttest-rmse:0.87556\ttest-hr_err:6.52020\n",
      "[65]\ttrain-rmse:1.08749\ttrain-hr_err:1.14348\ttest-rmse:0.87788\ttest-hr_err:7.91758\n",
      "[67]\ttrain-rmse:1.08944\ttrain-hr_err:1.14348\ttest-rmse:0.87882\ttest-hr_err:10.84501\n",
      "\n",
      "\n",
      "Fine-tuning...\n",
      "[18:01:32] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:1.61854\ttrain-hr_err:1.14348\ttest-rmse:0.87986\ttest-hr_err:9.44763\n",
      "[5]\ttrain-rmse:1.62639\ttrain-hr_err:1.14348\ttest-rmse:0.88513\ttest-hr_err:7.97806\n",
      "[10]\ttrain-rmse:1.63425\ttrain-hr_err:1.26105\ttest-rmse:0.89060\ttest-hr_err:8.16905\n",
      "[13]\ttrain-rmse:1.63898\ttrain-hr_err:1.26105\ttest-rmse:0.89389\ttest-hr_err:8.16905\n",
      "[18:01:37] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:0.70116\ttrain-hr_err:33.86682\ttest-rmse:0.89585\ttest-hr_err:8.16905\n",
      "[5]\ttrain-rmse:0.70664\ttrain-hr_err:33.86682\ttest-rmse:0.89985\ttest-hr_err:8.16905\n",
      "[10]\ttrain-rmse:0.71216\ttrain-hr_err:33.86682\ttest-rmse:0.90391\ttest-hr_err:8.16905\n",
      "[15]\ttrain-rmse:0.71774\ttrain-hr_err:33.86682\ttest-rmse:0.90802\ttest-hr_err:8.16905\n",
      "\n",
      "\n",
      "Fine-tuning...\n",
      "[18:01:42] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:1.39739\ttrain-hr_err:33.93035\ttest-rmse:0.91033\ttest-hr_err:8.16905\n",
      "[5]\ttrain-rmse:1.40727\ttrain-hr_err:35.88130\ttest-rmse:0.91779\ttest-hr_err:9.63862\n",
      "[8]\ttrain-rmse:1.41322\ttrain-hr_err:35.88130\ttest-rmse:0.92230\ttest-hr_err:9.63862\n",
      "[18:01:45] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:1.09817\ttrain-hr_err:12.75519\ttest-rmse:0.92253\ttest-hr_err:9.63862\n",
      "[5]\ttrain-rmse:1.10269\ttrain-hr_err:12.87062\ttest-rmse:0.92381\ttest-hr_err:9.63862\n",
      "[10]\ttrain-rmse:1.10718\ttrain-hr_err:12.87062\ttest-rmse:0.92519\ttest-hr_err:9.56643\n",
      "[15]\ttrain-rmse:1.11167\ttrain-hr_err:9.30599\ttest-rmse:0.92681\ttest-hr_err:9.53272\n",
      "[20]\ttrain-rmse:1.11612\ttrain-hr_err:9.41349\ttest-rmse:0.92886\ttest-hr_err:9.53272\n",
      "[22]\ttrain-rmse:1.11790\ttrain-hr_err:9.41349\ttest-rmse:0.92969\ttest-hr_err:9.53272\n",
      "\n",
      "\n",
      "Fine-tuning...\n",
      "[18:01:53] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:1.68244\ttrain-hr_err:5.18051\ttest-rmse:0.93096\ttest-hr_err:9.53272\n",
      "[5]\ttrain-rmse:1.69105\ttrain-hr_err:5.18051\ttest-rmse:0.93749\ttest-hr_err:6.68849\n",
      "[10]\ttrain-rmse:1.69972\ttrain-hr_err:5.28335\ttest-rmse:0.94413\ttest-hr_err:8.24823\n",
      "[12]\ttrain-rmse:1.70319\ttrain-hr_err:9.62233\ttest-rmse:0.94682\ttest-hr_err:6.85085\n",
      "[18:01:57] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:0.73156\ttrain-hr_err:41.99103\ttest-rmse:0.94774\ttest-hr_err:6.85085\n",
      "[5]\ttrain-rmse:0.73747\ttrain-hr_err:41.99103\ttest-rmse:0.95234\ttest-hr_err:6.85085\n",
      "[10]\ttrain-rmse:0.74344\ttrain-hr_err:41.99103\ttest-rmse:0.95701\ttest-hr_err:6.85085\n",
      "[15]\ttrain-rmse:0.74946\ttrain-hr_err:41.99103\ttest-rmse:0.96172\ttest-hr_err:6.85085\n",
      "[16]\ttrain-rmse:0.75067\ttrain-hr_err:41.99103\ttest-rmse:0.96267\ttest-hr_err:6.85085\n",
      "\n",
      "\n",
      "Fine-tuning...\n",
      "[18:02:03] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:1.47288\ttrain-hr_err:43.86593\ttest-rmse:0.96432\ttest-hr_err:6.85085\n",
      "[5]\ttrain-rmse:1.48321\ttrain-hr_err:43.86593\ttest-rmse:0.97262\ttest-hr_err:6.85085\n",
      "[10]\ttrain-rmse:1.49358\ttrain-hr_err:43.86593\ttest-rmse:0.98100\ttest-hr_err:6.82220\n",
      "[14]\ttrain-rmse:1.50190\ttrain-hr_err:43.86593\ttest-rmse:0.98776\ttest-hr_err:6.82220\n",
      "Finished training in 0:01:21.297591\n",
      "\n",
      "\n",
      "Training excluding subject 2...\n",
      "\n",
      "Rows per batch: 960\n",
      "[18:02:12] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:0.53074\ttrain-hr_err:10.85980\ttest-rmse:0.83696\ttest-hr_err:56.44435\n",
      "[5]\ttrain-rmse:0.53507\ttrain-hr_err:10.85980\ttest-rmse:0.83927\ttest-hr_err:56.44435\n",
      "[10]\ttrain-rmse:0.53943\ttrain-hr_err:10.85980\ttest-rmse:0.84161\ttest-hr_err:56.44435\n",
      "[15]\ttrain-rmse:0.54383\ttrain-hr_err:10.85980\ttest-rmse:0.84399\ttest-hr_err:56.44435\n",
      "[16]\ttrain-rmse:0.54471\ttrain-hr_err:10.85980\ttest-rmse:0.84447\ttest-hr_err:56.44435\n",
      "\n",
      "\n",
      "Fine-tuning...\n",
      "[18:02:17] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:1.04539\ttrain-hr_err:11.81273\ttest-rmse:0.84549\ttest-hr_err:56.44435\n",
      "[5]\ttrain-rmse:1.05370\ttrain-hr_err:11.81273\ttest-rmse:0.85064\ttest-hr_err:56.44435\n",
      "[8]\ttrain-rmse:1.05871\ttrain-hr_err:11.81273\ttest-rmse:0.85377\ttest-hr_err:56.44435\n",
      "[18:02:19] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:0.86393\ttrain-hr_err:38.95703\ttest-rmse:0.85397\ttest-hr_err:57.07963\n",
      "[5]\ttrain-rmse:0.86850\ttrain-hr_err:0.30750\ttest-rmse:0.85499\ttest-hr_err:37.40445\n",
      "[10]\ttrain-rmse:0.87306\ttrain-hr_err:0.23036\ttest-rmse:0.85604\ttest-hr_err:32.29087\n",
      "[15]\ttrain-rmse:0.87762\ttrain-hr_err:0.23036\ttest-rmse:0.85712\ttest-hr_err:31.91627\n",
      "[20]\ttrain-rmse:0.88215\ttrain-hr_err:0.23036\ttest-rmse:0.85916\ttest-hr_err:33.21429\n",
      "[24]\ttrain-rmse:0.88578\ttrain-hr_err:0.23036\ttest-rmse:0.86080\ttest-hr_err:34.90364\n",
      "\n",
      "\n",
      "Fine-tuning...\n",
      "[18:02:26] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:1.30510\ttrain-hr_err:0.23036\ttest-rmse:0.86209\ttest-hr_err:34.90364\n",
      "[5]\ttrain-rmse:1.31203\ttrain-hr_err:0.38480\ttest-rmse:0.86656\ttest-hr_err:38.86497\n",
      "[10]\ttrain-rmse:1.31899\ttrain-hr_err:0.38480\ttest-rmse:0.87093\ttest-hr_err:37.37220\n",
      "[18:02:30] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:0.99659\ttrain-hr_err:21.38815\ttest-rmse:0.87127\ttest-hr_err:37.38329\n",
      "[5]\ttrain-rmse:1.00116\ttrain-hr_err:16.88782\ttest-rmse:0.87297\ttest-hr_err:34.48769\n",
      "[10]\ttrain-rmse:1.00558\ttrain-hr_err:16.80618\ttest-rmse:0.87439\ttest-hr_err:27.02889\n",
      "[15]\ttrain-rmse:1.00997\ttrain-hr_err:16.80618\ttest-rmse:0.87578\ttest-hr_err:28.25621\n",
      "[20]\ttrain-rmse:1.01436\ttrain-hr_err:7.94805\ttest-rmse:0.87720\ttest-hr_err:26.75178\n",
      "[25]\ttrain-rmse:1.01876\ttrain-hr_err:7.94805\ttest-rmse:0.87865\ttest-hr_err:25.89026\n",
      "[30]\ttrain-rmse:1.02315\ttrain-hr_err:7.94805\ttest-rmse:0.88011\ttest-hr_err:28.47476\n",
      "[34]\ttrain-rmse:1.02666\ttrain-hr_err:7.94805\ttest-rmse:0.88130\ttest-hr_err:25.47258\n",
      "\n",
      "\n",
      "Fine-tuning...\n",
      "[18:02:39] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:1.44606\ttrain-hr_err:7.94805\ttest-rmse:0.88192\ttest-hr_err:25.47258\n",
      "[5]\ttrain-rmse:1.45314\ttrain-hr_err:7.85599\ttest-rmse:0.88543\ttest-hr_err:26.73079\n",
      "[9]\ttrain-rmse:1.45877\ttrain-hr_err:7.85599\ttest-rmse:0.88894\ttest-hr_err:26.73079\n",
      "[18:02:42] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:0.62026\ttrain-hr_err:40.81782\ttest-rmse:0.88958\ttest-hr_err:26.73079\n",
      "[5]\ttrain-rmse:0.62518\ttrain-hr_err:40.81782\ttest-rmse:0.89283\ttest-hr_err:26.73079\n",
      "[10]\ttrain-rmse:0.63014\ttrain-hr_err:40.81782\ttest-rmse:0.89612\ttest-hr_err:28.98828\n",
      "[15]\ttrain-rmse:0.63514\ttrain-hr_err:40.81782\ttest-rmse:0.89946\ttest-hr_err:29.00850\n",
      "[16]\ttrain-rmse:0.63615\ttrain-hr_err:40.81782\ttest-rmse:0.90014\ttest-hr_err:31.26600\n",
      "\n",
      "\n",
      "Fine-tuning...\n",
      "[18:02:47] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:1.22534\ttrain-hr_err:40.88150\ttest-rmse:0.90138\ttest-hr_err:31.26600\n",
      "[5]\ttrain-rmse:1.23457\ttrain-hr_err:40.88150\ttest-rmse:0.90762\ttest-hr_err:31.26600\n",
      "[7]\ttrain-rmse:1.23828\ttrain-hr_err:40.88150\ttest-rmse:0.91014\ttest-hr_err:31.26600\n",
      "[18:02:50] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:1.05845\ttrain-hr_err:9.40650\ttest-rmse:0.91161\ttest-hr_err:29.00850\n",
      "[5]\ttrain-rmse:1.06268\ttrain-hr_err:13.65404\ttest-rmse:0.91258\ttest-hr_err:30.64329\n",
      "[10]\ttrain-rmse:1.06692\ttrain-hr_err:9.04594\ttest-rmse:0.91355\ttest-hr_err:35.71937\n",
      "[15]\ttrain-rmse:1.07115\ttrain-hr_err:9.04594\ttest-rmse:0.91454\ttest-hr_err:35.96158\n",
      "[20]\ttrain-rmse:1.07539\ttrain-hr_err:8.95526\ttest-rmse:0.91557\ttest-hr_err:38.77929\n",
      "[24]\ttrain-rmse:1.07878\ttrain-hr_err:13.48357\ttest-rmse:0.91642\ttest-hr_err:36.42897\n",
      "\n",
      "\n",
      "Fine-tuning...\n",
      "[18:02:58] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:1.57004\ttrain-hr_err:13.38246\ttest-rmse:0.91752\ttest-hr_err:31.96510\n",
      "[5]\ttrain-rmse:1.57780\ttrain-hr_err:13.29692\ttest-rmse:0.92207\ttest-hr_err:33.58211\n",
      "[8]\ttrain-rmse:1.58248\ttrain-hr_err:13.29692\ttest-rmse:0.92489\ttest-hr_err:33.58211\n",
      "Finished training in 0:00:48.558399\n",
      "\n",
      "\n",
      "Training excluding subject 2...\n",
      "\n",
      "Rows per batch: 960\n",
      "[18:03:05] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:0.96961\ttrain-hr_err:16.36349\ttest-rmse:0.81164\ttest-hr_err:18.74599\n",
      "[5]\ttrain-rmse:0.97357\ttrain-hr_err:16.36349\ttest-rmse:0.81308\ttest-hr_err:18.74599\n",
      "[10]\ttrain-rmse:0.97755\ttrain-hr_err:16.36349\ttest-rmse:0.81457\ttest-hr_err:18.74599\n",
      "[15]\ttrain-rmse:0.98152\ttrain-hr_err:16.36349\ttest-rmse:0.81610\ttest-hr_err:18.74599\n",
      "\n",
      "\n",
      "Fine-tuning...\n",
      "[18:03:09] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:1.33523\ttrain-hr_err:16.36349\ttest-rmse:0.81710\ttest-hr_err:20.19317\n",
      "[5]\ttrain-rmse:1.34162\ttrain-hr_err:12.00145\ttest-rmse:0.82061\ttest-hr_err:18.74109\n",
      "[10]\ttrain-rmse:1.34804\ttrain-hr_err:12.00145\ttest-rmse:0.82422\ttest-hr_err:20.16846\n",
      "[15]\ttrain-rmse:1.35448\ttrain-hr_err:12.00145\ttest-rmse:0.82797\ttest-hr_err:18.55758\n",
      "[19]\ttrain-rmse:1.35966\ttrain-hr_err:12.17594\ttest-rmse:0.83106\ttest-hr_err:21.74661\n",
      "[18:03:15] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:0.98227\ttrain-hr_err:41.94040\ttest-rmse:0.83231\ttest-hr_err:21.72344\n",
      "[5]\ttrain-rmse:0.98696\ttrain-hr_err:33.35058\ttest-rmse:0.83465\ttest-hr_err:15.77525\n",
      "[10]\ttrain-rmse:0.99166\ttrain-hr_err:29.20196\ttest-rmse:0.83703\ttest-hr_err:12.78957\n",
      "[15]\ttrain-rmse:0.99635\ttrain-hr_err:16.33600\ttest-rmse:0.83945\ttest-hr_err:17.37064\n",
      "[20]\ttrain-rmse:1.00105\ttrain-hr_err:11.90466\ttest-rmse:0.84190\ttest-hr_err:18.04617\n",
      "[25]\ttrain-rmse:1.00574\ttrain-hr_err:7.35546\ttest-rmse:0.84434\ttest-hr_err:22.60201\n",
      "[27]\ttrain-rmse:1.00761\ttrain-hr_err:7.35546\ttest-rmse:0.84532\ttest-hr_err:21.13074\n",
      "\n",
      "\n",
      "Fine-tuning...\n",
      "[18:03:23] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:1.41221\ttrain-hr_err:7.35546\ttest-rmse:0.84626\ttest-hr_err:21.13074\n",
      "[5]\ttrain-rmse:1.41919\ttrain-hr_err:3.19511\ttest-rmse:0.85101\ttest-hr_err:22.08846\n",
      "[10]\ttrain-rmse:1.42618\ttrain-hr_err:3.19511\ttest-rmse:0.85570\ttest-hr_err:20.62463\n",
      "[15]\ttrain-rmse:1.43318\ttrain-hr_err:3.31218\ttest-rmse:0.86037\ttest-hr_err:21.46160\n",
      "[18:03:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:0.60744\ttrain-hr_err:5.10784\ttest-rmse:0.86081\ttest-hr_err:21.46160\n",
      "[5]\ttrain-rmse:0.61238\ttrain-hr_err:5.10784\ttest-rmse:0.86313\ttest-hr_err:21.46160\n",
      "[10]\ttrain-rmse:0.61735\ttrain-hr_err:0.87877\ttest-rmse:0.86551\ttest-hr_err:21.46160\n",
      "[15]\ttrain-rmse:0.62236\ttrain-hr_err:0.87877\ttest-rmse:0.86793\ttest-hr_err:24.45926\n",
      "\n",
      "\n",
      "Fine-tuning...\n",
      "[18:03:34] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:1.20952\ttrain-hr_err:0.46318\ttest-rmse:0.86975\ttest-hr_err:24.45926\n",
      "[5]\ttrain-rmse:1.21874\ttrain-hr_err:0.46318\ttest-rmse:0.87645\ttest-hr_err:24.45926\n",
      "[8]\ttrain-rmse:1.22429\ttrain-hr_err:0.46318\ttest-rmse:0.88053\ttest-hr_err:24.45926\n",
      "[18:03:37] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:0.58390\ttrain-hr_err:11.78749\ttest-rmse:0.88118\ttest-hr_err:24.45926\n",
      "[5]\ttrain-rmse:0.58852\ttrain-hr_err:11.78749\ttest-rmse:0.88447\ttest-hr_err:24.45926\n",
      "[10]\ttrain-rmse:0.59318\ttrain-hr_err:11.78749\ttest-rmse:0.88780\ttest-hr_err:24.45926\n",
      "[15]\ttrain-rmse:0.59788\ttrain-hr_err:11.78749\ttest-rmse:0.89116\ttest-hr_err:24.48973\n",
      "[18]\ttrain-rmse:0.60072\ttrain-hr_err:7.42385\ttest-rmse:0.89321\ttest-hr_err:24.48973\n",
      "\n",
      "\n",
      "Fine-tuning...\n",
      "[18:03:43] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:1.18586\ttrain-hr_err:7.42385\ttest-rmse:0.89517\ttest-hr_err:24.48973\n",
      "[5]\ttrain-rmse:1.19481\ttrain-hr_err:7.42385\ttest-rmse:0.90159\ttest-hr_err:24.48973\n",
      "[7]\ttrain-rmse:1.19840\ttrain-hr_err:7.42385\ttest-rmse:0.90419\ttest-hr_err:24.48973\n",
      "[18:03:46] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:0.91311\ttrain-hr_err:23.04640\ttest-rmse:0.90594\ttest-hr_err:24.48973\n",
      "[5]\ttrain-rmse:0.91755\ttrain-hr_err:24.81492\ttest-rmse:0.90819\ttest-hr_err:24.20337\n",
      "[10]\ttrain-rmse:0.92198\ttrain-hr_err:29.09586\ttest-rmse:0.91051\ttest-hr_err:24.68581\n",
      "[15]\ttrain-rmse:0.92645\ttrain-hr_err:29.09586\ttest-rmse:0.91282\ttest-hr_err:24.69654\n",
      "[20]\ttrain-rmse:0.93096\ttrain-hr_err:29.09586\ttest-rmse:0.91517\ttest-hr_err:23.13557\n",
      "[25]\ttrain-rmse:0.93547\ttrain-hr_err:24.81492\ttest-rmse:0.91759\ttest-hr_err:21.70199\n",
      "[30]\ttrain-rmse:0.94001\ttrain-hr_err:11.97211\ttest-rmse:0.92012\ttest-hr_err:19.92076\n",
      "[35]\ttrain-rmse:0.94455\ttrain-hr_err:3.41024\ttest-rmse:0.92266\ttest-hr_err:15.41930\n",
      "[40]\ttrain-rmse:0.94910\ttrain-hr_err:3.56330\ttest-rmse:0.92524\ttest-hr_err:13.87899\n",
      "[45]\ttrain-rmse:0.95366\ttrain-hr_err:3.56330\ttest-rmse:0.92786\ttest-hr_err:13.96980\n",
      "[50]\ttrain-rmse:0.95822\ttrain-hr_err:0.72720\ttest-rmse:0.93050\ttest-hr_err:14.00320\n",
      "[55]\ttrain-rmse:0.96285\ttrain-hr_err:3.56330\ttest-rmse:0.93323\ttest-hr_err:15.52139\n",
      "[56]\ttrain-rmse:0.96377\ttrain-hr_err:3.56330\ttest-rmse:0.93378\ttest-hr_err:15.52139\n",
      "\n",
      "\n",
      "Fine-tuning...\n",
      "[18:04:04] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:1.53166\ttrain-hr_err:0.72720\ttest-rmse:0.93566\ttest-hr_err:13.97736\n",
      "[5]\ttrain-rmse:1.53969\ttrain-hr_err:0.72720\ttest-rmse:0.94244\ttest-hr_err:14.06353\n",
      "[10]\ttrain-rmse:1.54780\ttrain-hr_err:0.72720\ttest-rmse:0.94887\ttest-hr_err:12.51950\n",
      "[15]\ttrain-rmse:1.55592\ttrain-hr_err:0.65522\ttest-rmse:0.95538\ttest-hr_err:12.51950\n",
      "[20]\ttrain-rmse:1.56409\ttrain-hr_err:0.65522\ttest-rmse:0.96196\ttest-hr_err:11.00530\n",
      "[21]\ttrain-rmse:1.56573\ttrain-hr_err:0.65522\ttest-rmse:0.96326\ttest-hr_err:11.00530\n",
      "Finished training in 0:01:05.794801\n",
      "\n",
      "\n",
      "Training excluding subject 2...\n",
      "\n",
      "Rows per batch: 960\n",
      "[18:04:14] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:0.60446\ttrain-hr_err:21.06939\ttest-rmse:0.79463\ttest-hr_err:21.88568\n",
      "[5]\ttrain-rmse:0.60838\ttrain-hr_err:21.06939\ttest-rmse:0.79635\ttest-hr_err:21.88568\n",
      "[10]\ttrain-rmse:0.61233\ttrain-hr_err:21.06939\ttest-rmse:0.79810\ttest-hr_err:21.88568\n",
      "[15]\ttrain-rmse:0.61631\ttrain-hr_err:21.06939\ttest-rmse:0.79988\ttest-hr_err:21.88568\n",
      "[20]\ttrain-rmse:0.62031\ttrain-hr_err:21.06939\ttest-rmse:0.80176\ttest-hr_err:20.44934\n",
      "[21]\ttrain-rmse:0.62114\ttrain-hr_err:21.06939\ttest-rmse:0.80217\ttest-hr_err:24.85955\n",
      "\n",
      "\n",
      "Fine-tuning...\n",
      "[18:04:20] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:1.08554\ttrain-hr_err:15.93737\ttest-rmse:0.80354\ttest-hr_err:24.85955\n",
      "[5]\ttrain-rmse:1.09296\ttrain-hr_err:27.52092\ttest-rmse:0.80831\ttest-hr_err:24.85955\n",
      "[8]\ttrain-rmse:1.09743\ttrain-hr_err:27.52092\ttest-rmse:0.81121\ttest-hr_err:24.85955\n",
      "[18:04:23] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:0.56666\ttrain-hr_err:34.72599\ttest-rmse:0.81178\ttest-hr_err:24.85955\n",
      "[5]\ttrain-rmse:0.57116\ttrain-hr_err:43.14704\ttest-rmse:0.81463\ttest-hr_err:29.22067\n",
      "[10]\ttrain-rmse:0.57569\ttrain-hr_err:38.83967\ttest-rmse:0.81751\ttest-hr_err:30.70731\n",
      "[15]\ttrain-rmse:0.58026\ttrain-hr_err:34.63376\ttest-rmse:0.82042\ttest-hr_err:28.81488\n",
      "[18]\ttrain-rmse:0.58302\ttrain-hr_err:34.63376\ttest-rmse:0.82218\ttest-hr_err:27.32824\n",
      "\n",
      "\n",
      "Fine-tuning...\n",
      "[18:04:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:1.11479\ttrain-hr_err:34.56990\ttest-rmse:0.82329\ttest-hr_err:27.32824\n",
      "[5]\ttrain-rmse:1.12342\ttrain-hr_err:34.56990\ttest-rmse:0.82887\ttest-hr_err:27.32824\n",
      "[7]\ttrain-rmse:1.12688\ttrain-hr_err:34.56990\ttest-rmse:0.83113\ttest-hr_err:27.32824\n",
      "[18:04:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:0.99200\ttrain-hr_err:65.14041\ttest-rmse:0.83266\ttest-hr_err:31.74583\n",
      "[5]\ttrain-rmse:0.99664\ttrain-hr_err:48.71995\ttest-rmse:0.83467\ttest-hr_err:29.63971\n",
      "[10]\ttrain-rmse:1.00127\ttrain-hr_err:26.26938\ttest-rmse:0.83671\ttest-hr_err:12.49006\n",
      "[15]\ttrain-rmse:1.00588\ttrain-hr_err:16.84445\ttest-rmse:0.83894\ttest-hr_err:6.60722\n",
      "[20]\ttrain-rmse:1.01049\ttrain-hr_err:12.63197\ttest-rmse:0.84121\ttest-hr_err:6.99848\n",
      "[25]\ttrain-rmse:1.01507\ttrain-hr_err:12.52621\ttest-rmse:0.84351\ttest-hr_err:11.39352\n",
      "[30]\ttrain-rmse:1.01966\ttrain-hr_err:12.52621\ttest-rmse:0.84585\ttest-hr_err:11.36488\n",
      "[33]\ttrain-rmse:1.02241\ttrain-hr_err:8.41046\ttest-rmse:0.84727\ttest-hr_err:10.04912\n",
      "\n",
      "\n",
      "Fine-tuning...\n",
      "[18:04:40] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:1.45993\ttrain-hr_err:8.41046\ttest-rmse:0.84861\ttest-hr_err:12.16887\n",
      "[5]\ttrain-rmse:1.46719\ttrain-hr_err:8.41046\ttest-rmse:0.85296\ttest-hr_err:11.97611\n",
      "[8]\ttrain-rmse:1.47156\ttrain-hr_err:8.30006\ttest-rmse:0.85561\ttest-hr_err:12.48433\n",
      "[18:04:43] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:1.02493\ttrain-hr_err:18.02934\ttest-rmse:0.85674\ttest-hr_err:13.99399\n",
      "[5]\ttrain-rmse:1.02924\ttrain-hr_err:22.58217\ttest-rmse:0.85800\ttest-hr_err:13.18090\n",
      "[10]\ttrain-rmse:1.03356\ttrain-hr_err:18.02934\ttest-rmse:0.85934\ttest-hr_err:13.46169\n",
      "[15]\ttrain-rmse:1.03790\ttrain-hr_err:18.02934\ttest-rmse:0.86072\ttest-hr_err:9.34152\n",
      "[20]\ttrain-rmse:1.04224\ttrain-hr_err:20.16380\ttest-rmse:0.86217\ttest-hr_err:8.00477\n",
      "[25]\ttrain-rmse:1.04660\ttrain-hr_err:6.55304\ttest-rmse:0.86366\ttest-hr_err:8.85383\n",
      "[30]\ttrain-rmse:1.05096\ttrain-hr_err:6.55304\ttest-rmse:0.86518\ttest-hr_err:8.19053\n",
      "[35]\ttrain-rmse:1.05534\ttrain-hr_err:10.70525\ttest-rmse:0.86669\ttest-hr_err:8.78991\n",
      "[40]\ttrain-rmse:1.05973\ttrain-hr_err:10.70525\ttest-rmse:0.86821\ttest-hr_err:8.78991\n",
      "[45]\ttrain-rmse:1.06412\ttrain-hr_err:2.32097\ttest-rmse:0.86979\ttest-hr_err:6.84849\n",
      "[50]\ttrain-rmse:1.06851\ttrain-hr_err:2.32097\ttest-rmse:0.87130\ttest-hr_err:6.87892\n",
      "[55]\ttrain-rmse:1.07290\ttrain-hr_err:2.32097\ttest-rmse:0.87268\ttest-hr_err:5.40257\n",
      "[60]\ttrain-rmse:1.07728\ttrain-hr_err:2.32097\ttest-rmse:0.87414\ttest-hr_err:7.13230\n",
      "[65]\ttrain-rmse:1.08167\ttrain-hr_err:2.32097\ttest-rmse:0.87565\ttest-hr_err:8.51417\n",
      "[70]\ttrain-rmse:1.08606\ttrain-hr_err:2.32097\ttest-rmse:0.87719\ttest-hr_err:8.84210\n",
      "\n",
      "\n",
      "Fine-tuning...\n",
      "[18:05:02] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:1.60579\ttrain-hr_err:2.43603\ttest-rmse:0.87855\ttest-hr_err:8.89324\n",
      "[5]\ttrain-rmse:1.61341\ttrain-hr_err:2.43603\ttest-rmse:0.88382\ttest-hr_err:9.53017\n",
      "[10]\ttrain-rmse:1.62106\ttrain-hr_err:2.43603\ttest-rmse:0.88928\ttest-hr_err:7.69372\n",
      "[13]\ttrain-rmse:1.62567\ttrain-hr_err:2.43603\ttest-rmse:0.89245\ttest-hr_err:8.42771\n",
      "[18:05:06] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:0.64187\ttrain-hr_err:20.80472\ttest-rmse:0.89409\ttest-hr_err:10.02656\n",
      "[5]\ttrain-rmse:0.64707\ttrain-hr_err:20.80472\ttest-rmse:0.89714\ttest-hr_err:9.53017\n",
      "[10]\ttrain-rmse:0.65231\ttrain-hr_err:20.80472\ttest-rmse:0.90023\ttest-hr_err:9.53017\n",
      "[15]\ttrain-rmse:0.65760\ttrain-hr_err:20.80472\ttest-rmse:0.90337\ttest-hr_err:9.55648\n",
      "[17]\ttrain-rmse:0.65972\ttrain-hr_err:20.80472\ttest-rmse:0.90464\ttest-hr_err:9.55648\n",
      "\n",
      "\n",
      "Fine-tuning...\n",
      "[18:05:11] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:1.28472\ttrain-hr_err:20.56808\ttest-rmse:0.90608\ttest-hr_err:9.55648\n",
      "[5]\ttrain-rmse:1.29430\ttrain-hr_err:20.56808\ttest-rmse:0.91333\ttest-hr_err:9.55648\n",
      "[7]\ttrain-rmse:1.29814\ttrain-hr_err:20.56808\ttest-rmse:0.91626\ttest-hr_err:9.58199\n",
      "Finished training in 0:00:59.291856\n",
      "\n",
      "\n",
      "Training excluding subject 2...\n",
      "\n",
      "Rows per batch: 960\n",
      "[18:05:17] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:0.50479\ttrain-hr_err:50.88567\ttest-rmse:0.85207\ttest-hr_err:38.50131\n",
      "[5]\ttrain-rmse:0.50872\ttrain-hr_err:50.88567\ttest-rmse:0.85414\ttest-hr_err:34.90769\n",
      "[10]\ttrain-rmse:0.51268\ttrain-hr_err:42.15361\ttest-rmse:0.85626\ttest-hr_err:35.74873\n",
      "[15]\ttrain-rmse:0.51668\ttrain-hr_err:42.15361\ttest-rmse:0.85842\ttest-hr_err:41.99263\n",
      "[20]\ttrain-rmse:0.52072\ttrain-hr_err:42.15361\ttest-rmse:0.86060\ttest-hr_err:41.99263\n",
      "[21]\ttrain-rmse:0.52153\ttrain-hr_err:42.15361\ttest-rmse:0.86105\ttest-hr_err:41.99263\n",
      "\n",
      "\n",
      "Fine-tuning...\n",
      "[18:05:23] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:1.02050\ttrain-hr_err:42.15361\ttest-rmse:0.86248\ttest-hr_err:42.01679\n",
      "[5]\ttrain-rmse:1.02849\ttrain-hr_err:42.15361\ttest-rmse:0.86747\ttest-hr_err:42.01679\n",
      "[8]\ttrain-rmse:1.03330\ttrain-hr_err:42.15361\ttest-rmse:0.87051\ttest-hr_err:42.01679\n",
      "[18:05:25] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:0.63155\ttrain-hr_err:24.97646\ttest-rmse:0.87091\ttest-hr_err:35.09787\n",
      "[5]\ttrain-rmse:0.63569\ttrain-hr_err:26.78211\ttest-rmse:0.87293\ttest-hr_err:42.04126\n",
      "[10]\ttrain-rmse:0.63986\ttrain-hr_err:26.82612\ttest-rmse:0.87498\ttest-hr_err:43.89097\n",
      "[15]\ttrain-rmse:0.64406\ttrain-hr_err:21.01674\ttest-rmse:0.87706\ttest-hr_err:43.92092\n",
      "[16]\ttrain-rmse:0.64490\ttrain-hr_err:21.01674\ttest-rmse:0.87748\ttest-hr_err:43.92092\n",
      "\n",
      "\n",
      "Fine-tuning...\n",
      "[18:05:30] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:1.14072\ttrain-hr_err:21.01674\ttest-rmse:0.87848\ttest-hr_err:43.92092\n",
      "[5]\ttrain-rmse:1.14841\ttrain-hr_err:32.60029\ttest-rmse:0.88350\ttest-hr_err:43.92092\n",
      "[8]\ttrain-rmse:1.15304\ttrain-hr_err:38.41847\ttest-rmse:0.88655\ttest-hr_err:43.92092\n",
      "[18:05:33] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:0.85776\ttrain-hr_err:18.04688\ttest-rmse:0.88690\ttest-hr_err:31.82194\n",
      "[5]\ttrain-rmse:0.86194\ttrain-hr_err:1.01356\ttest-rmse:0.88871\ttest-hr_err:23.87282\n",
      "[10]\ttrain-rmse:0.86613\ttrain-hr_err:5.41771\ttest-rmse:0.89055\ttest-hr_err:19.78494\n",
      "[15]\ttrain-rmse:0.87031\ttrain-hr_err:1.29737\ttest-rmse:0.89239\ttest-hr_err:21.58861\n",
      "[20]\ttrain-rmse:0.87451\ttrain-hr_err:0.71697\ttest-rmse:0.89426\ttest-hr_err:24.45678\n",
      "[25]\ttrain-rmse:0.87883\ttrain-hr_err:0.00000\ttest-rmse:0.89585\ttest-hr_err:28.77204\n",
      "\n",
      "\n",
      "Fine-tuning...\n",
      "[18:05:40] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:1.32500\ttrain-hr_err:0.07870\ttest-rmse:0.89679\ttest-hr_err:28.74860\n",
      "[5]\ttrain-rmse:1.33211\ttrain-hr_err:0.07870\ttest-rmse:0.90149\ttest-hr_err:34.86715\n",
      "[7]\ttrain-rmse:1.33496\ttrain-hr_err:0.07870\ttest-rmse:0.90338\ttest-hr_err:36.08792\n",
      "[18:05:42] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:1.01247\ttrain-hr_err:14.15116\ttest-rmse:0.90501\ttest-hr_err:37.69045\n",
      "[5]\ttrain-rmse:1.01699\ttrain-hr_err:9.73401\ttest-rmse:0.90826\ttest-hr_err:31.21771\n",
      "[10]\ttrain-rmse:1.02151\ttrain-hr_err:5.39992\ttest-rmse:0.91154\ttest-hr_err:33.06981\n",
      "[15]\ttrain-rmse:1.02602\ttrain-hr_err:5.21361\ttest-rmse:0.91497\ttest-hr_err:28.90261\n",
      "[20]\ttrain-rmse:1.02997\ttrain-hr_err:3.59530\ttest-rmse:0.91798\ttest-hr_err:24.73145\n",
      "[25]\ttrain-rmse:1.03394\ttrain-hr_err:3.59530\ttest-rmse:0.92107\ttest-hr_err:27.42082\n",
      "[30]\ttrain-rmse:1.03791\ttrain-hr_err:8.02437\ttest-rmse:0.92418\ttest-hr_err:28.89743\n",
      "[35]\ttrain-rmse:1.04207\ttrain-hr_err:8.02437\ttest-rmse:0.92724\ttest-hr_err:28.33549\n",
      "[36]\ttrain-rmse:1.04297\ttrain-hr_err:8.02437\ttest-rmse:0.92795\ttest-hr_err:28.33549\n",
      "\n",
      "\n",
      "Fine-tuning...\n",
      "[18:05:52] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:1.50072\ttrain-hr_err:7.92899\ttest-rmse:0.92914\ttest-hr_err:28.33549\n",
      "[5]\ttrain-rmse:1.50787\ttrain-hr_err:7.92899\ttest-rmse:0.93512\ttest-hr_err:24.70051\n",
      "[10]\ttrain-rmse:1.51506\ttrain-hr_err:7.92899\ttest-rmse:0.94118\ttest-hr_err:23.30770\n",
      "[15]\ttrain-rmse:1.52230\ttrain-hr_err:7.92899\ttest-rmse:0.94733\ttest-hr_err:23.93787\n",
      "[18:05:57] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:0.66496\ttrain-hr_err:15.60998\ttest-rmse:0.94804\ttest-hr_err:23.93787\n",
      "[5]\ttrain-rmse:0.67023\ttrain-hr_err:15.60998\ttest-rmse:0.95164\ttest-hr_err:23.93787\n",
      "[10]\ttrain-rmse:0.67554\ttrain-hr_err:15.60998\ttest-rmse:0.95528\ttest-hr_err:23.93787\n",
      "[15]\ttrain-rmse:0.68090\ttrain-hr_err:15.60998\ttest-rmse:0.95902\ttest-hr_err:23.93787\n",
      "\n",
      "\n",
      "Fine-tuning...\n",
      "[18:06:02] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:1.32279\ttrain-hr_err:15.80105\ttest-rmse:0.96116\ttest-hr_err:23.93787\n",
      "[5]\ttrain-rmse:1.33248\ttrain-hr_err:15.80105\ttest-rmse:0.96813\ttest-hr_err:23.93787\n",
      "[8]\ttrain-rmse:1.33832\ttrain-hr_err:15.80105\ttest-rmse:0.97236\ttest-hr_err:23.93787\n",
      "Finished training in 0:00:47.709475\n",
      "\n",
      "\n",
      "Training excluding subject 3...\n",
      "\n",
      "Rows per batch: 960\n",
      "[18:06:09] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:0.83842\ttrain-hr_err:1.33969\ttest-rmse:0.84243\ttest-hr_err:51.84951\n",
      "[5]\ttrain-rmse:0.84274\ttrain-hr_err:0.13351\ttest-rmse:0.84388\ttest-hr_err:51.46511\n",
      "[10]\ttrain-rmse:0.84705\ttrain-hr_err:0.20317\ttest-rmse:0.84540\ttest-hr_err:51.44119\n",
      "[15]\ttrain-rmse:0.85134\ttrain-hr_err:0.20317\ttest-rmse:0.84691\ttest-hr_err:50.02994\n",
      "[18]\ttrain-rmse:0.85392\ttrain-hr_err:0.20317\ttest-rmse:0.84783\ttest-hr_err:53.53200\n",
      "\n",
      "\n",
      "Fine-tuning...\n",
      "[18:06:14] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:1.22976\ttrain-hr_err:0.20317\ttest-rmse:0.84864\ttest-hr_err:48.95848\n",
      "[5]\ttrain-rmse:1.23602\ttrain-hr_err:0.27299\ttest-rmse:0.85275\ttest-hr_err:49.55205\n",
      "[10]\ttrain-rmse:1.24231\ttrain-hr_err:0.27299\ttest-rmse:0.85694\ttest-hr_err:41.14101\n",
      "[15]\ttrain-rmse:1.24863\ttrain-hr_err:9.07118\ttest-rmse:0.86116\ttest-hr_err:37.39729\n",
      "[20]\ttrain-rmse:1.25499\ttrain-hr_err:13.79442\ttest-rmse:0.86538\ttest-hr_err:33.70580\n",
      "[25]\ttrain-rmse:1.26138\ttrain-hr_err:13.73625\ttest-rmse:0.86958\ttest-hr_err:32.94739\n",
      "[30]\ttrain-rmse:1.26780\ttrain-hr_err:5.99505\ttest-rmse:0.87350\ttest-hr_err:28.73503\n",
      "[35]\ttrain-rmse:1.27425\ttrain-hr_err:12.03168\ttest-rmse:0.87749\ttest-hr_err:29.72357\n",
      "[18:06:26] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:0.60388\ttrain-hr_err:7.15600\ttest-rmse:0.87885\ttest-hr_err:29.72357\n",
      "[5]\ttrain-rmse:0.60884\ttrain-hr_err:7.15072\ttest-rmse:0.88164\ttest-hr_err:29.69948\n",
      "[10]\ttrain-rmse:0.61385\ttrain-hr_err:2.34538\ttest-rmse:0.88449\ttest-hr_err:29.67410\n",
      "[15]\ttrain-rmse:0.61889\ttrain-hr_err:2.34538\ttest-rmse:0.88738\ttest-hr_err:30.33029\n",
      "[20]\ttrain-rmse:0.62398\ttrain-hr_err:4.15097\ttest-rmse:0.89031\ttest-hr_err:31.86139\n",
      "[25]\ttrain-rmse:0.62910\ttrain-hr_err:4.27793\ttest-rmse:0.89328\ttest-hr_err:31.86139\n",
      "[26]\ttrain-rmse:0.63013\ttrain-hr_err:0.23441\ttest-rmse:0.89388\ttest-hr_err:31.86139\n",
      "\n",
      "\n",
      "Fine-tuning...\n",
      "[18:06:34] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:1.22186\ttrain-hr_err:0.23441\ttest-rmse:0.89513\ttest-hr_err:31.86139\n",
      "[5]\ttrain-rmse:1.23118\ttrain-hr_err:0.23441\ttest-rmse:0.90140\ttest-hr_err:31.86139\n",
      "[7]\ttrain-rmse:1.23492\ttrain-hr_err:0.23441\ttest-rmse:0.90394\ttest-hr_err:31.86139\n",
      "[18:06:37] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:0.90263\ttrain-hr_err:8.31659\ttest-rmse:0.90545\ttest-hr_err:33.39249\n",
      "[5]\ttrain-rmse:0.90720\ttrain-hr_err:2.09549\ttest-rmse:0.90782\ttest-hr_err:36.60316\n",
      "[10]\ttrain-rmse:0.91174\ttrain-hr_err:2.29308\ttest-rmse:0.91054\ttest-hr_err:31.94483\n",
      "[15]\ttrain-rmse:0.91607\ttrain-hr_err:6.60651\ttest-rmse:0.91342\ttest-hr_err:33.29297\n",
      "[20]\ttrain-rmse:0.92041\ttrain-hr_err:6.60651\ttest-rmse:0.91634\ttest-hr_err:30.76623\n",
      "[25]\ttrain-rmse:0.92475\ttrain-hr_err:2.22294\ttest-rmse:0.91911\ttest-hr_err:32.89489\n",
      "[30]\ttrain-rmse:0.92911\ttrain-hr_err:2.15297\ttest-rmse:0.92181\ttest-hr_err:36.39755\n",
      "[35]\ttrain-rmse:0.93343\ttrain-hr_err:2.15297\ttest-rmse:0.92465\ttest-hr_err:36.16046\n",
      "\n",
      "\n",
      "Fine-tuning...\n",
      "[18:06:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:1.42126\ttrain-hr_err:2.15297\ttest-rmse:0.92573\ttest-hr_err:37.72334\n",
      "[5]\ttrain-rmse:1.42893\ttrain-hr_err:2.15297\ttest-rmse:0.93119\ttest-hr_err:37.69917\n",
      "[10]\ttrain-rmse:1.43664\ttrain-hr_err:2.15297\ttest-rmse:0.93674\ttest-hr_err:36.09516\n",
      "[15]\ttrain-rmse:1.44441\ttrain-hr_err:2.15297\ttest-rmse:0.94238\ttest-hr_err:36.09516\n",
      "[16]\ttrain-rmse:1.44597\ttrain-hr_err:2.15297\ttest-rmse:0.94351\ttest-hr_err:36.09516\n",
      "[18:06:53] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:1.05119\ttrain-hr_err:14.51018\ttest-rmse:0.94379\ttest-hr_err:36.09516\n",
      "[5]\ttrain-rmse:1.05541\ttrain-hr_err:8.65734\ttest-rmse:0.94532\ttest-hr_err:33.31255\n",
      "[10]\ttrain-rmse:1.05968\ttrain-hr_err:13.41969\ttest-rmse:0.94724\ttest-hr_err:35.36840\n",
      "[15]\ttrain-rmse:1.06399\ttrain-hr_err:13.51029\ttest-rmse:0.94917\ttest-hr_err:32.41270\n",
      "[20]\ttrain-rmse:1.06822\ttrain-hr_err:13.60067\ttest-rmse:0.95094\ttest-hr_err:32.26989\n",
      "[25]\ttrain-rmse:1.07214\ttrain-hr_err:18.33974\ttest-rmse:0.95184\ttest-hr_err:29.45700\n",
      "[30]\ttrain-rmse:1.07608\ttrain-hr_err:18.33974\ttest-rmse:0.95280\ttest-hr_err:29.97958\n",
      "[35]\ttrain-rmse:1.08011\ttrain-hr_err:21.17444\ttest-rmse:0.95403\ttest-hr_err:28.70025\n",
      "[40]\ttrain-rmse:1.08448\ttrain-hr_err:21.25205\ttest-rmse:0.95629\ttest-hr_err:30.54147\n",
      "[45]\ttrain-rmse:1.08887\ttrain-hr_err:21.32948\ttest-rmse:0.95863\ttest-hr_err:25.65870\n",
      "[50]\ttrain-rmse:1.09326\ttrain-hr_err:21.32948\ttest-rmse:0.96097\ttest-hr_err:25.84551\n",
      "[55]\ttrain-rmse:1.09765\ttrain-hr_err:21.32948\ttest-rmse:0.96326\ttest-hr_err:27.91244\n",
      "[60]\ttrain-rmse:1.10203\ttrain-hr_err:21.40673\ttest-rmse:0.96618\ttest-hr_err:29.36643\n",
      "[61]\ttrain-rmse:1.10291\ttrain-hr_err:21.40673\ttest-rmse:0.96681\ttest-hr_err:29.36643\n",
      "\n",
      "\n",
      "Fine-tuning...\n",
      "[18:07:13] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:1.65973\ttrain-hr_err:21.40673\ttest-rmse:0.96813\ttest-hr_err:29.36643\n",
      "[5]\ttrain-rmse:1.66801\ttrain-hr_err:21.40673\ttest-rmse:0.97500\ttest-hr_err:28.03602\n",
      "[10]\ttrain-rmse:1.67633\ttrain-hr_err:21.32948\ttest-rmse:0.98216\ttest-hr_err:27.97737\n",
      "[15]\ttrain-rmse:1.68468\ttrain-hr_err:21.32948\ttest-rmse:0.98897\ttest-hr_err:27.94831\n",
      "[19]\ttrain-rmse:1.69139\ttrain-hr_err:21.32948\ttest-rmse:0.99396\ttest-hr_err:29.95275\n",
      "[18:07:20] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:1.12146\ttrain-hr_err:6.25539\ttest-rmse:0.99622\ttest-hr_err:29.95275\n",
      "[5]\ttrain-rmse:1.12637\ttrain-hr_err:10.44753\ttest-rmse:1.00133\ttest-hr_err:29.79101\n",
      "[10]\ttrain-rmse:1.13130\ttrain-hr_err:6.34225\ttest-rmse:1.00652\ttest-hr_err:33.42062\n",
      "[15]\ttrain-rmse:1.13616\ttrain-hr_err:2.15468\ttest-rmse:1.01148\ttest-hr_err:29.08438\n",
      "[20]\ttrain-rmse:1.14102\ttrain-hr_err:2.24591\ttest-rmse:1.01633\ttest-hr_err:29.08438\n",
      "[25]\ttrain-rmse:1.14600\ttrain-hr_err:6.42892\ttest-rmse:1.01922\ttest-hr_err:32.38417\n",
      "[30]\ttrain-rmse:1.15101\ttrain-hr_err:1.93710\ttest-rmse:1.02168\ttest-hr_err:35.37476\n",
      "[35]\ttrain-rmse:1.15602\ttrain-hr_err:1.93710\ttest-rmse:1.02401\ttest-hr_err:32.42980\n",
      "[36]\ttrain-rmse:1.15702\ttrain-hr_err:1.93710\ttest-rmse:1.02456\ttest-hr_err:32.42980\n",
      "\n",
      "\n",
      "Fine-tuning...\n",
      "[18:07:32] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:1.77361\ttrain-hr_err:1.93710\ttest-rmse:1.02688\ttest-hr_err:34.07082\n",
      "[5]\ttrain-rmse:1.78270\ttrain-hr_err:1.93710\ttest-rmse:1.03580\ttest-hr_err:33.93171\n",
      "[9]\ttrain-rmse:1.79000\ttrain-hr_err:1.93710\ttest-rmse:1.04303\ttest-hr_err:35.40636\n",
      "Finished training in 0:01:25.702507\n",
      "\n",
      "\n",
      "Training excluding subject 3...\n",
      "\n",
      "Rows per batch: 960\n",
      "[18:07:38] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:0.95886\ttrain-hr_err:21.38291\ttest-rmse:0.93135\ttest-hr_err:26.24897\n",
      "[5]\ttrain-rmse:0.96225\ttrain-hr_err:21.38291\ttest-rmse:0.93193\ttest-hr_err:26.24897\n",
      "[10]\ttrain-rmse:0.96565\ttrain-hr_err:21.38291\ttest-rmse:0.93254\ttest-hr_err:26.24897\n",
      "[15]\ttrain-rmse:0.96908\ttrain-hr_err:21.38291\ttest-rmse:0.93312\ttest-hr_err:27.82953\n",
      "[20]\ttrain-rmse:0.97281\ttrain-hr_err:25.89399\ttest-rmse:0.93430\ttest-hr_err:24.92901\n",
      "[25]\ttrain-rmse:0.97662\ttrain-hr_err:25.82222\ttest-rmse:0.93562\ttest-hr_err:20.78025\n",
      "[30]\ttrain-rmse:0.98049\ttrain-hr_err:16.94361\ttest-rmse:0.93703\ttest-hr_err:15.28328\n",
      "[35]\ttrain-rmse:0.98456\ttrain-hr_err:12.50430\ttest-rmse:0.93867\ttest-hr_err:11.18920\n",
      "[40]\ttrain-rmse:0.98863\ttrain-hr_err:8.06499\ttest-rmse:0.94033\ttest-hr_err:9.68866\n",
      "[45]\ttrain-rmse:0.99270\ttrain-hr_err:3.62569\ttest-rmse:0.94202\ttest-hr_err:9.02806\n",
      "[50]\ttrain-rmse:0.99665\ttrain-hr_err:3.62569\ttest-rmse:0.94371\ttest-hr_err:9.11297\n",
      "[55]\ttrain-rmse:1.00065\ttrain-hr_err:3.62569\ttest-rmse:0.94546\ttest-hr_err:8.75936\n",
      "[60]\ttrain-rmse:1.00463\ttrain-hr_err:3.62569\ttest-rmse:0.94723\ttest-hr_err:8.95629\n",
      "[65]\ttrain-rmse:1.00863\ttrain-hr_err:3.62569\ttest-rmse:0.94908\ttest-hr_err:10.67101\n",
      "[70]\ttrain-rmse:1.01263\ttrain-hr_err:3.52806\ttest-rmse:0.95104\ttest-hr_err:10.67101\n",
      "\n",
      "\n",
      "Fine-tuning...\n",
      "[18:07:59] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:1.40592\ttrain-hr_err:3.62569\ttest-rmse:0.95162\ttest-hr_err:10.64370\n",
      "[5]\ttrain-rmse:1.41210\ttrain-hr_err:3.62569\ttest-rmse:0.95457\ttest-hr_err:12.09330\n",
      "[7]\ttrain-rmse:1.41457\ttrain-hr_err:3.62569\ttest-rmse:0.95575\ttest-hr_err:10.67475\n",
      "[18:08:01] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:0.83756\ttrain-hr_err:17.31426\ttest-rmse:0.95683\ttest-hr_err:9.26597\n",
      "[5]\ttrain-rmse:0.84169\ttrain-hr_err:16.79277\ttest-rmse:0.95927\ttest-hr_err:10.65998\n",
      "[10]\ttrain-rmse:0.84584\ttrain-hr_err:16.59962\ttest-rmse:0.96175\ttest-hr_err:10.65998\n",
      "[15]\ttrain-rmse:0.84999\ttrain-hr_err:16.59962\ttest-rmse:0.96415\ttest-hr_err:10.71991\n",
      "\n",
      "\n",
      "Fine-tuning...\n",
      "[18:08:06] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:1.25305\ttrain-hr_err:16.59962\ttest-rmse:0.96530\ttest-hr_err:12.23309\n",
      "[5]\ttrain-rmse:1.25957\ttrain-hr_err:19.38956\ttest-rmse:0.96854\ttest-hr_err:12.26287\n",
      "[8]\ttrain-rmse:1.26349\ttrain-hr_err:14.70091\ttest-rmse:0.97052\ttest-hr_err:12.29259\n",
      "[18:08:09] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:0.58863\ttrain-hr_err:28.35137\ttest-rmse:0.97102\ttest-hr_err:12.29259\n",
      "[5]\ttrain-rmse:0.59317\ttrain-hr_err:28.35137\ttest-rmse:0.97356\ttest-hr_err:12.29259\n",
      "[10]\ttrain-rmse:0.59775\ttrain-hr_err:23.76903\ttest-rmse:0.97613\ttest-hr_err:12.29259\n",
      "[15]\ttrain-rmse:0.60237\ttrain-hr_err:23.76903\ttest-rmse:0.97875\ttest-hr_err:12.26287\n",
      "[20]\ttrain-rmse:0.60703\ttrain-hr_err:23.76903\ttest-rmse:0.98140\ttest-hr_err:13.80589\n",
      "[25]\ttrain-rmse:0.61173\ttrain-hr_err:23.76903\ttest-rmse:0.98416\ttest-hr_err:13.80589\n",
      "[30]\ttrain-rmse:0.61647\ttrain-hr_err:28.35137\ttest-rmse:0.98701\ttest-hr_err:13.83561\n",
      "[34]\ttrain-rmse:0.62029\ttrain-hr_err:28.35137\ttest-rmse:0.98931\ttest-hr_err:13.83561\n",
      "\n",
      "\n",
      "Fine-tuning...\n",
      "[18:08:18] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:1.19443\ttrain-hr_err:28.47891\ttest-rmse:0.99041\ttest-hr_err:13.83561\n",
      "[5]\ttrain-rmse:1.20343\ttrain-hr_err:28.47891\ttest-rmse:0.99596\ttest-hr_err:13.83561\n",
      "[8]\ttrain-rmse:1.20886\ttrain-hr_err:28.47891\ttest-rmse:0.99934\ttest-hr_err:13.83561\n",
      "[18:08:21] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:1.01673\ttrain-hr_err:37.94629\ttest-rmse:0.99958\ttest-hr_err:11.37299\n",
      "[5]\ttrain-rmse:1.02157\ttrain-hr_err:37.84194\ttest-rmse:1.00083\ttest-hr_err:9.95983\n",
      "[10]\ttrain-rmse:1.02643\ttrain-hr_err:28.75778\ttest-rmse:1.00236\ttest-hr_err:12.75088\n",
      "[15]\ttrain-rmse:1.03134\ttrain-hr_err:31.45005\ttest-rmse:1.00396\ttest-hr_err:8.47832\n",
      "[20]\ttrain-rmse:1.03625\ttrain-hr_err:20.83953\ttest-rmse:1.00561\ttest-hr_err:12.65621\n",
      "[25]\ttrain-rmse:1.04113\ttrain-hr_err:15.92539\ttest-rmse:1.00712\ttest-hr_err:13.79351\n",
      "[28]\ttrain-rmse:1.04405\ttrain-hr_err:11.11938\ttest-rmse:1.00806\ttest-hr_err:21.01163\n",
      "\n",
      "\n",
      "Fine-tuning...\n",
      "[18:08:29] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:1.51359\ttrain-hr_err:8.89261\ttest-rmse:1.00933\ttest-hr_err:19.56561\n",
      "[5]\ttrain-rmse:1.52124\ttrain-hr_err:11.45721\ttest-rmse:1.01403\ttest-hr_err:19.56561\n",
      "[7]\ttrain-rmse:1.52431\ttrain-hr_err:11.45721\ttest-rmse:1.01598\ttest-hr_err:19.56561\n",
      "[18:08:32] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:0.92376\ttrain-hr_err:13.12521\ttest-rmse:1.01734\ttest-hr_err:19.56561\n",
      "[5]\ttrain-rmse:0.92825\ttrain-hr_err:18.17583\ttest-rmse:1.01933\ttest-hr_err:19.53670\n",
      "[10]\ttrain-rmse:0.93289\ttrain-hr_err:23.13067\ttest-rmse:1.02154\ttest-hr_err:19.53670\n",
      "[15]\ttrain-rmse:0.93764\ttrain-hr_err:18.17583\ttest-rmse:1.02387\ttest-hr_err:16.55586\n",
      "[20]\ttrain-rmse:0.94238\ttrain-hr_err:9.05675\ttest-rmse:1.02624\ttest-hr_err:16.52346\n",
      "[25]\ttrain-rmse:0.94714\ttrain-hr_err:9.05675\ttest-rmse:1.02864\ttest-hr_err:16.49527\n",
      "[30]\ttrain-rmse:0.95189\ttrain-hr_err:9.68182\ttest-rmse:1.03100\ttest-hr_err:15.00749\n",
      "[35]\ttrain-rmse:0.95664\ttrain-hr_err:9.68182\ttest-rmse:1.03320\ttest-hr_err:13.54797\n",
      "[40]\ttrain-rmse:0.96139\ttrain-hr_err:5.25786\ttest-rmse:1.03529\ttest-hr_err:13.54797\n",
      "[45]\ttrain-rmse:0.96614\ttrain-hr_err:5.25786\ttest-rmse:1.03774\ttest-hr_err:13.54797\n",
      "[50]\ttrain-rmse:0.97089\ttrain-hr_err:0.83389\ttest-rmse:1.04024\ttest-hr_err:16.49527\n",
      "\n",
      "\n",
      "Fine-tuning...\n",
      "[18:08:47] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:1.53798\ttrain-hr_err:0.98310\ttest-rmse:1.04191\ttest-hr_err:16.46280\n",
      "[5]\ttrain-rmse:1.54626\ttrain-hr_err:0.98310\ttest-rmse:1.04750\ttest-hr_err:16.49527\n",
      "[7]\ttrain-rmse:1.54958\ttrain-hr_err:0.91183\ttest-rmse:1.04979\ttest-hr_err:16.49527\n",
      "Finished training in 0:01:11.150326\n",
      "\n",
      "\n",
      "Training excluding subject 3...\n",
      "\n",
      "Rows per batch: 960\n",
      "[18:08:54] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:0.98111\ttrain-hr_err:1.26763\ttest-rmse:0.80048\ttest-hr_err:17.96820\n",
      "[5]\ttrain-rmse:0.98540\ttrain-hr_err:1.26763\ttest-rmse:0.80037\ttest-hr_err:19.38100\n",
      "[10]\ttrain-rmse:0.98969\ttrain-hr_err:1.16879\ttest-rmse:0.80027\ttest-hr_err:17.88217\n",
      "[15]\ttrain-rmse:0.99398\ttrain-hr_err:1.16879\ttest-rmse:0.80005\ttest-hr_err:19.38039\n",
      "[20]\ttrain-rmse:0.99826\ttrain-hr_err:1.16879\ttest-rmse:0.79986\ttest-hr_err:19.32039\n",
      "[25]\ttrain-rmse:1.00254\ttrain-hr_err:1.16879\ttest-rmse:0.79970\ttest-hr_err:19.32039\n",
      "[26]\ttrain-rmse:1.00339\ttrain-hr_err:1.16879\ttest-rmse:0.79967\ttest-hr_err:19.32039\n",
      "\n",
      "\n",
      "Fine-tuning...\n",
      "[18:09:01] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:1.35218\ttrain-hr_err:1.16879\ttest-rmse:0.80006\ttest-hr_err:17.86419\n",
      "[5]\ttrain-rmse:1.35844\ttrain-hr_err:1.16879\ttest-rmse:0.80165\ttest-hr_err:15.98283\n",
      "[10]\ttrain-rmse:1.36473\ttrain-hr_err:1.16879\ttest-rmse:0.80331\ttest-hr_err:16.73707\n",
      "[12]\ttrain-rmse:1.36726\ttrain-hr_err:1.16879\ttest-rmse:0.80400\ttest-hr_err:18.21712\n",
      "[18:09:05] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:0.84786\ttrain-hr_err:19.09497\ttest-rmse:0.80429\ttest-hr_err:18.21712\n",
      "[5]\ttrain-rmse:0.85227\ttrain-hr_err:14.27947\ttest-rmse:0.80578\ttest-hr_err:18.22670\n",
      "[10]\ttrain-rmse:0.85667\ttrain-hr_err:9.76346\ttest-rmse:0.80729\ttest-hr_err:19.67960\n",
      "[15]\ttrain-rmse:0.86107\ttrain-hr_err:9.76346\ttest-rmse:0.80875\ttest-hr_err:21.25635\n",
      "[17]\ttrain-rmse:0.86283\ttrain-hr_err:9.57325\ttest-rmse:0.80931\ttest-hr_err:21.25635\n",
      "\n",
      "\n",
      "Fine-tuning...\n",
      "[18:09:10] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:1.26083\ttrain-hr_err:9.66008\ttest-rmse:0.81003\ttest-hr_err:21.25635\n",
      "[5]\ttrain-rmse:1.26735\ttrain-hr_err:9.66008\ttest-rmse:0.81371\ttest-hr_err:19.66123\n",
      "[10]\ttrain-rmse:1.27391\ttrain-hr_err:9.66008\ttest-rmse:0.81750\ttest-hr_err:16.65723\n",
      "[15]\ttrain-rmse:1.28044\ttrain-hr_err:4.94264\ttest-rmse:0.82100\ttest-hr_err:16.62683\n",
      "[20]\ttrain-rmse:1.28699\ttrain-hr_err:0.22519\ttest-rmse:0.82395\ttest-hr_err:18.05831\n",
      "[24]\ttrain-rmse:1.29226\ttrain-hr_err:4.49226\ttest-rmse:0.82637\ttest-hr_err:18.05831\n",
      "[18:09:17] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:0.99108\ttrain-hr_err:9.22703\ttest-rmse:0.82731\ttest-hr_err:19.53261\n",
      "[5]\ttrain-rmse:0.99542\ttrain-hr_err:9.13193\ttest-rmse:0.82906\ttest-hr_err:26.01140\n",
      "[10]\ttrain-rmse:0.99953\ttrain-hr_err:8.94103\ttest-rmse:0.83059\ttest-hr_err:27.33349\n",
      "[15]\ttrain-rmse:1.00362\ttrain-hr_err:18.15433\ttest-rmse:0.83214\ttest-hr_err:25.74725\n",
      "[16]\ttrain-rmse:1.00444\ttrain-hr_err:18.15433\ttest-rmse:0.83245\ttest-hr_err:25.71515\n",
      "\n",
      "\n",
      "Fine-tuning...\n",
      "[18:09:22] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:1.41786\ttrain-hr_err:18.15433\ttest-rmse:0.83339\ttest-hr_err:24.24894\n",
      "[5]\ttrain-rmse:1.42465\ttrain-hr_err:18.15433\ttest-rmse:0.83816\ttest-hr_err:25.75231\n",
      "[10]\ttrain-rmse:1.43148\ttrain-hr_err:18.06960\ttest-rmse:0.84303\ttest-hr_err:27.59613\n",
      "[14]\ttrain-rmse:1.43693\ttrain-hr_err:18.15433\ttest-rmse:0.84618\ttest-hr_err:27.59613\n",
      "[18:09:26] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:0.60348\ttrain-hr_err:31.97117\ttest-rmse:0.84749\ttest-hr_err:30.53866\n",
      "[5]\ttrain-rmse:0.60828\ttrain-hr_err:31.97117\ttest-rmse:0.85042\ttest-hr_err:30.53361\n",
      "[10]\ttrain-rmse:0.61312\ttrain-hr_err:31.97117\ttest-rmse:0.85340\ttest-hr_err:30.53361\n",
      "[15]\ttrain-rmse:0.61800\ttrain-hr_err:31.97117\ttest-rmse:0.85640\ttest-hr_err:30.53361\n",
      "[18]\ttrain-rmse:0.62095\ttrain-hr_err:31.97117\ttest-rmse:0.85828\ttest-hr_err:30.53361\n",
      "\n",
      "\n",
      "Fine-tuning...\n",
      "[18:09:32] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:1.20325\ttrain-hr_err:32.16223\ttest-rmse:0.86018\ttest-hr_err:30.53361\n",
      "[5]\ttrain-rmse:1.21239\ttrain-hr_err:32.16223\ttest-rmse:0.86662\ttest-hr_err:30.53361\n",
      "[8]\ttrain-rmse:1.21789\ttrain-hr_err:32.16223\ttest-rmse:0.87053\ttest-hr_err:30.53361\n",
      "[18:09:35] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:0.88156\ttrain-hr_err:14.16921\ttest-rmse:0.87100\ttest-hr_err:28.68978\n",
      "[5]\ttrain-rmse:0.88613\ttrain-hr_err:18.66368\ttest-rmse:0.87332\ttest-hr_err:32.34631\n",
      "[10]\ttrain-rmse:0.89070\ttrain-hr_err:8.25995\ttest-rmse:0.87566\ttest-hr_err:32.24190\n",
      "[15]\ttrain-rmse:0.89528\ttrain-hr_err:5.77736\ttest-rmse:0.87830\ttest-hr_err:27.92885\n",
      "[20]\ttrain-rmse:0.89987\ttrain-hr_err:5.77736\ttest-rmse:0.88080\ttest-hr_err:27.04430\n",
      "[25]\ttrain-rmse:0.90450\ttrain-hr_err:1.35340\ttest-rmse:0.88283\ttest-hr_err:27.12367\n",
      "[30]\ttrain-rmse:0.90914\ttrain-hr_err:5.77736\ttest-rmse:0.88489\ttest-hr_err:27.12367\n",
      "[35]\ttrain-rmse:0.91376\ttrain-hr_err:1.27704\ttest-rmse:0.88694\ttest-hr_err:27.21702\n",
      "[37]\ttrain-rmse:0.91558\ttrain-hr_err:1.27704\ttest-rmse:0.88778\ttest-hr_err:27.21702\n",
      "\n",
      "\n",
      "Fine-tuning...\n",
      "[18:09:47] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:1.41731\ttrain-hr_err:1.27704\ttest-rmse:0.88884\ttest-hr_err:27.21702\n",
      "[5]\ttrain-rmse:1.42485\ttrain-hr_err:1.27704\ttest-rmse:0.89434\ttest-hr_err:27.21702\n",
      "[8]\ttrain-rmse:1.42939\ttrain-hr_err:1.27704\ttest-rmse:0.89770\ttest-hr_err:27.24732\n",
      "Finished training in 0:00:56.096215\n",
      "\n",
      "\n",
      "Training excluding subject 3...\n",
      "\n",
      "Rows per batch: 960\n",
      "[18:09:54] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:0.85662\ttrain-hr_err:1.38267\ttest-rmse:0.79828\ttest-hr_err:22.52161\n",
      "[5]\ttrain-rmse:0.86112\ttrain-hr_err:1.38267\ttest-rmse:0.79917\ttest-hr_err:22.52161\n",
      "[10]\ttrain-rmse:0.86559\ttrain-hr_err:1.38267\ttest-rmse:0.80002\ttest-hr_err:32.02654\n",
      "[15]\ttrain-rmse:0.87006\ttrain-hr_err:1.38267\ttest-rmse:0.80083\ttest-hr_err:29.92519\n",
      "\n",
      "\n",
      "Fine-tuning...\n",
      "[18:09:59] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:1.25543\ttrain-hr_err:1.38267\ttest-rmse:0.80185\ttest-hr_err:31.36495\n",
      "[5]\ttrain-rmse:1.26208\ttrain-hr_err:1.38267\ttest-rmse:0.80622\ttest-hr_err:27.45699\n",
      "[10]\ttrain-rmse:1.26874\ttrain-hr_err:1.46699\ttest-rmse:0.81063\ttest-hr_err:31.75862\n",
      "[13]\ttrain-rmse:1.27278\ttrain-hr_err:1.46699\ttest-rmse:0.81324\ttest-hr_err:30.36865\n",
      "[18:10:03] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:0.96893\ttrain-hr_err:24.54176\ttest-rmse:0.81334\ttest-hr_err:29.99922\n",
      "[5]\ttrain-rmse:0.97261\ttrain-hr_err:15.94437\ttest-rmse:0.81384\ttest-hr_err:17.44252\n",
      "[10]\ttrain-rmse:0.97629\ttrain-hr_err:16.19681\ttest-rmse:0.81381\ttest-hr_err:14.09267\n",
      "[15]\ttrain-rmse:0.97998\ttrain-hr_err:7.26454\ttest-rmse:0.81379\ttest-hr_err:17.19786\n",
      "[20]\ttrain-rmse:0.98368\ttrain-hr_err:7.35372\ttest-rmse:0.81376\ttest-hr_err:18.10292\n",
      "[25]\ttrain-rmse:0.98738\ttrain-hr_err:11.68112\ttest-rmse:0.81368\ttest-hr_err:18.07882\n",
      "[26]\ttrain-rmse:0.98813\ttrain-hr_err:11.68112\ttest-rmse:0.81367\ttest-hr_err:18.10505\n",
      "\n",
      "\n",
      "Fine-tuning...\n",
      "[18:10:12] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:1.37261\ttrain-hr_err:11.68112\ttest-rmse:0.81395\ttest-hr_err:18.10505\n",
      "[5]\ttrain-rmse:1.37912\ttrain-hr_err:12.59145\ttest-rmse:0.81512\ttest-hr_err:16.67008\n",
      "[10]\ttrain-rmse:1.38568\ttrain-hr_err:12.59145\ttest-rmse:0.81640\ttest-hr_err:12.56733\n",
      "[15]\ttrain-rmse:1.39227\ttrain-hr_err:12.59145\ttest-rmse:0.81779\ttest-hr_err:8.78119\n",
      "[20]\ttrain-rmse:1.39889\ttrain-hr_err:12.59145\ttest-rmse:0.81923\ttest-hr_err:10.83197\n",
      "[25]\ttrain-rmse:1.40555\ttrain-hr_err:13.04568\ttest-rmse:0.82076\ttest-hr_err:12.14952\n",
      "[18:10:19] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:0.98015\ttrain-hr_err:24.72610\ttest-rmse:0.82135\ttest-hr_err:17.56947\n",
      "[5]\ttrain-rmse:0.98447\ttrain-hr_err:30.91026\ttest-rmse:0.82271\ttest-hr_err:14.58014\n",
      "[10]\ttrain-rmse:0.98881\ttrain-hr_err:26.28590\ttest-rmse:0.82408\ttest-hr_err:13.07236\n",
      "[15]\ttrain-rmse:0.99318\ttrain-hr_err:20.73831\ttest-rmse:0.82550\ttest-hr_err:21.69006\n",
      "[20]\ttrain-rmse:0.99756\ttrain-hr_err:25.10906\ttest-rmse:0.82693\ttest-hr_err:12.68191\n",
      "[25]\ttrain-rmse:1.00195\ttrain-hr_err:20.69761\ttest-rmse:0.82838\ttest-hr_err:15.26026\n",
      "[30]\ttrain-rmse:1.00634\ttrain-hr_err:16.38300\ttest-rmse:0.82985\ttest-hr_err:13.14824\n",
      "[35]\ttrain-rmse:1.01073\ttrain-hr_err:12.06839\ttest-rmse:0.83126\ttest-hr_err:10.04443\n",
      "[40]\ttrain-rmse:1.01514\ttrain-hr_err:11.67192\ttest-rmse:0.83266\ttest-hr_err:11.59595\n",
      "[45]\ttrain-rmse:1.01954\ttrain-hr_err:11.67192\ttest-rmse:0.83410\ttest-hr_err:11.59595\n",
      "[48]\ttrain-rmse:1.02218\ttrain-hr_err:11.67192\ttest-rmse:0.83497\ttest-hr_err:11.66368\n",
      "\n",
      "\n",
      "Fine-tuning...\n",
      "[18:10:33] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:1.45882\ttrain-hr_err:11.67192\ttest-rmse:0.83621\ttest-hr_err:11.58401\n",
      "[5]\ttrain-rmse:1.46538\ttrain-hr_err:11.56409\ttest-rmse:0.84100\ttest-hr_err:14.58334\n",
      "[7]\ttrain-rmse:1.46801\ttrain-hr_err:7.40824\ttest-rmse:0.84294\ttest-hr_err:14.56559\n",
      "[18:10:36] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:1.05799\ttrain-hr_err:3.74388\ttest-rmse:0.84394\ttest-hr_err:14.56559\n",
      "[5]\ttrain-rmse:1.06257\ttrain-hr_err:5.00715\ttest-rmse:0.84411\ttest-hr_err:13.12514\n",
      "[10]\ttrain-rmse:1.06720\ttrain-hr_err:5.00715\ttest-rmse:0.84431\ttest-hr_err:13.15908\n",
      "[15]\ttrain-rmse:1.07190\ttrain-hr_err:7.75250\ttest-rmse:0.84446\ttest-hr_err:13.17141\n",
      "[20]\ttrain-rmse:1.07660\ttrain-hr_err:3.29257\ttest-rmse:0.84456\ttest-hr_err:15.27971\n",
      "\n",
      "\n",
      "Fine-tuning...\n",
      "[18:10:42] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:1.56848\ttrain-hr_err:3.39629\ttest-rmse:0.84538\ttest-hr_err:15.31357\n",
      "[5]\ttrain-rmse:1.57623\ttrain-hr_err:3.39629\ttest-rmse:0.84938\ttest-hr_err:13.20527\n",
      "[10]\ttrain-rmse:1.58401\ttrain-hr_err:3.39629\ttest-rmse:0.85383\ttest-hr_err:11.35708\n",
      "[15]\ttrain-rmse:1.59184\ttrain-hr_err:1.06883\ttest-rmse:0.85838\ttest-hr_err:11.35708\n",
      "[18:10:47] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:0.89793\ttrain-hr_err:18.37152\ttest-rmse:0.85876\ttest-hr_err:11.35708\n",
      "[5]\ttrain-rmse:0.90227\ttrain-hr_err:18.37152\ttest-rmse:0.86103\ttest-hr_err:12.88987\n",
      "[10]\ttrain-rmse:0.90667\ttrain-hr_err:27.52407\ttest-rmse:0.86360\ttest-hr_err:14.39315\n",
      "[15]\ttrain-rmse:0.91107\ttrain-hr_err:32.15058\ttest-rmse:0.86645\ttest-hr_err:16.70622\n",
      "[18]\ttrain-rmse:0.91372\ttrain-hr_err:32.15058\ttest-rmse:0.86817\ttest-hr_err:14.09398\n",
      "\n",
      "\n",
      "Fine-tuning...\n",
      "[18:10:52] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:1.42843\ttrain-hr_err:32.22909\ttest-rmse:0.86930\ttest-hr_err:14.09398\n",
      "[5]\ttrain-rmse:1.43607\ttrain-hr_err:31.84222\ttest-rmse:0.87500\ttest-hr_err:18.25774\n",
      "[8]\ttrain-rmse:1.44068\ttrain-hr_err:31.84222\ttest-rmse:0.87845\ttest-hr_err:18.25774\n",
      "Finished training in 0:01:01.086842\n",
      "\n",
      "\n",
      "Training excluding subject 3...\n",
      "\n",
      "Rows per batch: 960\n",
      "[18:10:59] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:0.83199\ttrain-hr_err:0.00533\ttest-rmse:0.93019\ttest-hr_err:26.18200\n",
      "[5]\ttrain-rmse:0.83640\ttrain-hr_err:0.06401\ttest-rmse:0.93102\ttest-hr_err:30.17538\n",
      "[10]\ttrain-rmse:0.84081\ttrain-hr_err:0.06401\ttest-rmse:0.93188\ttest-hr_err:28.84551\n",
      "[15]\ttrain-rmse:0.84520\ttrain-hr_err:0.06401\ttest-rmse:0.93278\ttest-hr_err:28.84551\n",
      "[16]\ttrain-rmse:0.84608\ttrain-hr_err:0.06401\ttest-rmse:0.93297\ttest-hr_err:27.29022\n",
      "\n",
      "\n",
      "Fine-tuning...\n",
      "[18:11:04] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:1.21840\ttrain-hr_err:0.06401\ttest-rmse:0.93353\ttest-hr_err:26.18200\n",
      "[5]\ttrain-rmse:1.22477\ttrain-hr_err:0.13351\ttest-rmse:0.93633\ttest-hr_err:30.21364\n",
      "[10]\ttrain-rmse:1.23118\ttrain-hr_err:0.29989\ttest-rmse:0.93919\ttest-hr_err:25.29255\n",
      "[15]\ttrain-rmse:1.23762\ttrain-hr_err:4.41756\ttest-rmse:0.94214\ttest-hr_err:19.08021\n",
      "[20]\ttrain-rmse:1.24409\ttrain-hr_err:5.10457\ttest-rmse:0.94515\ttest-hr_err:18.27243\n",
      "[24]\ttrain-rmse:1.24929\ttrain-hr_err:0.36339\ttest-rmse:0.94768\ttest-hr_err:20.38107\n",
      "[18:11:11] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:0.87494\ttrain-hr_err:3.12719\ttest-rmse:0.94806\ttest-hr_err:17.27041\n",
      "[5]\ttrain-rmse:0.87947\ttrain-hr_err:3.00087\ttest-rmse:0.94991\ttest-hr_err:15.30279\n",
      "[10]\ttrain-rmse:0.88400\ttrain-hr_err:10.05011\ttest-rmse:0.95175\ttest-hr_err:14.75240\n",
      "[15]\ttrain-rmse:0.88853\ttrain-hr_err:1.32346\ttest-rmse:0.95366\ttest-hr_err:10.81287\n",
      "[20]\ttrain-rmse:0.89306\ttrain-hr_err:1.32346\ttest-rmse:0.95577\ttest-hr_err:13.99127\n",
      "[25]\ttrain-rmse:0.89759\ttrain-hr_err:1.32346\ttest-rmse:0.95800\ttest-hr_err:14.37361\n",
      "[28]\ttrain-rmse:0.90031\ttrain-hr_err:1.25536\ttest-rmse:0.95933\ttest-hr_err:14.37361\n",
      "\n",
      "\n",
      "Fine-tuning...\n",
      "[18:11:19] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:1.33046\ttrain-hr_err:1.25536\ttest-rmse:0.96057\ttest-hr_err:14.37361\n",
      "[5]\ttrain-rmse:1.33746\ttrain-hr_err:1.25536\ttest-rmse:0.96457\ttest-hr_err:13.00781\n",
      "[10]\ttrain-rmse:1.34452\ttrain-hr_err:1.25536\ttest-rmse:0.96854\ttest-hr_err:13.90606\n",
      "[13]\ttrain-rmse:1.34877\ttrain-hr_err:1.25536\ttest-rmse:0.97093\ttest-hr_err:14.14518\n",
      "[18:11:23] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:0.99891\ttrain-hr_err:5.78464\ttest-rmse:0.97127\ttest-hr_err:13.00781\n",
      "[5]\ttrain-rmse:1.00269\ttrain-hr_err:10.35063\ttest-rmse:0.97298\ttest-hr_err:11.77440\n",
      "[10]\ttrain-rmse:1.00673\ttrain-hr_err:10.25822\ttest-rmse:0.97363\ttest-hr_err:13.43777\n",
      "[15]\ttrain-rmse:1.01077\ttrain-hr_err:10.16560\ttest-rmse:0.97435\ttest-hr_err:12.61583\n",
      "[19]\ttrain-rmse:1.01402\ttrain-hr_err:5.29308\ttest-rmse:0.97495\ttest-hr_err:12.75451\n",
      "\n",
      "\n",
      "Fine-tuning...\n",
      "[18:11:29] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:1.45295\ttrain-hr_err:0.69978\ttest-rmse:0.97590\ttest-hr_err:12.78505\n",
      "[5]\ttrain-rmse:1.46014\ttrain-hr_err:0.49049\ttest-rmse:0.97993\ttest-hr_err:12.35423\n",
      "[10]\ttrain-rmse:1.46737\ttrain-hr_err:4.11382\ttest-rmse:0.98403\ttest-hr_err:9.25607\n",
      "[15]\ttrain-rmse:1.47463\ttrain-hr_err:8.83421\ttest-rmse:0.98822\ttest-hr_err:8.61109\n",
      "[20]\ttrain-rmse:1.48192\ttrain-hr_err:4.33518\ttest-rmse:0.99251\ttest-hr_err:6.82363\n",
      "[25]\ttrain-rmse:1.48923\ttrain-hr_err:4.33518\ttest-rmse:0.99690\ttest-hr_err:9.27002\n",
      "[28]\ttrain-rmse:1.49364\ttrain-hr_err:0.28020\ttest-rmse:0.99956\ttest-hr_err:9.57158\n",
      "[18:11:37] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:1.03771\ttrain-hr_err:40.72648\ttest-rmse:1.00018\ttest-hr_err:9.20563\n",
      "[5]\ttrain-rmse:1.04222\ttrain-hr_err:36.27689\ttest-rmse:1.00341\ttest-hr_err:10.26083\n",
      "[10]\ttrain-rmse:1.04675\ttrain-hr_err:27.37770\ttest-rmse:1.00685\ttest-hr_err:12.37846\n",
      "[15]\ttrain-rmse:1.05127\ttrain-hr_err:31.82729\ttest-rmse:1.01033\ttest-hr_err:11.56129\n",
      "[18]\ttrain-rmse:1.05400\ttrain-hr_err:31.91484\ttest-rmse:1.01245\ttest-hr_err:11.59689\n",
      "\n",
      "\n",
      "Fine-tuning...\n",
      "[18:11:44] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:1.54276\ttrain-hr_err:27.56288\ttest-rmse:1.01436\ttest-hr_err:13.06477\n",
      "[5]\ttrain-rmse:1.55047\ttrain-hr_err:22.60852\ttest-rmse:1.02041\ttest-hr_err:10.11968\n",
      "[9]\ttrain-rmse:1.55667\ttrain-hr_err:22.60852\ttest-rmse:1.02533\ttest-hr_err:10.18167\n",
      "[18:11:47] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:0.92110\ttrain-hr_err:21.43945\ttest-rmse:1.02576\ttest-hr_err:10.18167\n",
      "[5]\ttrain-rmse:0.92560\ttrain-hr_err:21.43945\ttest-rmse:1.02793\ttest-hr_err:8.73489\n",
      "[10]\ttrain-rmse:0.93010\ttrain-hr_err:23.16847\ttest-rmse:1.03011\ttest-hr_err:12.61307\n",
      "[15]\ttrain-rmse:0.93460\ttrain-hr_err:5.53356\ttest-rmse:1.03234\ttest-hr_err:11.60601\n",
      "[17]\ttrain-rmse:0.93640\ttrain-hr_err:5.53356\ttest-rmse:1.03324\ttest-hr_err:11.57443\n",
      "\n",
      "\n",
      "Fine-tuning...\n",
      "[18:11:53] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:1.48176\ttrain-hr_err:5.45267\ttest-rmse:1.03483\ttest-hr_err:11.60288\n",
      "[5]\ttrain-rmse:1.48976\ttrain-hr_err:0.97333\ttest-rmse:1.04059\ttest-hr_err:12.24231\n",
      "[7]\ttrain-rmse:1.49297\ttrain-hr_err:5.37196\ttest-rmse:1.04292\ttest-hr_err:12.24231\n",
      "Finished training in 0:00:56.602371\n",
      "\n",
      "\n",
      "Training excluding subject 4...\n",
      "\n",
      "Rows per batch: 960\n",
      "[18:12:00] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:0.96329\ttrain-hr_err:0.81770\ttest-rmse:0.71178\ttest-hr_err:24.35117\n",
      "[5]\ttrain-rmse:0.96767\ttrain-hr_err:0.81770\ttest-rmse:0.71525\ttest-hr_err:23.36739\n",
      "[10]\ttrain-rmse:0.97207\ttrain-hr_err:0.81770\ttest-rmse:0.71881\ttest-hr_err:21.92975\n",
      "[15]\ttrain-rmse:0.97646\ttrain-hr_err:0.81770\ttest-rmse:0.72243\ttest-hr_err:21.95224\n",
      "[20]\ttrain-rmse:0.98085\ttrain-hr_err:0.81770\ttest-rmse:0.72609\ttest-hr_err:23.01891\n",
      "[25]\ttrain-rmse:0.98524\ttrain-hr_err:0.81770\ttest-rmse:0.72975\ttest-hr_err:23.04264\n",
      "\n",
      "\n",
      "Fine-tuning...\n",
      "[18:12:08] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:1.34877\ttrain-hr_err:0.81770\ttest-rmse:0.73039\ttest-hr_err:23.01891\n",
      "[5]\ttrain-rmse:1.35535\ttrain-hr_err:0.93553\ttest-rmse:0.73352\ttest-hr_err:22.04339\n",
      "[10]\ttrain-rmse:1.36194\ttrain-hr_err:0.93553\ttest-rmse:0.73669\ttest-hr_err:12.50051\n",
      "[15]\ttrain-rmse:1.36854\ttrain-hr_err:0.93553\ttest-rmse:0.74001\ttest-hr_err:19.08647\n",
      "[18]\ttrain-rmse:1.37250\ttrain-hr_err:0.93553\ttest-rmse:0.74187\ttest-hr_err:22.30618\n",
      "[18:12:15] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:0.53463\ttrain-hr_err:3.16115\ttest-rmse:0.74301\ttest-hr_err:23.65829\n",
      "[5]\ttrain-rmse:0.53885\ttrain-hr_err:3.07138\ttest-rmse:0.74585\ttest-hr_err:22.42594\n",
      "[10]\ttrain-rmse:0.54310\ttrain-hr_err:3.07138\ttest-rmse:0.74874\ttest-hr_err:22.29667\n",
      "[15]\ttrain-rmse:0.54738\ttrain-hr_err:3.07138\ttest-rmse:0.75180\ttest-hr_err:23.64879\n",
      "[20]\ttrain-rmse:0.55169\ttrain-hr_err:2.98141\ttest-rmse:0.75502\ttest-hr_err:22.41485\n",
      "[25]\ttrain-rmse:0.55603\ttrain-hr_err:2.98141\ttest-rmse:0.75829\ttest-hr_err:21.18092\n",
      "[30]\ttrain-rmse:0.56041\ttrain-hr_err:2.98141\ttest-rmse:0.76160\ttest-hr_err:21.27112\n",
      "[35]\ttrain-rmse:0.56483\ttrain-hr_err:1.49734\ttest-rmse:0.76497\ttest-hr_err:18.97556\n",
      "[40]\ttrain-rmse:0.56928\ttrain-hr_err:1.49734\ttest-rmse:0.76838\ttest-hr_err:20.54804\n",
      "[45]\ttrain-rmse:0.57377\ttrain-hr_err:2.89124\ttest-rmse:0.77185\ttest-hr_err:20.28169\n",
      "[47]\ttrain-rmse:0.57558\ttrain-hr_err:2.89124\ttest-rmse:0.77324\ttest-hr_err:20.28169\n",
      "\n",
      "\n",
      "Fine-tuning...\n",
      "[18:12:30] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:1.13660\ttrain-hr_err:2.98324\ttest-rmse:0.77528\ttest-hr_err:20.28169\n",
      "[5]\ttrain-rmse:1.14528\ttrain-hr_err:2.98324\ttest-rmse:0.78205\ttest-hr_err:20.28169\n",
      "[7]\ttrain-rmse:1.14876\ttrain-hr_err:2.98324\ttest-rmse:0.78479\ttest-hr_err:20.28169\n",
      "[18:12:33] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:1.00589\ttrain-hr_err:39.60145\ttest-rmse:0.78651\ttest-hr_err:20.28169\n",
      "[5]\ttrain-rmse:1.01018\ttrain-hr_err:35.39093\ttest-rmse:0.78820\ttest-hr_err:28.39093\n",
      "[10]\ttrain-rmse:1.01441\ttrain-hr_err:35.39093\ttest-rmse:0.79052\ttest-hr_err:32.08649\n",
      "[15]\ttrain-rmse:1.01865\ttrain-hr_err:35.39093\ttest-rmse:0.79287\ttest-hr_err:24.38979\n",
      "[16]\ttrain-rmse:1.01950\ttrain-hr_err:35.39093\ttest-rmse:0.79335\ttest-hr_err:24.37250\n",
      "\n",
      "\n",
      "Fine-tuning...\n",
      "[18:12:38] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:1.47697\ttrain-hr_err:35.39093\ttest-rmse:0.79439\ttest-hr_err:24.85687\n",
      "[5]\ttrain-rmse:1.48424\ttrain-hr_err:35.39093\ttest-rmse:0.79965\ttest-hr_err:24.71487\n",
      "[10]\ttrain-rmse:1.49152\ttrain-hr_err:35.39093\ttest-rmse:0.80507\ttest-hr_err:19.13981\n",
      "[15]\ttrain-rmse:1.49884\ttrain-hr_err:35.39093\ttest-rmse:0.81044\ttest-hr_err:15.19944\n",
      "[20]\ttrain-rmse:1.50622\ttrain-hr_err:39.60145\ttest-rmse:0.81586\ttest-hr_err:11.33668\n",
      "[25]\ttrain-rmse:1.51364\ttrain-hr_err:43.73803\ttest-rmse:0.82150\ttest-hr_err:9.43714\n",
      "[30]\ttrain-rmse:1.52108\ttrain-hr_err:47.95318\ttest-rmse:0.82716\ttest-hr_err:9.82223\n",
      "[35]\ttrain-rmse:1.52852\ttrain-hr_err:52.16833\ttest-rmse:0.83287\ttest-hr_err:8.95439\n",
      "[40]\ttrain-rmse:1.53601\ttrain-hr_err:56.38347\ttest-rmse:0.83853\ttest-hr_err:5.01662\n",
      "[45]\ttrain-rmse:1.54354\ttrain-hr_err:56.38347\ttest-rmse:0.84425\ttest-hr_err:5.91191\n",
      "[49]\ttrain-rmse:1.54960\ttrain-hr_err:56.38347\ttest-rmse:0.84885\ttest-hr_err:8.09226\n",
      "[18:12:53] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:0.94727\ttrain-hr_err:6.18766\ttest-rmse:0.84949\ttest-hr_err:8.09226\n",
      "[5]\ttrain-rmse:0.95197\ttrain-hr_err:1.98635\ttest-rmse:0.85228\ttest-hr_err:7.60864\n",
      "[10]\ttrain-rmse:0.95656\ttrain-hr_err:1.98143\ttest-rmse:0.85495\ttest-hr_err:7.60864\n",
      "[15]\ttrain-rmse:0.96117\ttrain-hr_err:1.98143\ttest-rmse:0.85752\ttest-hr_err:7.34796\n",
      "[20]\ttrain-rmse:0.96579\ttrain-hr_err:1.98143\ttest-rmse:0.86013\ttest-hr_err:7.31485\n",
      "[25]\ttrain-rmse:0.97042\ttrain-hr_err:6.55171\ttest-rmse:0.86278\ttest-hr_err:7.31612\n",
      "[30]\ttrain-rmse:0.97506\ttrain-hr_err:2.05523\ttest-rmse:0.86546\ttest-hr_err:10.09590\n",
      "[35]\ttrain-rmse:0.97971\ttrain-hr_err:2.05523\ttest-rmse:0.86818\ttest-hr_err:8.70713\n",
      "[37]\ttrain-rmse:0.98157\ttrain-hr_err:4.05366\ttest-rmse:0.86928\ttest-hr_err:8.68446\n",
      "\n",
      "\n",
      "Fine-tuning...\n",
      "[18:13:05] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:1.58336\ttrain-hr_err:3.83952\ttest-rmse:0.87076\ttest-hr_err:7.59356\n",
      "[5]\ttrain-rmse:1.59193\ttrain-hr_err:3.83952\ttest-rmse:0.87830\ttest-hr_err:7.59356\n",
      "[7]\ttrain-rmse:1.59537\ttrain-hr_err:3.83952\ttest-rmse:0.88131\ttest-hr_err:7.59356\n",
      "[18:13:08] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:0.97508\ttrain-hr_err:18.25052\ttest-rmse:0.88347\ttest-hr_err:7.59356\n",
      "[5]\ttrain-rmse:0.97994\ttrain-hr_err:13.29569\ttest-rmse:0.88640\ttest-hr_err:8.69827\n",
      "[10]\ttrain-rmse:0.98485\ttrain-hr_err:3.30300\ttest-rmse:0.88930\ttest-hr_err:8.44697\n",
      "[15]\ttrain-rmse:0.98976\ttrain-hr_err:3.30300\ttest-rmse:0.89218\ttest-hr_err:9.82587\n",
      "\n",
      "\n",
      "Fine-tuning...\n",
      "[18:13:13] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:1.60680\ttrain-hr_err:3.45185\ttest-rmse:0.89424\ttest-hr_err:10.95795\n",
      "[5]\ttrain-rmse:1.61571\ttrain-hr_err:3.45185\ttest-rmse:0.90184\ttest-hr_err:10.95795\n",
      "[10]\ttrain-rmse:1.62468\ttrain-hr_err:3.35134\ttest-rmse:0.90953\ttest-hr_err:10.66844\n",
      "[15]\ttrain-rmse:1.63364\ttrain-hr_err:3.27470\ttest-rmse:0.91735\ttest-hr_err:10.37303\n",
      "[20]\ttrain-rmse:1.64265\ttrain-hr_err:3.19823\ttest-rmse:0.92527\ttest-hr_err:10.37303\n",
      "[25]\ttrain-rmse:1.65172\ttrain-hr_err:3.19823\ttest-rmse:0.93327\ttest-hr_err:8.60084\n",
      "[29]\ttrain-rmse:1.65902\ttrain-hr_err:3.19823\ttest-rmse:0.93973\ttest-hr_err:8.60084\n",
      "Finished training in 0:01:22.296238\n",
      "\n",
      "\n",
      "Training excluding subject 4...\n",
      "\n",
      "Rows per batch: 960\n",
      "[18:13:26] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:0.95518\ttrain-hr_err:9.35182\ttest-rmse:0.85512\ttest-hr_err:36.11449\n",
      "[5]\ttrain-rmse:0.95894\ttrain-hr_err:9.35182\ttest-rmse:0.85617\ttest-hr_err:36.11449\n",
      "[10]\ttrain-rmse:0.96271\ttrain-hr_err:9.35182\ttest-rmse:0.85725\ttest-hr_err:37.16253\n",
      "[15]\ttrain-rmse:0.96649\ttrain-hr_err:9.35182\ttest-rmse:0.85834\ttest-hr_err:37.16253\n",
      "\n",
      "\n",
      "Fine-tuning...\n",
      "[18:13:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:1.31595\ttrain-hr_err:9.35182\ttest-rmse:0.85901\ttest-hr_err:39.30513\n",
      "[5]\ttrain-rmse:1.32189\ttrain-hr_err:9.18201\ttest-rmse:0.86133\ttest-hr_err:30.45955\n",
      "[10]\ttrain-rmse:1.32786\ttrain-hr_err:9.09683\ttest-rmse:0.86371\ttest-hr_err:35.32658\n",
      "[11]\ttrain-rmse:1.32906\ttrain-hr_err:9.09683\ttest-rmse:0.86419\ttest-hr_err:34.03110\n",
      "[18:13:35] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:0.85381\ttrain-hr_err:24.63030\ttest-rmse:0.86521\ttest-hr_err:33.09196\n",
      "[5]\ttrain-rmse:0.85835\ttrain-hr_err:24.87684\ttest-rmse:0.86791\ttest-hr_err:34.38579\n",
      "[10]\ttrain-rmse:0.86290\ttrain-hr_err:8.60565\ttest-rmse:0.87033\ttest-hr_err:27.08007\n",
      "[15]\ttrain-rmse:0.86744\ttrain-hr_err:3.80624\ttest-rmse:0.87243\ttest-hr_err:21.74120\n",
      "[20]\ttrain-rmse:0.87198\ttrain-hr_err:0.79808\ttest-rmse:0.87458\ttest-hr_err:17.50672\n",
      "[25]\ttrain-rmse:0.87650\ttrain-hr_err:0.88099\ttest-rmse:0.87680\ttest-hr_err:15.10864\n",
      "[30]\ttrain-rmse:0.88102\ttrain-hr_err:0.88099\ttest-rmse:0.87903\ttest-hr_err:14.14422\n",
      "[35]\ttrain-rmse:0.88552\ttrain-hr_err:0.88099\ttest-rmse:0.88134\ttest-hr_err:15.22882\n",
      "[40]\ttrain-rmse:0.89000\ttrain-hr_err:0.88099\ttest-rmse:0.88367\ttest-hr_err:14.16568\n",
      "[45]\ttrain-rmse:0.89447\ttrain-hr_err:0.88099\ttest-rmse:0.88604\ttest-hr_err:13.41456\n",
      "[50]\ttrain-rmse:0.89897\ttrain-hr_err:0.88099\ttest-rmse:0.88803\ttest-hr_err:11.05292\n",
      "[55]\ttrain-rmse:0.90345\ttrain-hr_err:0.88099\ttest-rmse:0.89004\ttest-hr_err:9.60536\n",
      "[60]\ttrain-rmse:0.90792\ttrain-hr_err:0.96410\ttest-rmse:0.89203\ttest-hr_err:10.75473\n",
      "[65]\ttrain-rmse:0.91237\ttrain-hr_err:0.96410\ttest-rmse:0.89401\ttest-hr_err:10.79515\n",
      "[70]\ttrain-rmse:0.91678\ttrain-hr_err:0.96410\ttest-rmse:0.89590\ttest-hr_err:10.26383\n",
      "[71]\ttrain-rmse:0.91766\ttrain-hr_err:0.96410\ttest-rmse:0.89626\ttest-hr_err:12.40605\n",
      "\n",
      "\n",
      "Fine-tuning...\n",
      "[18:13:57] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:1.35253\ttrain-hr_err:0.96410\ttest-rmse:0.89739\ttest-hr_err:12.40605\n",
      "[5]\ttrain-rmse:1.35925\ttrain-hr_err:0.96410\ttest-rmse:0.90133\ttest-hr_err:13.11799\n",
      "[9]\ttrain-rmse:1.36465\ttrain-hr_err:0.96410\ttest-rmse:0.90457\ttest-hr_err:12.88253\n",
      "[18:14:00] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:0.90519\ttrain-hr_err:12.35363\ttest-rmse:0.90506\ttest-hr_err:13.01599\n",
      "[5]\ttrain-rmse:0.90956\ttrain-hr_err:8.14771\ttest-rmse:0.90760\ttest-hr_err:13.08361\n",
      "[10]\ttrain-rmse:0.91396\ttrain-hr_err:6.45672\ttest-rmse:0.91011\ttest-hr_err:13.10291\n",
      "[15]\ttrain-rmse:0.91840\ttrain-hr_err:2.01349\ttest-rmse:0.91242\ttest-hr_err:15.68782\n",
      "[16]\ttrain-rmse:0.91929\ttrain-hr_err:2.01349\ttest-rmse:0.91288\ttest-hr_err:15.54804\n",
      "\n",
      "\n",
      "Fine-tuning...\n",
      "[18:14:06] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:1.37862\ttrain-hr_err:2.08349\ttest-rmse:0.91391\ttest-hr_err:16.71167\n",
      "[5]\ttrain-rmse:1.38578\ttrain-hr_err:2.08349\ttest-rmse:0.91894\ttest-hr_err:16.71167\n",
      "[7]\ttrain-rmse:1.38865\ttrain-hr_err:2.08349\ttest-rmse:0.92088\ttest-hr_err:16.74647\n",
      "[18:14:09] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:0.62268\ttrain-hr_err:31.10656\ttest-rmse:0.92236\ttest-hr_err:16.74647\n",
      "[5]\ttrain-rmse:0.62777\ttrain-hr_err:31.10656\ttest-rmse:0.92515\ttest-hr_err:16.74647\n",
      "[10]\ttrain-rmse:0.63291\ttrain-hr_err:31.10656\ttest-rmse:0.92797\ttest-hr_err:16.72393\n",
      "[15]\ttrain-rmse:0.63808\ttrain-hr_err:26.84463\ttest-rmse:0.93080\ttest-hr_err:16.72393\n",
      "[20]\ttrain-rmse:0.64330\ttrain-hr_err:26.84463\ttest-rmse:0.93369\ttest-hr_err:16.72393\n",
      "[25]\ttrain-rmse:0.64857\ttrain-hr_err:26.84463\ttest-rmse:0.93664\ttest-hr_err:16.72393\n",
      "\n",
      "\n",
      "Fine-tuning...\n",
      "[18:14:17] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:1.25928\ttrain-hr_err:28.04556\ttest-rmse:0.93859\ttest-hr_err:16.72393\n",
      "[5]\ttrain-rmse:1.26873\ttrain-hr_err:28.04556\ttest-rmse:0.94541\ttest-hr_err:16.72393\n",
      "[8]\ttrain-rmse:1.27443\ttrain-hr_err:28.04556\ttest-rmse:0.94955\ttest-hr_err:16.72393\n",
      "[18:14:20] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:1.04290\ttrain-hr_err:55.43500\ttest-rmse:0.95001\ttest-hr_err:16.75861\n",
      "[5]\ttrain-rmse:1.04793\ttrain-hr_err:39.10585\ttest-rmse:0.95236\ttest-hr_err:15.85340\n",
      "[10]\ttrain-rmse:1.05297\ttrain-hr_err:24.72436\ttest-rmse:0.95471\ttest-hr_err:18.00451\n",
      "[15]\ttrain-rmse:1.05801\ttrain-hr_err:25.02070\ttest-rmse:0.95707\ttest-hr_err:22.63710\n",
      "[20]\ttrain-rmse:1.06306\ttrain-hr_err:16.07423\ttest-rmse:0.95949\ttest-hr_err:22.63384\n",
      "[21]\ttrain-rmse:1.06407\ttrain-hr_err:16.07423\ttest-rmse:0.95998\ttest-hr_err:22.11949\n",
      "\n",
      "\n",
      "Fine-tuning...\n",
      "[18:14:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:1.58070\ttrain-hr_err:11.50280\ttest-rmse:0.96129\ttest-hr_err:22.11949\n",
      "[5]\ttrain-rmse:1.58881\ttrain-hr_err:11.73083\ttest-rmse:0.96543\ttest-hr_err:21.01321\n",
      "[10]\ttrain-rmse:1.59693\ttrain-hr_err:11.84444\ttest-rmse:0.96998\ttest-hr_err:20.99261\n",
      "[15]\ttrain-rmse:1.60506\ttrain-hr_err:11.84444\ttest-rmse:0.97503\ttest-hr_err:20.97565\n",
      "[20]\ttrain-rmse:1.61324\ttrain-hr_err:11.95778\ttest-rmse:0.98010\ttest-hr_err:24.17427\n",
      "[22]\ttrain-rmse:1.61652\ttrain-hr_err:11.95778\ttest-rmse:0.98221\ttest-hr_err:24.15069\n",
      "Finished training in 0:01:08.901419\n",
      "\n",
      "\n",
      "Training excluding subject 4...\n",
      "\n",
      "Rows per batch: 960\n",
      "[18:14:39] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:0.95456\ttrain-hr_err:0.90378\ttest-rmse:0.84048\ttest-hr_err:19.96034\n",
      "[5]\ttrain-rmse:0.95912\ttrain-hr_err:0.90378\ttest-rmse:0.84099\ttest-hr_err:19.96034\n",
      "[10]\ttrain-rmse:0.96367\ttrain-hr_err:0.90378\ttest-rmse:0.84145\ttest-hr_err:19.92313\n",
      "[15]\ttrain-rmse:0.96822\ttrain-hr_err:0.90378\ttest-rmse:0.84201\ttest-hr_err:17.86989\n",
      "[20]\ttrain-rmse:0.97277\ttrain-hr_err:1.02136\ttest-rmse:0.84262\ttest-hr_err:17.47361\n",
      "[25]\ttrain-rmse:0.97732\ttrain-hr_err:0.90378\ttest-rmse:0.84327\ttest-hr_err:17.49330\n",
      "[30]\ttrain-rmse:0.98186\ttrain-hr_err:0.90378\ttest-rmse:0.84406\ttest-hr_err:15.04826\n",
      "[35]\ttrain-rmse:0.98638\ttrain-hr_err:0.90378\ttest-rmse:0.84505\ttest-hr_err:14.01184\n",
      "[40]\ttrain-rmse:0.99085\ttrain-hr_err:0.90378\ttest-rmse:0.84586\ttest-hr_err:12.96225\n",
      "[45]\ttrain-rmse:0.99532\ttrain-hr_err:0.90378\ttest-rmse:0.84669\ttest-hr_err:13.41025\n",
      "[50]\ttrain-rmse:0.99977\ttrain-hr_err:0.90378\ttest-rmse:0.84715\ttest-hr_err:13.38644\n",
      "[51]\ttrain-rmse:1.00066\ttrain-hr_err:0.90378\ttest-rmse:0.84724\ttest-hr_err:14.44139\n",
      "\n",
      "\n",
      "Fine-tuning...\n",
      "[18:14:54] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:1.38905\ttrain-hr_err:0.78353\ttest-rmse:0.84795\ttest-hr_err:15.55121\n",
      "[5]\ttrain-rmse:1.39558\ttrain-hr_err:0.78353\ttest-rmse:0.85108\ttest-hr_err:15.35481\n",
      "[10]\ttrain-rmse:1.40210\ttrain-hr_err:0.90111\ttest-rmse:0.85436\ttest-hr_err:14.62990\n",
      "[15]\ttrain-rmse:1.40863\ttrain-hr_err:0.78353\ttest-rmse:0.85773\ttest-hr_err:17.20869\n",
      "[18]\ttrain-rmse:1.41258\ttrain-hr_err:0.78353\ttest-rmse:0.85989\ttest-hr_err:16.64491\n",
      "[18:15:00] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:0.88758\ttrain-hr_err:30.01918\ttest-rmse:0.86028\ttest-hr_err:16.64491\n",
      "[5]\ttrain-rmse:0.89180\ttrain-hr_err:30.15699\ttest-rmse:0.86230\ttest-hr_err:17.63251\n",
      "[10]\ttrain-rmse:0.89602\ttrain-hr_err:24.08410\ttest-rmse:0.86438\ttest-hr_err:16.51745\n",
      "[15]\ttrain-rmse:0.89988\ttrain-hr_err:22.23409\ttest-rmse:0.86596\ttest-hr_err:15.38395\n",
      "[20]\ttrain-rmse:0.90377\ttrain-hr_err:10.36065\ttest-rmse:0.86760\ttest-hr_err:14.25258\n",
      "[25]\ttrain-rmse:0.90765\ttrain-hr_err:15.41151\ttest-rmse:0.86917\ttest-hr_err:15.60366\n",
      "[30]\ttrain-rmse:0.91173\ttrain-hr_err:14.13576\ttest-rmse:0.87095\ttest-hr_err:15.62431\n",
      "[34]\ttrain-rmse:0.91504\ttrain-hr_err:9.48280\ttest-rmse:0.87254\ttest-hr_err:15.60366\n",
      "\n",
      "\n",
      "Fine-tuning...\n",
      "[18:15:12] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:1.35830\ttrain-hr_err:9.49451\ttest-rmse:0.87396\ttest-hr_err:15.58509\n",
      "[5]\ttrain-rmse:1.36545\ttrain-hr_err:14.15311\ttest-rmse:0.87868\ttest-hr_err:14.71628\n",
      "[10]\ttrain-rmse:1.37266\ttrain-hr_err:14.15311\ttest-rmse:0.88344\ttest-hr_err:14.41907\n",
      "[15]\ttrain-rmse:1.37992\ttrain-hr_err:14.15311\ttest-rmse:0.88828\ttest-hr_err:14.49595\n",
      "[18:15:17] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:0.87461\ttrain-hr_err:3.40516\ttest-rmse:0.88856\ttest-hr_err:14.49595\n",
      "[5]\ttrain-rmse:0.87864\ttrain-hr_err:7.69566\ttest-rmse:0.88997\ttest-hr_err:15.62861\n",
      "[10]\ttrain-rmse:0.88269\ttrain-hr_err:7.69566\ttest-rmse:0.89140\ttest-hr_err:16.74315\n",
      "[15]\ttrain-rmse:0.88675\ttrain-hr_err:16.36305\ttest-rmse:0.89287\ttest-hr_err:14.77547\n",
      "[20]\ttrain-rmse:0.89086\ttrain-hr_err:16.36305\ttest-rmse:0.89440\ttest-hr_err:13.75852\n",
      "[25]\ttrain-rmse:0.89497\ttrain-hr_err:16.36305\ttest-rmse:0.89596\ttest-hr_err:13.58475\n",
      "[30]\ttrain-rmse:0.89911\ttrain-hr_err:16.36305\ttest-rmse:0.89759\ttest-hr_err:11.47441\n",
      "[35]\ttrain-rmse:0.90313\ttrain-hr_err:12.06775\ttest-rmse:0.89948\ttest-hr_err:10.36201\n",
      "[40]\ttrain-rmse:0.90733\ttrain-hr_err:12.06775\ttest-rmse:0.90118\ttest-hr_err:10.18549\n",
      "[45]\ttrain-rmse:0.91153\ttrain-hr_err:12.06775\ttest-rmse:0.90303\ttest-hr_err:10.18549\n",
      "[50]\ttrain-rmse:0.91574\ttrain-hr_err:7.77245\ttest-rmse:0.90490\ttest-hr_err:11.10699\n",
      "[54]\ttrain-rmse:0.91911\ttrain-hr_err:7.77245\ttest-rmse:0.90642\ttest-hr_err:12.21939\n",
      "\n",
      "\n",
      "Fine-tuning...\n",
      "[18:15:35] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:1.40893\ttrain-hr_err:7.84678\ttest-rmse:0.90769\ttest-hr_err:12.23778\n",
      "[5]\ttrain-rmse:1.41617\ttrain-hr_err:7.84678\ttest-rmse:0.91207\ttest-hr_err:12.23778\n",
      "[8]\ttrain-rmse:1.42053\ttrain-hr_err:7.84678\ttest-rmse:0.91465\ttest-hr_err:12.23778\n",
      "[18:15:38] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:1.06374\ttrain-hr_err:0.38523\ttest-rmse:0.91510\ttest-hr_err:12.23778\n",
      "[5]\ttrain-rmse:1.06792\ttrain-hr_err:4.79669\ttest-rmse:0.91738\ttest-hr_err:12.54154\n",
      "[10]\ttrain-rmse:1.07212\ttrain-hr_err:0.48208\ttest-rmse:0.91969\ttest-hr_err:13.71351\n",
      "[15]\ttrain-rmse:1.07634\ttrain-hr_err:4.79669\ttest-rmse:0.92202\ttest-hr_err:12.92562\n",
      "[16]\ttrain-rmse:1.07719\ttrain-hr_err:4.79669\ttest-rmse:0.92249\ttest-hr_err:12.92562\n",
      "\n",
      "\n",
      "Fine-tuning...\n",
      "[18:15:44] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:1.57600\ttrain-hr_err:4.89861\ttest-rmse:0.92351\ttest-hr_err:13.57854\n",
      "[5]\ttrain-rmse:1.58383\ttrain-hr_err:4.89861\ttest-rmse:0.92878\ttest-hr_err:14.46560\n",
      "[9]\ttrain-rmse:1.59012\ttrain-hr_err:4.89861\ttest-rmse:0.93354\ttest-hr_err:14.04343\n",
      "[18:15:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:0.93992\ttrain-hr_err:16.20180\ttest-rmse:0.93510\ttest-hr_err:15.15198\n",
      "[5]\ttrain-rmse:0.94461\ttrain-hr_err:14.58341\ttest-rmse:0.93688\ttest-hr_err:14.49906\n",
      "[10]\ttrain-rmse:0.94930\ttrain-hr_err:19.09371\ttest-rmse:0.93855\ttest-hr_err:19.41373\n",
      "[15]\ttrain-rmse:0.95400\ttrain-hr_err:10.25596\ttest-rmse:0.94025\ttest-hr_err:15.85600\n",
      "[18]\ttrain-rmse:0.95683\ttrain-hr_err:10.16962\ttest-rmse:0.94128\ttest-hr_err:15.87851\n",
      "\n",
      "\n",
      "Fine-tuning...\n",
      "[18:15:54] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:1.51328\ttrain-hr_err:10.24258\ttest-rmse:0.94249\ttest-hr_err:13.69787\n",
      "[5]\ttrain-rmse:1.52134\ttrain-hr_err:5.82879\ttest-rmse:0.94853\ttest-hr_err:13.69787\n",
      "[7]\ttrain-rmse:1.52457\ttrain-hr_err:1.41500\ttest-rmse:0.95098\ttest-hr_err:13.69787\n",
      "Finished training in 0:01:18.476553\n",
      "\n",
      "\n",
      "Training excluding subject 4...\n",
      "\n",
      "Rows per batch: 960\n",
      "[18:16:01] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:0.53065\ttrain-hr_err:0.03481\ttest-rmse:0.91194\ttest-hr_err:27.49865\n",
      "[5]\ttrain-rmse:0.53485\ttrain-hr_err:0.03481\ttest-rmse:0.91409\ttest-hr_err:27.51387\n",
      "[10]\ttrain-rmse:0.53908\ttrain-hr_err:0.03481\ttest-rmse:0.91625\ttest-hr_err:25.68871\n",
      "[15]\ttrain-rmse:0.54335\ttrain-hr_err:0.03481\ttest-rmse:0.91843\ttest-hr_err:24.88367\n",
      "[20]\ttrain-rmse:0.54765\ttrain-hr_err:0.03481\ttest-rmse:0.92065\ttest-hr_err:24.88367\n",
      "[25]\ttrain-rmse:0.55198\ttrain-hr_err:0.03481\ttest-rmse:0.92290\ttest-hr_err:24.36351\n",
      "[30]\ttrain-rmse:0.55636\ttrain-hr_err:0.02318\ttest-rmse:0.92519\ttest-hr_err:25.43017\n",
      "[35]\ttrain-rmse:0.56076\ttrain-hr_err:0.02318\ttest-rmse:0.92750\ttest-hr_err:25.43017\n",
      "[38]\ttrain-rmse:0.56341\ttrain-hr_err:0.02318\ttest-rmse:0.92890\ttest-hr_err:25.41070\n",
      "\n",
      "\n",
      "Fine-tuning...\n",
      "[18:16:13] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:1.07951\ttrain-hr_err:0.02318\ttest-rmse:0.92988\ttest-hr_err:25.41070\n",
      "[5]\ttrain-rmse:1.08790\ttrain-hr_err:0.02318\ttest-rmse:0.93483\ttest-hr_err:25.41070\n",
      "[8]\ttrain-rmse:1.09296\ttrain-hr_err:0.02318\ttest-rmse:0.93784\ttest-hr_err:25.41070\n",
      "[18:16:16] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:0.87171\ttrain-hr_err:9.26568\ttest-rmse:0.93812\ttest-hr_err:24.34417\n",
      "[5]\ttrain-rmse:0.87625\ttrain-hr_err:13.81006\ttest-rmse:0.93954\ttest-hr_err:12.36815\n",
      "[10]\ttrain-rmse:0.88078\ttrain-hr_err:13.74545\ttest-rmse:0.94100\ttest-hr_err:9.82239\n",
      "[15]\ttrain-rmse:0.88531\ttrain-hr_err:0.09616\ttest-rmse:0.94248\ttest-hr_err:9.50481\n",
      "[20]\ttrain-rmse:0.88984\ttrain-hr_err:0.09616\ttest-rmse:0.94399\ttest-hr_err:9.80517\n",
      "[25]\ttrain-rmse:0.89435\ttrain-hr_err:0.01520\ttest-rmse:0.94554\ttest-hr_err:12.06550\n",
      "[28]\ttrain-rmse:0.89706\ttrain-hr_err:0.01520\ttest-rmse:0.94647\ttest-hr_err:15.27548\n",
      "\n",
      "\n",
      "Fine-tuning...\n",
      "[18:16:26] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:1.33717\ttrain-hr_err:0.01520\ttest-rmse:0.94740\ttest-hr_err:14.21471\n",
      "[5]\ttrain-rmse:1.34429\ttrain-hr_err:1.22261\ttest-rmse:0.95206\ttest-hr_err:15.32170\n",
      "[7]\ttrain-rmse:1.34715\ttrain-hr_err:1.22261\ttest-rmse:0.95394\ttest-hr_err:15.32170\n",
      "[18:16:29] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:0.99205\ttrain-hr_err:4.69540\ttest-rmse:0.95508\ttest-hr_err:14.23203\n",
      "[5]\ttrain-rmse:0.99632\ttrain-hr_err:7.86124\ttest-rmse:0.95603\ttest-hr_err:8.71163\n",
      "[10]\ttrain-rmse:1.00060\ttrain-hr_err:18.54275\ttest-rmse:0.95701\ttest-hr_err:8.24609\n",
      "[15]\ttrain-rmse:1.00489\ttrain-hr_err:18.54275\ttest-rmse:0.95801\ttest-hr_err:8.37956\n",
      "[20]\ttrain-rmse:1.00917\ttrain-hr_err:13.20199\ttest-rmse:0.95906\ttest-hr_err:10.56997\n",
      "[25]\ttrain-rmse:1.01345\ttrain-hr_err:16.53065\ttest-rmse:0.96016\ttest-hr_err:16.63800\n",
      "[30]\ttrain-rmse:1.01774\ttrain-hr_err:16.53065\ttest-rmse:0.96125\ttest-hr_err:15.57581\n",
      "[32]\ttrain-rmse:1.01946\ttrain-hr_err:16.53065\ttest-rmse:0.96170\ttest-hr_err:15.60694\n",
      "\n",
      "\n",
      "Fine-tuning...\n",
      "[18:16:39] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:1.45424\ttrain-hr_err:16.53065\ttest-rmse:0.96235\ttest-hr_err:14.88502\n",
      "[5]\ttrain-rmse:1.46118\ttrain-hr_err:16.53065\ttest-rmse:0.96559\ttest-hr_err:11.77343\n",
      "[10]\ttrain-rmse:1.46817\ttrain-hr_err:20.99576\ttest-rmse:0.96890\ttest-hr_err:13.02453\n",
      "[11]\ttrain-rmse:1.46957\ttrain-hr_err:20.99576\ttest-rmse:0.96957\ttest-hr_err:13.05039\n",
      "[18:16:43] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:1.01926\ttrain-hr_err:24.08537\ttest-rmse:0.96985\ttest-hr_err:13.05039\n",
      "[5]\ttrain-rmse:1.02419\ttrain-hr_err:24.17562\ttest-rmse:0.97127\ttest-hr_err:13.02061\n",
      "[10]\ttrain-rmse:1.02914\ttrain-hr_err:15.75565\ttest-rmse:0.97273\ttest-hr_err:13.02261\n",
      "[15]\ttrain-rmse:1.03409\ttrain-hr_err:15.85492\ttest-rmse:0.97422\ttest-hr_err:11.82503\n",
      "[20]\ttrain-rmse:1.03905\ttrain-hr_err:15.85492\ttest-rmse:0.97575\ttest-hr_err:10.73162\n",
      "[25]\ttrain-rmse:1.04401\ttrain-hr_err:15.85492\ttest-rmse:0.97730\ttest-hr_err:8.86601\n",
      "[30]\ttrain-rmse:1.04897\ttrain-hr_err:11.69458\ttest-rmse:0.97886\ttest-hr_err:9.63286\n",
      "[35]\ttrain-rmse:1.05393\ttrain-hr_err:11.79814\ttest-rmse:0.98046\ttest-hr_err:8.30547\n",
      "[40]\ttrain-rmse:1.05889\ttrain-hr_err:11.69458\ttest-rmse:0.98209\ttest-hr_err:10.27407\n",
      "[45]\ttrain-rmse:1.06384\ttrain-hr_err:3.37388\ttest-rmse:0.98372\ttest-hr_err:10.27407\n",
      "[50]\ttrain-rmse:1.06879\ttrain-hr_err:0.78646\ttest-rmse:0.98538\ttest-hr_err:7.06354\n",
      "[53]\ttrain-rmse:1.07176\ttrain-hr_err:0.78646\ttest-rmse:0.98636\ttest-hr_err:6.23156\n",
      "\n",
      "\n",
      "Fine-tuning...\n",
      "[18:17:01] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:1.59120\ttrain-hr_err:0.66622\ttest-rmse:0.98717\ttest-hr_err:6.25998\n",
      "[5]\ttrain-rmse:1.59909\ttrain-hr_err:0.66622\ttest-rmse:0.99181\ttest-hr_err:7.00793\n",
      "[8]\ttrain-rmse:1.60387\ttrain-hr_err:0.66622\ttest-rmse:0.99463\ttest-hr_err:7.60805\n",
      "[18:17:04] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:0.72629\ttrain-hr_err:24.31260\ttest-rmse:0.99520\ttest-hr_err:7.63400\n",
      "[5]\ttrain-rmse:0.73125\ttrain-hr_err:28.76735\ttest-rmse:0.99860\ttest-hr_err:7.76297\n",
      "[10]\ttrain-rmse:0.73624\ttrain-hr_err:28.76735\ttest-rmse:1.00205\ttest-hr_err:8.23864\n",
      "[15]\ttrain-rmse:0.74127\ttrain-hr_err:28.76735\ttest-rmse:1.00553\ttest-hr_err:7.15020\n",
      "[20]\ttrain-rmse:0.74633\ttrain-hr_err:28.76735\ttest-rmse:1.00901\ttest-hr_err:7.15020\n",
      "[25]\ttrain-rmse:0.75142\ttrain-hr_err:28.76735\ttest-rmse:1.01244\ttest-hr_err:7.15425\n",
      "[30]\ttrain-rmse:0.75651\ttrain-hr_err:28.76735\ttest-rmse:1.01574\ttest-hr_err:7.66431\n",
      "[35]\ttrain-rmse:0.76161\ttrain-hr_err:28.76735\ttest-rmse:1.01879\ttest-hr_err:7.66431\n",
      "[40]\ttrain-rmse:0.76673\ttrain-hr_err:24.31260\ttest-rmse:1.02178\ttest-hr_err:9.08234\n",
      "[42]\ttrain-rmse:0.76879\ttrain-hr_err:24.40573\ttest-rmse:1.02297\ttest-hr_err:9.08234\n",
      "\n",
      "\n",
      "Fine-tuning...\n",
      "[18:17:17] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:1.40607\ttrain-hr_err:24.38641\ttest-rmse:1.02410\ttest-hr_err:9.08234\n",
      "[5]\ttrain-rmse:1.41427\ttrain-hr_err:28.84116\ttest-rmse:1.02975\ttest-hr_err:9.67409\n",
      "[8]\ttrain-rmse:1.41922\ttrain-hr_err:28.84116\ttest-rmse:1.03318\ttest-hr_err:9.62603\n",
      "Finished training in 0:01:18.550745\n",
      "\n",
      "\n",
      "Training excluding subject 4...\n",
      "\n",
      "Rows per batch: 960\n",
      "[18:17:23] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:0.61201\ttrain-hr_err:15.26879\ttest-rmse:0.73415\ttest-hr_err:27.39398\n",
      "[5]\ttrain-rmse:0.61606\ttrain-hr_err:15.26879\ttest-rmse:0.73623\ttest-hr_err:27.39398\n",
      "[10]\ttrain-rmse:0.62014\ttrain-hr_err:15.26879\ttest-rmse:0.73834\ttest-hr_err:27.39398\n",
      "[15]\ttrain-rmse:0.62418\ttrain-hr_err:15.26879\ttest-rmse:0.74061\ttest-hr_err:27.59806\n",
      "[20]\ttrain-rmse:0.62823\ttrain-hr_err:15.26879\ttest-rmse:0.74293\ttest-hr_err:28.75733\n",
      "[25]\ttrain-rmse:0.63231\ttrain-hr_err:15.26879\ttest-rmse:0.74530\ttest-hr_err:29.18050\n",
      "[28]\ttrain-rmse:0.63477\ttrain-hr_err:15.26879\ttest-rmse:0.74674\ttest-hr_err:29.16637\n",
      "\n",
      "\n",
      "Fine-tuning...\n",
      "[18:17:32] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:1.10612\ttrain-hr_err:10.18942\ttest-rmse:0.74828\ttest-hr_err:29.16637\n",
      "[5]\ttrain-rmse:1.11356\ttrain-hr_err:10.06638\ttest-rmse:0.75358\ttest-hr_err:29.16637\n",
      "[8]\ttrain-rmse:1.11805\ttrain-hr_err:10.06638\ttest-rmse:0.75679\ttest-hr_err:29.16637\n",
      "[18:17:35] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:0.85535\ttrain-hr_err:3.33396\ttest-rmse:0.75720\ttest-hr_err:31.06904\n",
      "[5]\ttrain-rmse:0.85994\ttrain-hr_err:3.47557\ttest-rmse:0.75923\ttest-hr_err:17.75377\n",
      "[10]\ttrain-rmse:0.86455\ttrain-hr_err:12.37863\ttest-rmse:0.76130\ttest-hr_err:23.58317\n",
      "[15]\ttrain-rmse:0.86916\ttrain-hr_err:8.21100\ttest-rmse:0.76340\ttest-hr_err:21.99928\n",
      "[20]\ttrain-rmse:0.87376\ttrain-hr_err:0.33360\ttest-rmse:0.76555\ttest-hr_err:22.79151\n",
      "[22]\ttrain-rmse:0.87560\ttrain-hr_err:0.25303\ttest-rmse:0.76642\ttest-hr_err:24.98079\n",
      "\n",
      "\n",
      "Fine-tuning...\n",
      "[18:17:42] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:1.29222\ttrain-hr_err:0.25303\ttest-rmse:0.76739\ttest-hr_err:24.96359\n",
      "[5]\ttrain-rmse:1.29915\ttrain-hr_err:0.45411\ttest-rmse:0.77231\ttest-hr_err:23.88430\n",
      "[10]\ttrain-rmse:1.30610\ttrain-hr_err:0.45411\ttest-rmse:0.77727\ttest-hr_err:26.11293\n",
      "[13]\ttrain-rmse:1.31028\ttrain-hr_err:0.45411\ttest-rmse:0.78029\ttest-hr_err:26.11293\n",
      "[18:17:46] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:0.60069\ttrain-hr_err:36.13419\ttest-rmse:0.78093\ttest-hr_err:26.11293\n",
      "[5]\ttrain-rmse:0.60544\ttrain-hr_err:39.09678\ttest-rmse:0.78420\ttest-hr_err:24.70019\n",
      "[10]\ttrain-rmse:0.61024\ttrain-hr_err:39.09678\ttest-rmse:0.78756\ttest-hr_err:24.70019\n",
      "[15]\ttrain-rmse:0.61507\ttrain-hr_err:39.09678\ttest-rmse:0.79096\ttest-hr_err:25.04469\n",
      "[20]\ttrain-rmse:0.61994\ttrain-hr_err:39.09678\ttest-rmse:0.79442\ttest-hr_err:22.68992\n",
      "[25]\ttrain-rmse:0.62485\ttrain-hr_err:39.09678\ttest-rmse:0.79792\ttest-hr_err:22.71353\n",
      "[30]\ttrain-rmse:0.62979\ttrain-hr_err:39.09678\ttest-rmse:0.80148\ttest-hr_err:25.23652\n",
      "[34]\ttrain-rmse:0.63377\ttrain-hr_err:34.66771\ttest-rmse:0.80435\ttest-hr_err:26.47309\n",
      "\n",
      "\n",
      "Fine-tuning...\n",
      "[18:17:56] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:1.23026\ttrain-hr_err:34.53985\ttest-rmse:0.80645\ttest-hr_err:26.47309\n",
      "[5]\ttrain-rmse:1.23952\ttrain-hr_err:34.53985\ttest-rmse:0.81338\ttest-hr_err:26.47309\n",
      "[8]\ttrain-rmse:1.24510\ttrain-hr_err:34.53985\ttest-rmse:0.81758\ttest-hr_err:26.47309\n",
      "[18:17:59] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:0.94682\ttrain-hr_err:15.06186\ttest-rmse:0.81804\ttest-hr_err:25.23652\n",
      "[5]\ttrain-rmse:0.95147\ttrain-hr_err:6.14336\ttest-rmse:0.82040\ttest-hr_err:27.59593\n",
      "[10]\ttrain-rmse:0.95602\ttrain-hr_err:6.07007\ttest-rmse:0.82278\ttest-hr_err:26.05019\n",
      "[15]\ttrain-rmse:0.96014\ttrain-hr_err:6.07007\ttest-rmse:0.82489\ttest-hr_err:27.29080\n",
      "\n",
      "\n",
      "Fine-tuning...\n",
      "[18:18:04] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:1.47199\ttrain-hr_err:5.93090\ttest-rmse:0.82650\ttest-hr_err:28.55396\n",
      "[5]\ttrain-rmse:1.48000\ttrain-hr_err:5.93090\ttest-rmse:0.83226\ttest-hr_err:29.65110\n",
      "[7]\ttrain-rmse:1.48321\ttrain-hr_err:5.85777\ttest-rmse:0.83494\ttest-hr_err:30.25317\n",
      "[18:18:07] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:1.04668\ttrain-hr_err:16.04526\ttest-rmse:0.83678\ttest-hr_err:29.41806\n",
      "[5]\ttrain-rmse:1.05125\ttrain-hr_err:18.59209\ttest-rmse:0.83923\ttest-hr_err:25.84480\n",
      "[10]\ttrain-rmse:1.05585\ttrain-hr_err:18.17578\ttest-rmse:0.84160\ttest-hr_err:26.98813\n",
      "[15]\ttrain-rmse:1.06045\ttrain-hr_err:4.97544\ttest-rmse:0.84400\ttest-hr_err:25.90948\n",
      "[20]\ttrain-rmse:1.06507\ttrain-hr_err:13.63782\ttest-rmse:0.84634\ttest-hr_err:24.85323\n",
      "[25]\ttrain-rmse:1.06970\ttrain-hr_err:17.93641\ttest-rmse:0.84873\ttest-hr_err:19.17966\n",
      "[30]\ttrain-rmse:1.07435\ttrain-hr_err:17.85625\ttest-rmse:0.85112\ttest-hr_err:15.93504\n",
      "[35]\ttrain-rmse:1.07899\ttrain-hr_err:12.11735\ttest-rmse:0.85351\ttest-hr_err:15.62326\n",
      "[40]\ttrain-rmse:1.08365\ttrain-hr_err:12.11735\ttest-rmse:0.85591\ttest-hr_err:15.58190\n",
      "[45]\ttrain-rmse:1.08831\ttrain-hr_err:12.11735\ttest-rmse:0.85840\ttest-hr_err:15.58591\n",
      "[50]\ttrain-rmse:1.09297\ttrain-hr_err:7.89757\ttest-rmse:0.86099\ttest-hr_err:15.58326\n",
      "[55]\ttrain-rmse:1.09763\ttrain-hr_err:7.89757\ttest-rmse:0.86363\ttest-hr_err:16.29700\n",
      "[59]\ttrain-rmse:1.10137\ttrain-hr_err:7.89757\ttest-rmse:0.86577\ttest-hr_err:14.91780\n",
      "\n",
      "\n",
      "Fine-tuning...\n",
      "[18:18:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:1.66461\ttrain-hr_err:7.89757\ttest-rmse:0.86698\ttest-hr_err:14.91780\n",
      "[5]\ttrain-rmse:1.67284\ttrain-hr_err:7.89757\ttest-rmse:0.87312\ttest-hr_err:16.39088\n",
      "[10]\ttrain-rmse:1.68117\ttrain-hr_err:3.58495\ttest-rmse:0.87901\ttest-hr_err:17.94701\n",
      "Finished training in 0:01:08.544881\n",
      "\n",
      "\n",
      "Training excluding subject 5...\n",
      "\n",
      "Rows per batch: 960\n",
      "[18:18:37] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:0.53387\ttrain-hr_err:3.34143\ttest-rmse:0.84894\ttest-hr_err:31.91691\n",
      "[5]\ttrain-rmse:0.53826\ttrain-hr_err:3.34143\ttest-rmse:0.85052\ttest-hr_err:31.91691\n",
      "[10]\ttrain-rmse:0.54268\ttrain-hr_err:3.34143\ttest-rmse:0.85213\ttest-hr_err:31.91691\n",
      "[15]\ttrain-rmse:0.54714\ttrain-hr_err:3.34143\ttest-rmse:0.85360\ttest-hr_err:31.98735\n",
      "[20]\ttrain-rmse:0.55164\ttrain-hr_err:3.39806\ttest-rmse:0.85506\ttest-hr_err:30.58760\n",
      "[25]\ttrain-rmse:0.55616\ttrain-hr_err:3.39806\ttest-rmse:0.85665\ttest-hr_err:30.58760\n",
      "[30]\ttrain-rmse:0.56073\ttrain-hr_err:3.39806\ttest-rmse:0.85838\ttest-hr_err:30.58760\n",
      "[31]\ttrain-rmse:0.56164\ttrain-hr_err:3.39806\ttest-rmse:0.85873\ttest-hr_err:30.58760\n",
      "\n",
      "\n",
      "Fine-tuning...\n",
      "[18:18:49] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:1.07928\ttrain-hr_err:3.46325\ttest-rmse:0.86011\ttest-hr_err:30.57452\n",
      "[5]\ttrain-rmse:1.08780\ttrain-hr_err:3.46325\ttest-rmse:0.86529\ttest-hr_err:30.57452\n",
      "[8]\ttrain-rmse:1.09293\ttrain-hr_err:3.46325\ttest-rmse:0.86844\ttest-hr_err:30.57452\n",
      "[18:18:52] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:0.99496\ttrain-hr_err:31.65621\ttest-rmse:0.86864\ttest-hr_err:30.52879\n",
      "[5]\ttrain-rmse:0.99903\ttrain-hr_err:1.06777\ttest-rmse:0.86965\ttest-hr_err:13.45589\n",
      "[10]\ttrain-rmse:1.00310\ttrain-hr_err:1.16616\ttest-rmse:0.87069\ttest-hr_err:15.07483\n",
      "[15]\ttrain-rmse:1.00717\ttrain-hr_err:1.16616\ttest-rmse:0.87177\ttest-hr_err:8.98268\n",
      "[20]\ttrain-rmse:1.01124\ttrain-hr_err:1.16616\ttest-rmse:0.87297\ttest-hr_err:10.46557\n",
      "[25]\ttrain-rmse:1.01531\ttrain-hr_err:1.16616\ttest-rmse:0.87454\ttest-hr_err:6.80322\n",
      "[30]\ttrain-rmse:1.01938\ttrain-hr_err:1.16616\ttest-rmse:0.87614\ttest-hr_err:6.77664\n",
      "[35]\ttrain-rmse:1.02345\ttrain-hr_err:1.16616\ttest-rmse:0.87777\ttest-hr_err:6.99921\n",
      "[40]\ttrain-rmse:1.02751\ttrain-hr_err:1.16616\ttest-rmse:0.87943\ttest-hr_err:6.97491\n",
      "[45]\ttrain-rmse:1.03157\ttrain-hr_err:1.16616\ttest-rmse:0.88102\ttest-hr_err:6.95048\n",
      "\n",
      "\n",
      "Fine-tuning...\n",
      "[18:19:07] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:1.42343\ttrain-hr_err:1.16616\ttest-rmse:0.88161\ttest-hr_err:5.93527\n",
      "[5]\ttrain-rmse:1.42992\ttrain-hr_err:1.16616\ttest-rmse:0.88459\ttest-hr_err:5.14102\n",
      "[10]\ttrain-rmse:1.43644\ttrain-hr_err:1.16616\ttest-rmse:0.88762\ttest-hr_err:6.46602\n",
      "[12]\ttrain-rmse:1.43905\ttrain-hr_err:1.16616\ttest-rmse:0.88884\ttest-hr_err:6.46602\n",
      "[18:19:11] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:0.56064\ttrain-hr_err:19.99122\ttest-rmse:0.88940\ttest-hr_err:7.10204\n",
      "[5]\ttrain-rmse:0.56509\ttrain-hr_err:18.82268\ttest-rmse:0.89223\ttest-hr_err:7.10204\n",
      "[10]\ttrain-rmse:0.56957\ttrain-hr_err:18.74819\ttest-rmse:0.89511\ttest-hr_err:7.10204\n",
      "[15]\ttrain-rmse:0.57409\ttrain-hr_err:27.73012\ttest-rmse:0.89793\ttest-hr_err:6.85700\n",
      "[20]\ttrain-rmse:0.57864\ttrain-hr_err:27.66596\ttest-rmse:0.90079\ttest-hr_err:6.85700\n",
      "[25]\ttrain-rmse:0.58322\ttrain-hr_err:27.60166\ttest-rmse:0.90370\ttest-hr_err:6.82677\n",
      "[30]\ttrain-rmse:0.58785\ttrain-hr_err:27.60166\ttest-rmse:0.90665\ttest-hr_err:6.82677\n",
      "[35]\ttrain-rmse:0.59250\ttrain-hr_err:27.53720\ttest-rmse:0.90968\ttest-hr_err:6.82677\n",
      "[36]\ttrain-rmse:0.59344\ttrain-hr_err:27.53720\ttest-rmse:0.91029\ttest-hr_err:6.82677\n",
      "\n",
      "\n",
      "Fine-tuning...\n",
      "[18:19:23] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:1.17883\ttrain-hr_err:27.26118\ttest-rmse:0.91209\ttest-hr_err:6.82677\n",
      "[5]\ttrain-rmse:1.18770\ttrain-hr_err:27.26118\ttest-rmse:0.91806\ttest-hr_err:6.82677\n",
      "[8]\ttrain-rmse:1.19305\ttrain-hr_err:27.26118\ttest-rmse:0.92168\ttest-hr_err:6.82677\n",
      "[18:19:25] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:0.70058\ttrain-hr_err:25.06375\ttest-rmse:0.92229\ttest-hr_err:6.82677\n",
      "[5]\ttrain-rmse:0.70521\ttrain-hr_err:22.49433\ttest-rmse:0.92537\ttest-hr_err:6.82677\n",
      "[10]\ttrain-rmse:0.70986\ttrain-hr_err:22.49433\ttest-rmse:0.92852\ttest-hr_err:8.37453\n",
      "[15]\ttrain-rmse:0.71455\ttrain-hr_err:22.49433\ttest-rmse:0.93174\ttest-hr_err:8.37453\n",
      "[16]\ttrain-rmse:0.71549\ttrain-hr_err:22.49433\ttest-rmse:0.93239\ttest-hr_err:8.37453\n",
      "\n",
      "\n",
      "Fine-tuning...\n",
      "[18:19:30] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:1.28893\ttrain-hr_err:22.49433\ttest-rmse:0.93348\ttest-hr_err:8.37453\n",
      "[5]\ttrain-rmse:1.29694\ttrain-hr_err:22.49433\ttest-rmse:0.93903\ttest-hr_err:8.37453\n",
      "[7]\ttrain-rmse:1.30016\ttrain-hr_err:22.49433\ttest-rmse:0.94123\ttest-hr_err:8.37453\n",
      "[18:19:33] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:0.89722\ttrain-hr_err:30.91311\ttest-rmse:0.94294\ttest-hr_err:8.34439\n",
      "[5]\ttrain-rmse:0.90200\ttrain-hr_err:30.96489\ttest-rmse:0.94597\ttest-hr_err:6.76658\n",
      "[10]\ttrain-rmse:0.90679\ttrain-hr_err:32.02003\ttest-rmse:0.94903\ttest-hr_err:2.50696\n",
      "[15]\ttrain-rmse:0.91156\ttrain-hr_err:37.19523\ttest-rmse:0.95185\ttest-hr_err:5.82255\n",
      "[20]\ttrain-rmse:0.91632\ttrain-hr_err:24.99238\ttest-rmse:0.95462\ttest-hr_err:3.38623\n",
      "[25]\ttrain-rmse:0.92107\ttrain-hr_err:13.50960\ttest-rmse:0.95744\ttest-hr_err:3.41082\n",
      "\n",
      "\n",
      "Fine-tuning...\n",
      "[18:19:41] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:1.42341\ttrain-hr_err:13.56956\ttest-rmse:0.95921\ttest-hr_err:3.43372\n",
      "[5]\ttrain-rmse:1.43123\ttrain-hr_err:9.36364\ttest-rmse:0.96530\ttest-hr_err:7.91731\n",
      "[8]\ttrain-rmse:1.43594\ttrain-hr_err:9.36364\ttest-rmse:0.96898\ttest-hr_err:8.52995\n",
      "Finished training in 0:01:06.857632\n",
      "\n",
      "\n",
      "Training excluding subject 5...\n",
      "\n",
      "Rows per batch: 960\n",
      "[18:19:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:0.53384\ttrain-hr_err:2.53933\ttest-rmse:0.80087\ttest-hr_err:34.85365\n",
      "[5]\ttrain-rmse:0.53821\ttrain-hr_err:2.53933\ttest-rmse:0.80285\ttest-hr_err:34.85365\n",
      "[10]\ttrain-rmse:0.54263\ttrain-hr_err:3.79061\ttest-rmse:0.80485\ttest-hr_err:34.85365\n",
      "[15]\ttrain-rmse:0.54710\ttrain-hr_err:3.79061\ttest-rmse:0.80690\ttest-hr_err:34.85365\n",
      "\n",
      "\n",
      "Fine-tuning...\n",
      "[18:19:53] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:1.04946\ttrain-hr_err:3.85580\ttest-rmse:0.80837\ttest-hr_err:34.85365\n",
      "[5]\ttrain-rmse:1.05780\ttrain-hr_err:3.85580\ttest-rmse:0.81370\ttest-hr_err:34.85365\n",
      "[7]\ttrain-rmse:1.06115\ttrain-hr_err:3.85580\ttest-rmse:0.81586\ttest-hr_err:34.85365\n",
      "[18:19:55] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:0.99481\ttrain-hr_err:16.35269\ttest-rmse:0.81723\ttest-hr_err:30.82375\n",
      "[5]\ttrain-rmse:0.99903\ttrain-hr_err:8.28036\ttest-rmse:0.81864\ttest-hr_err:9.97741\n",
      "[10]\ttrain-rmse:1.00326\ttrain-hr_err:1.46267\ttest-rmse:0.82009\ttest-hr_err:6.13062\n",
      "[15]\ttrain-rmse:1.00741\ttrain-hr_err:1.36361\ttest-rmse:0.82148\ttest-hr_err:9.10697\n",
      "[20]\ttrain-rmse:1.01147\ttrain-hr_err:1.36361\ttest-rmse:0.82277\ttest-hr_err:12.11518\n",
      "[25]\ttrain-rmse:1.01552\ttrain-hr_err:1.36361\ttest-rmse:0.82409\ttest-hr_err:19.53509\n",
      "[26]\ttrain-rmse:1.01633\ttrain-hr_err:1.36361\ttest-rmse:0.82435\ttest-hr_err:19.53509\n",
      "\n",
      "\n",
      "Fine-tuning...\n",
      "[18:20:03] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:1.39275\ttrain-hr_err:1.36361\ttest-rmse:0.82529\ttest-hr_err:18.11830\n",
      "[5]\ttrain-rmse:1.39929\ttrain-hr_err:1.36361\ttest-rmse:0.82876\ttest-hr_err:15.11661\n",
      "[10]\ttrain-rmse:1.40586\ttrain-hr_err:1.36361\ttest-rmse:0.83224\ttest-hr_err:8.65034\n",
      "[15]\ttrain-rmse:1.41245\ttrain-hr_err:1.26477\ttest-rmse:0.83577\ttest-hr_err:9.86064\n",
      "[20]\ttrain-rmse:1.41905\ttrain-hr_err:1.26477\ttest-rmse:0.83932\ttest-hr_err:6.60637\n",
      "[25]\ttrain-rmse:1.42568\ttrain-hr_err:1.26477\ttest-rmse:0.84285\ttest-hr_err:8.07595\n",
      "[27]\ttrain-rmse:1.42834\ttrain-hr_err:1.26477\ttest-rmse:0.84428\ttest-hr_err:7.17512\n",
      "[18:20:11] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:0.86232\ttrain-hr_err:16.27652\ttest-rmse:0.84465\ttest-hr_err:7.17512\n",
      "[5]\ttrain-rmse:0.86687\ttrain-hr_err:19.57724\ttest-rmse:0.84653\ttest-hr_err:8.10481\n",
      "[10]\ttrain-rmse:0.87142\ttrain-hr_err:9.84340\ttest-rmse:0.84841\ttest-hr_err:8.10481\n",
      "[15]\ttrain-rmse:0.87596\ttrain-hr_err:4.47420\ttest-rmse:0.85029\ttest-hr_err:5.03857\n",
      "[20]\ttrain-rmse:0.88048\ttrain-hr_err:0.16211\ttest-rmse:0.85218\ttest-hr_err:4.16640\n",
      "[25]\ttrain-rmse:0.88499\ttrain-hr_err:0.20658\ttest-rmse:0.85411\ttest-hr_err:4.16640\n",
      "[30]\ttrain-rmse:0.88949\ttrain-hr_err:0.13115\ttest-rmse:0.85608\ttest-hr_err:6.94911\n",
      "[35]\ttrain-rmse:0.89399\ttrain-hr_err:0.13115\ttest-rmse:0.85812\ttest-hr_err:7.99840\n",
      "[36]\ttrain-rmse:0.89488\ttrain-hr_err:0.86492\ttest-rmse:0.85853\ttest-hr_err:7.99840\n",
      "\n",
      "\n",
      "Fine-tuning...\n",
      "[18:20:22] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:1.34121\ttrain-hr_err:0.86492\ttest-rmse:0.85959\ttest-hr_err:7.99840\n",
      "[5]\ttrain-rmse:1.34826\ttrain-hr_err:0.86492\ttest-rmse:0.86491\ttest-hr_err:6.92822\n",
      "[10]\ttrain-rmse:1.35533\ttrain-hr_err:0.86492\ttest-rmse:0.87025\ttest-hr_err:7.40011\n",
      "[11]\ttrain-rmse:1.35675\ttrain-hr_err:0.86492\ttest-rmse:0.87132\ttest-hr_err:7.40011\n",
      "[18:20:25] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:0.69713\ttrain-hr_err:33.84661\ttest-rmse:0.87185\ttest-hr_err:5.93726\n",
      "[5]\ttrain-rmse:0.70185\ttrain-hr_err:36.18178\ttest-rmse:0.87456\ttest-hr_err:10.26821\n",
      "[10]\ttrain-rmse:0.70653\ttrain-hr_err:36.07681\ttest-rmse:0.87766\ttest-hr_err:12.78788\n",
      "[15]\ttrain-rmse:0.71121\ttrain-hr_err:36.07681\ttest-rmse:0.88096\ttest-hr_err:13.23200\n",
      "\n",
      "\n",
      "Fine-tuning...\n",
      "[18:20:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:1.28097\ttrain-hr_err:30.99745\ttest-rmse:0.88302\ttest-hr_err:13.23200\n",
      "[5]\ttrain-rmse:1.28940\ttrain-hr_err:30.99745\ttest-rmse:0.89018\ttest-hr_err:13.26461\n",
      "[7]\ttrain-rmse:1.29278\ttrain-hr_err:30.99745\ttest-rmse:0.89306\ttest-hr_err:13.26461\n",
      "[18:20:34] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:0.92932\ttrain-hr_err:32.29176\ttest-rmse:0.89485\ttest-hr_err:13.29730\n",
      "[5]\ttrain-rmse:0.93409\ttrain-hr_err:23.14478\ttest-rmse:0.89681\ttest-hr_err:10.87289\n",
      "[10]\ttrain-rmse:0.93890\ttrain-hr_err:23.14478\ttest-rmse:0.89864\ttest-hr_err:10.17139\n",
      "[15]\ttrain-rmse:0.94367\ttrain-hr_err:18.51270\ttest-rmse:0.90057\ttest-hr_err:6.60756\n",
      "[20]\ttrain-rmse:0.94844\ttrain-hr_err:10.25596\ttest-rmse:0.90250\ttest-hr_err:6.68738\n",
      "[25]\ttrain-rmse:0.95318\ttrain-hr_err:10.25596\ttest-rmse:0.90433\ttest-hr_err:3.96768\n",
      "[30]\ttrain-rmse:0.95795\ttrain-hr_err:5.83709\ttest-rmse:0.90619\ttest-hr_err:3.61813\n",
      "[35]\ttrain-rmse:0.96271\ttrain-hr_err:5.83709\ttest-rmse:0.90807\ttest-hr_err:3.61813\n",
      "[40]\ttrain-rmse:0.96748\ttrain-hr_err:4.19988\ttest-rmse:0.90996\ttest-hr_err:5.20819\n",
      "[41]\ttrain-rmse:0.96843\ttrain-hr_err:4.19988\ttest-rmse:0.91034\ttest-hr_err:5.24173\n",
      "\n",
      "\n",
      "Fine-tuning...\n",
      "[18:20:47] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:1.51556\ttrain-hr_err:1.35054\ttest-rmse:0.91197\ttest-hr_err:5.24173\n",
      "[5]\ttrain-rmse:1.52354\ttrain-hr_err:1.35054\ttest-rmse:0.91821\ttest-hr_err:5.24173\n",
      "[8]\ttrain-rmse:1.52835\ttrain-hr_err:1.26890\ttest-rmse:0.92197\ttest-hr_err:5.24173\n",
      "Finished training in 0:01:02.369261\n",
      "\n",
      "\n",
      "Training excluding subject 5...\n",
      "\n",
      "Rows per batch: 960\n",
      "[18:20:54] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:0.50196\ttrain-hr_err:25.50694\ttest-rmse:0.88857\ttest-hr_err:26.87759\n",
      "[5]\ttrain-rmse:0.50594\ttrain-hr_err:25.50694\ttest-rmse:0.89084\ttest-hr_err:26.87759\n",
      "[10]\ttrain-rmse:0.50995\ttrain-hr_err:25.50694\ttest-rmse:0.89314\ttest-hr_err:26.08790\n",
      "[15]\ttrain-rmse:0.51399\ttrain-hr_err:25.50694\ttest-rmse:0.89548\ttest-hr_err:26.08790\n",
      "[20]\ttrain-rmse:0.51806\ttrain-hr_err:25.50694\ttest-rmse:0.89785\ttest-hr_err:26.08790\n",
      "[23]\ttrain-rmse:0.52052\ttrain-hr_err:29.85083\ttest-rmse:0.89929\ttest-hr_err:26.08790\n",
      "\n",
      "\n",
      "Fine-tuning...\n",
      "[18:21:01] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:1.02079\ttrain-hr_err:29.85083\ttest-rmse:0.90072\ttest-hr_err:26.08790\n",
      "[5]\ttrain-rmse:1.02877\ttrain-hr_err:29.85083\ttest-rmse:0.90553\ttest-hr_err:26.08790\n",
      "[8]\ttrain-rmse:1.03358\ttrain-hr_err:29.85083\ttest-rmse:0.90845\ttest-hr_err:26.08790\n",
      "[18:21:04] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:0.56090\ttrain-hr_err:20.78457\ttest-rmse:0.90897\ttest-hr_err:26.10653\n",
      "[5]\ttrain-rmse:0.56531\ttrain-hr_err:20.70901\ttest-rmse:0.91165\ttest-hr_err:25.47564\n",
      "[10]\ttrain-rmse:0.56975\ttrain-hr_err:24.83805\ttest-rmse:0.91436\ttest-hr_err:23.76878\n",
      "[15]\ttrain-rmse:0.57423\ttrain-hr_err:24.83805\ttest-rmse:0.91734\ttest-hr_err:23.52247\n",
      "[20]\ttrain-rmse:0.57874\ttrain-hr_err:24.83805\ttest-rmse:0.92041\ttest-hr_err:18.91190\n",
      "[25]\ttrain-rmse:0.58329\ttrain-hr_err:24.83805\ttest-rmse:0.92353\ttest-hr_err:17.73949\n",
      "[30]\ttrain-rmse:0.58787\ttrain-hr_err:20.70901\ttest-rmse:0.92668\ttest-hr_err:17.73949\n",
      "[35]\ttrain-rmse:0.59249\ttrain-hr_err:20.70901\ttest-rmse:0.92987\ttest-hr_err:17.76843\n",
      "[40]\ttrain-rmse:0.59716\ttrain-hr_err:20.70901\ttest-rmse:0.93310\ttest-hr_err:18.30137\n",
      "\n",
      "\n",
      "Fine-tuning...\n",
      "[18:21:15] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:1.15168\ttrain-hr_err:20.70901\ttest-rmse:0.93422\ttest-hr_err:18.30137\n",
      "[5]\ttrain-rmse:1.16051\ttrain-hr_err:20.70901\ttest-rmse:0.93986\ttest-hr_err:18.30137\n",
      "[7]\ttrain-rmse:1.16407\ttrain-hr_err:20.70901\ttest-rmse:0.94215\ttest-hr_err:18.30137\n",
      "[18:21:17] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:0.61338\ttrain-hr_err:9.65388\ttest-rmse:0.94375\ttest-hr_err:18.30137\n",
      "[5]\ttrain-rmse:0.61842\ttrain-hr_err:9.65388\ttest-rmse:0.94607\ttest-hr_err:17.27867\n",
      "[10]\ttrain-rmse:0.62351\ttrain-hr_err:6.53233\ttest-rmse:0.94845\ttest-hr_err:17.55401\n",
      "[15]\ttrain-rmse:0.62864\ttrain-hr_err:6.53233\ttest-rmse:0.95086\ttest-hr_err:18.37756\n",
      "[20]\ttrain-rmse:0.63382\ttrain-hr_err:6.53233\ttest-rmse:0.95332\ttest-hr_err:16.76051\n",
      "[25]\ttrain-rmse:0.63903\ttrain-hr_err:10.82183\ttest-rmse:0.95582\ttest-hr_err:15.32553\n",
      "[30]\ttrain-rmse:0.64430\ttrain-hr_err:10.82183\ttest-rmse:0.95837\ttest-hr_err:15.29654\n",
      "[32]\ttrain-rmse:0.64641\ttrain-hr_err:10.82183\ttest-rmse:0.95938\ttest-hr_err:15.28053\n",
      "\n",
      "\n",
      "Fine-tuning...\n",
      "[18:21:27] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:1.25640\ttrain-hr_err:10.60673\ttest-rmse:0.96119\ttest-hr_err:17.13024\n",
      "[5]\ttrain-rmse:1.26588\ttrain-hr_err:10.60673\ttest-rmse:0.96774\ttest-hr_err:17.13024\n",
      "[8]\ttrain-rmse:1.27159\ttrain-hr_err:10.60673\ttest-rmse:0.97171\ttest-hr_err:17.13024\n",
      "[18:21:29] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:0.93566\ttrain-hr_err:23.52515\ttest-rmse:0.97215\ttest-hr_err:17.14359\n",
      "[5]\ttrain-rmse:0.94052\ttrain-hr_err:18.65548\ttest-rmse:0.97440\ttest-hr_err:16.37819\n",
      "[10]\ttrain-rmse:0.94542\ttrain-hr_err:9.27982\ttest-rmse:0.97661\ttest-hr_err:10.54914\n",
      "[15]\ttrain-rmse:0.95037\ttrain-hr_err:4.50211\ttest-rmse:0.97879\ttest-hr_err:12.41384\n",
      "[20]\ttrain-rmse:0.95537\ttrain-hr_err:0.21988\ttest-rmse:0.98105\ttest-hr_err:12.41384\n",
      "[25]\ttrain-rmse:0.96036\ttrain-hr_err:0.29877\ttest-rmse:0.98335\ttest-hr_err:12.41811\n",
      "[27]\ttrain-rmse:0.96235\ttrain-hr_err:0.29877\ttest-rmse:0.98427\ttest-hr_err:12.41811\n",
      "\n",
      "\n",
      "Fine-tuning...\n",
      "[18:21:37] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:1.50184\ttrain-hr_err:0.29877\ttest-rmse:0.98538\ttest-hr_err:12.41811\n",
      "[5]\ttrain-rmse:1.50991\ttrain-hr_err:0.21988\ttest-rmse:0.99107\ttest-hr_err:13.82306\n",
      "[7]\ttrain-rmse:1.51315\ttrain-hr_err:0.21988\ttest-rmse:0.99337\ttest-hr_err:15.59677\n",
      "[18:21:39] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:0.93078\ttrain-hr_err:0.20662\ttest-rmse:0.99501\ttest-hr_err:15.57597\n",
      "[5]\ttrain-rmse:0.93547\ttrain-hr_err:4.48179\ttest-rmse:0.99746\ttest-hr_err:15.62082\n",
      "[10]\ttrain-rmse:0.94030\ttrain-hr_err:8.88458\ttest-rmse:0.99995\ttest-hr_err:15.22795\n",
      "[15]\ttrain-rmse:0.94485\ttrain-hr_err:4.54560\ttest-rmse:1.00207\ttest-hr_err:12.72568\n",
      "[20]\ttrain-rmse:0.94941\ttrain-hr_err:4.54560\ttest-rmse:1.00423\ttest-hr_err:15.67099\n",
      "[25]\ttrain-rmse:0.95399\ttrain-hr_err:4.54560\ttest-rmse:1.00644\ttest-hr_err:15.97929\n",
      "[30]\ttrain-rmse:0.95858\ttrain-hr_err:4.48179\ttest-rmse:1.00868\ttest-hr_err:15.54713\n",
      "\n",
      "\n",
      "Fine-tuning...\n",
      "[18:21:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:1.51305\ttrain-hr_err:4.48179\ttest-rmse:1.01028\ttest-hr_err:15.54713\n",
      "[5]\ttrain-rmse:1.52125\ttrain-hr_err:4.48179\ttest-rmse:1.01607\ttest-hr_err:13.98811\n",
      "[10]\ttrain-rmse:1.52947\ttrain-hr_err:4.48179\ttest-rmse:1.02191\ttest-hr_err:13.98811\n",
      "[11]\ttrain-rmse:1.53112\ttrain-hr_err:0.20662\ttest-rmse:1.02309\ttest-hr_err:14.01963\n",
      "Finished training in 0:00:57.199640\n",
      "\n",
      "\n",
      "Training excluding subject 5...\n",
      "\n",
      "Rows per batch: 960\n",
      "[18:21:55] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:0.50215\ttrain-hr_err:11.25163\ttest-rmse:0.81827\ttest-hr_err:22.15318\n",
      "[5]\ttrain-rmse:0.50611\ttrain-hr_err:11.25163\ttest-rmse:0.82076\ttest-hr_err:22.15318\n",
      "[10]\ttrain-rmse:0.51006\ttrain-hr_err:17.82478\ttest-rmse:0.82321\ttest-hr_err:20.63645\n",
      "[15]\ttrain-rmse:0.51402\ttrain-hr_err:21.89218\ttest-rmse:0.82568\ttest-hr_err:20.19465\n",
      "[20]\ttrain-rmse:0.51802\ttrain-hr_err:27.35448\ttest-rmse:0.82818\ttest-hr_err:19.47520\n",
      "[25]\ttrain-rmse:0.52205\ttrain-hr_err:27.35448\ttest-rmse:0.83073\ttest-hr_err:20.71123\n",
      "[30]\ttrain-rmse:0.52615\ttrain-hr_err:27.35448\ttest-rmse:0.83328\ttest-hr_err:24.00086\n",
      "[33]\ttrain-rmse:0.52865\ttrain-hr_err:27.35448\ttest-rmse:0.83480\ttest-hr_err:19.49005\n",
      "\n",
      "\n",
      "Fine-tuning...\n",
      "[18:22:04] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:1.03606\ttrain-hr_err:27.35448\ttest-rmse:0.83583\ttest-hr_err:19.49005\n",
      "[5]\ttrain-rmse:1.04413\ttrain-hr_err:27.35448\ttest-rmse:0.84104\ttest-hr_err:19.49005\n",
      "[7]\ttrain-rmse:1.04738\ttrain-hr_err:27.35448\ttest-rmse:0.84314\ttest-hr_err:19.49005\n",
      "[18:22:06] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:0.86047\ttrain-hr_err:7.96464\ttest-rmse:0.84459\ttest-hr_err:18.50863\n",
      "[5]\ttrain-rmse:0.86487\ttrain-hr_err:1.80958\ttest-rmse:0.84657\ttest-hr_err:14.98079\n",
      "[10]\ttrain-rmse:0.86926\ttrain-hr_err:0.39743\ttest-rmse:0.84861\ttest-hr_err:12.29459\n",
      "[15]\ttrain-rmse:0.87366\ttrain-hr_err:0.47439\ttest-rmse:0.85067\ttest-hr_err:15.74076\n",
      "[20]\ttrain-rmse:0.87804\ttrain-hr_err:0.47439\ttest-rmse:0.85277\ttest-hr_err:15.74076\n",
      "[22]\ttrain-rmse:0.87979\ttrain-hr_err:0.47439\ttest-rmse:0.85361\ttest-hr_err:15.74076\n",
      "\n",
      "\n",
      "Fine-tuning...\n",
      "[18:22:12] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:1.31080\ttrain-hr_err:0.47439\ttest-rmse:0.85450\ttest-hr_err:15.74076\n",
      "[5]\ttrain-rmse:1.31784\ttrain-hr_err:0.47439\ttest-rmse:0.85897\ttest-hr_err:12.58279\n",
      "[10]\ttrain-rmse:1.32492\ttrain-hr_err:0.47439\ttest-rmse:0.86354\ttest-hr_err:6.56088\n",
      "[15]\ttrain-rmse:1.33202\ttrain-hr_err:0.47439\ttest-rmse:0.86804\ttest-hr_err:8.50493\n",
      "[19]\ttrain-rmse:1.33774\ttrain-hr_err:0.55152\ttest-rmse:0.87169\ttest-hr_err:9.13028\n",
      "[18:22:17] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:0.60809\ttrain-hr_err:47.46166\ttest-rmse:0.87231\ttest-hr_err:9.13028\n",
      "[5]\ttrain-rmse:0.61309\ttrain-hr_err:43.20917\ttest-rmse:0.87540\ttest-hr_err:9.10551\n",
      "[10]\ttrain-rmse:0.61813\ttrain-hr_err:43.20917\ttest-rmse:0.87817\ttest-hr_err:9.10551\n",
      "[15]\ttrain-rmse:0.62322\ttrain-hr_err:43.20917\ttest-rmse:0.88072\ttest-hr_err:9.10551\n",
      "[18]\ttrain-rmse:0.62629\ttrain-hr_err:43.20917\ttest-rmse:0.88228\ttest-hr_err:9.10551\n",
      "\n",
      "\n",
      "Fine-tuning...\n",
      "[18:22:22] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:1.21282\ttrain-hr_err:43.38855\ttest-rmse:0.88355\ttest-hr_err:9.10551\n",
      "[5]\ttrain-rmse:1.22209\ttrain-hr_err:43.38855\ttest-rmse:0.88992\ttest-hr_err:9.10551\n",
      "[8]\ttrain-rmse:1.22768\ttrain-hr_err:43.38855\ttest-rmse:0.89379\ttest-hr_err:9.10551\n",
      "[18:22:25] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:1.04288\ttrain-hr_err:11.34293\ttest-rmse:0.89424\ttest-hr_err:7.55775\n",
      "[5]\ttrain-rmse:1.04794\ttrain-hr_err:9.95000\ttest-rmse:0.89652\ttest-hr_err:10.58278\n",
      "[10]\ttrain-rmse:1.05300\ttrain-hr_err:3.18495\ttest-rmse:0.89888\ttest-hr_err:7.57512\n",
      "[15]\ttrain-rmse:1.05806\ttrain-hr_err:3.09106\ttest-rmse:0.90134\ttest-hr_err:10.58074\n",
      "[17]\ttrain-rmse:1.06008\ttrain-hr_err:2.99695\ttest-rmse:0.90233\ttest-hr_err:10.58074\n",
      "\n",
      "\n",
      "Fine-tuning...\n",
      "[18:22:30] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:1.52282\ttrain-hr_err:7.36059\ttest-rmse:0.90371\ttest-hr_err:12.12851\n",
      "[5]\ttrain-rmse:1.53052\ttrain-hr_err:1.26763\ttest-rmse:0.90814\ttest-hr_err:14.92628\n",
      "[9]\ttrain-rmse:1.53670\ttrain-hr_err:1.36669\ttest-rmse:0.91171\ttest-hr_err:16.35617\n",
      "[18:22:33] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:0.94153\ttrain-hr_err:12.29826\ttest-rmse:0.91201\ttest-hr_err:16.42574\n",
      "[5]\ttrain-rmse:0.94634\ttrain-hr_err:2.25124\ttest-rmse:0.91354\ttest-hr_err:14.21423\n",
      "[10]\ttrain-rmse:0.95113\ttrain-hr_err:2.25124\ttest-rmse:0.91515\ttest-hr_err:14.11322\n",
      "[15]\ttrain-rmse:0.95588\ttrain-hr_err:7.40851\ttest-rmse:0.91684\ttest-hr_err:14.04696\n",
      "[20]\ttrain-rmse:0.96062\ttrain-hr_err:7.40851\ttest-rmse:0.91856\ttest-hr_err:15.46321\n",
      "[25]\ttrain-rmse:0.96537\ttrain-hr_err:7.40851\ttest-rmse:0.92033\ttest-hr_err:14.59140\n",
      "[28]\ttrain-rmse:0.96823\ttrain-hr_err:7.40851\ttest-rmse:0.92141\ttest-hr_err:14.65169\n",
      "\n",
      "\n",
      "Fine-tuning...\n",
      "[18:22:42] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:1.51699\ttrain-hr_err:7.40851\ttest-rmse:0.92302\ttest-hr_err:14.65169\n",
      "[5]\ttrain-rmse:1.52508\ttrain-hr_err:7.40851\ttest-rmse:0.92932\ttest-hr_err:14.63052\n",
      "[10]\ttrain-rmse:1.53321\ttrain-hr_err:12.26212\ttest-rmse:0.93548\ttest-hr_err:16.08506\n",
      "Finished training in 0:00:49.976194\n",
      "\n",
      "\n",
      "Training excluding subject 5...\n",
      "\n",
      "Rows per batch: 960\n",
      "[18:22:49] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:0.86464\ttrain-hr_err:4.02142\ttest-rmse:0.78988\ttest-hr_err:16.91597\n",
      "[5]\ttrain-rmse:0.86879\ttrain-hr_err:3.95525\ttest-rmse:0.79208\ttest-hr_err:13.32609\n",
      "[10]\ttrain-rmse:0.87301\ttrain-hr_err:3.88892\ttest-rmse:0.79423\ttest-hr_err:14.07869\n",
      "[15]\ttrain-rmse:0.87722\ttrain-hr_err:3.88892\ttest-rmse:0.79643\ttest-hr_err:16.15649\n",
      "[20]\ttrain-rmse:0.88143\ttrain-hr_err:3.88892\ttest-rmse:0.79868\ttest-hr_err:16.15649\n",
      "[24]\ttrain-rmse:0.88479\ttrain-hr_err:3.82243\ttest-rmse:0.80049\ttest-hr_err:16.12845\n",
      "\n",
      "\n",
      "Fine-tuning...\n",
      "[18:22:56] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:1.27288\ttrain-hr_err:3.82243\ttest-rmse:0.80112\ttest-hr_err:16.10806\n",
      "[5]\ttrain-rmse:1.27954\ttrain-hr_err:8.43782\ttest-rmse:0.80435\ttest-hr_err:12.95205\n",
      "[10]\ttrain-rmse:1.28622\ttrain-hr_err:8.43782\ttest-rmse:0.80769\ttest-hr_err:15.94939\n",
      "[13]\ttrain-rmse:1.29024\ttrain-hr_err:8.43782\ttest-rmse:0.80975\ttest-hr_err:13.58340\n",
      "[18:23:00] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:0.56541\ttrain-hr_err:36.98701\ttest-rmse:0.81023\ttest-hr_err:13.58340\n",
      "[5]\ttrain-rmse:0.57006\ttrain-hr_err:36.98701\ttest-rmse:0.81265\ttest-hr_err:13.64156\n",
      "[10]\ttrain-rmse:0.57474\ttrain-hr_err:28.67533\ttest-rmse:0.81512\ttest-hr_err:12.16350\n",
      "[15]\ttrain-rmse:0.57947\ttrain-hr_err:16.20779\ttest-rmse:0.81763\ttest-hr_err:12.21927\n",
      "[20]\ttrain-rmse:0.58423\ttrain-hr_err:16.20779\ttest-rmse:0.82018\ttest-hr_err:11.96493\n",
      "[25]\ttrain-rmse:0.58904\ttrain-hr_err:12.05195\ttest-rmse:0.82278\ttest-hr_err:13.38086\n",
      "[30]\ttrain-rmse:0.59388\ttrain-hr_err:7.95914\ttest-rmse:0.82542\ttest-hr_err:11.90333\n",
      "[35]\ttrain-rmse:0.59876\ttrain-hr_err:3.79879\ttest-rmse:0.82821\ttest-hr_err:13.38965\n",
      "[40]\ttrain-rmse:0.60368\ttrain-hr_err:3.79879\ttest-rmse:0.83108\ttest-hr_err:16.34042\n",
      "[44]\ttrain-rmse:0.60764\ttrain-hr_err:3.79879\ttest-rmse:0.83341\ttest-hr_err:16.52258\n",
      "\n",
      "\n",
      "Fine-tuning...\n",
      "[18:23:14] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:1.17300\ttrain-hr_err:3.79879\ttest-rmse:0.83468\ttest-hr_err:16.52258\n",
      "[5]\ttrain-rmse:1.18203\ttrain-hr_err:3.79879\ttest-rmse:0.84112\ttest-hr_err:15.10821\n",
      "[10]\ttrain-rmse:1.19111\ttrain-hr_err:3.79879\ttest-rmse:0.84765\ttest-hr_err:16.29395\n",
      "[13]\ttrain-rmse:1.19658\ttrain-hr_err:3.79879\ttest-rmse:0.85162\ttest-hr_err:16.29395\n",
      "[18:23:18] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:0.69516\ttrain-hr_err:8.35637\ttest-rmse:0.85218\ttest-hr_err:16.29395\n",
      "[5]\ttrain-rmse:0.69976\ttrain-hr_err:8.35637\ttest-rmse:0.85505\ttest-hr_err:16.99411\n",
      "[10]\ttrain-rmse:0.70440\ttrain-hr_err:3.76856\ttest-rmse:0.85812\ttest-hr_err:18.46200\n",
      "[15]\ttrain-rmse:0.70908\ttrain-hr_err:3.76856\ttest-rmse:0.86128\ttest-hr_err:15.72653\n",
      "[20]\ttrain-rmse:0.71383\ttrain-hr_err:8.27973\ttest-rmse:0.86440\ttest-hr_err:14.23862\n",
      "[25]\ttrain-rmse:0.71863\ttrain-hr_err:0.95049\ttest-rmse:0.86740\ttest-hr_err:12.77073\n",
      "[30]\ttrain-rmse:0.72345\ttrain-hr_err:2.87427\ttest-rmse:0.87069\ttest-hr_err:12.77073\n",
      "[35]\ttrain-rmse:0.72830\ttrain-hr_err:12.51041\ttest-rmse:0.87403\ttest-hr_err:12.77073\n",
      "[38]\ttrain-rmse:0.73121\ttrain-hr_err:22.14654\ttest-rmse:0.87599\ttest-hr_err:12.77073\n",
      "\n",
      "\n",
      "Fine-tuning...\n",
      "[18:23:29] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:1.31450\ttrain-hr_err:22.14654\ttest-rmse:0.87720\ttest-hr_err:12.77073\n",
      "[5]\ttrain-rmse:1.32277\ttrain-hr_err:26.96461\ttest-rmse:0.88328\ttest-hr_err:12.77073\n",
      "[8]\ttrain-rmse:1.32774\ttrain-hr_err:26.96461\ttest-rmse:0.88683\ttest-hr_err:12.77073\n",
      "[18:23:32] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:0.93537\ttrain-hr_err:8.55485\ttest-rmse:0.88698\ttest-hr_err:12.77073\n",
      "[5]\ttrain-rmse:0.93949\ttrain-hr_err:10.68125\ttest-rmse:0.88774\ttest-hr_err:15.55827\n",
      "[10]\ttrain-rmse:0.94364\ttrain-hr_err:6.10437\ttest-rmse:0.88854\ttest-hr_err:14.17619\n",
      "[15]\ttrain-rmse:0.94782\ttrain-hr_err:0.55445\ttest-rmse:0.88937\ttest-hr_err:17.90662\n",
      "[16]\ttrain-rmse:0.94865\ttrain-hr_err:0.48635\ttest-rmse:0.88954\ttest-hr_err:17.93720\n",
      "\n",
      "\n",
      "Fine-tuning...\n",
      "[18:23:37] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:1.48484\ttrain-hr_err:0.47994\ttest-rmse:0.89077\ttest-hr_err:17.93720\n",
      "[5]\ttrain-rmse:1.49300\ttrain-hr_err:3.76672\ttest-rmse:0.89694\ttest-hr_err:17.93720\n",
      "[7]\ttrain-rmse:1.49628\ttrain-hr_err:8.08133\ttest-rmse:0.89943\ttest-hr_err:17.93720\n",
      "[18:23:40] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:1.08496\ttrain-hr_err:12.39253\ttest-rmse:0.90125\ttest-hr_err:18.31389\n",
      "[5]\ttrain-rmse:1.08984\ttrain-hr_err:12.30965\ttest-rmse:0.90336\ttest-hr_err:21.08061\n",
      "[10]\ttrain-rmse:1.09469\ttrain-hr_err:0.67795\ttest-rmse:0.90575\ttest-hr_err:17.29075\n",
      "[15]\ttrain-rmse:1.09965\ttrain-hr_err:7.80434\ttest-rmse:0.90847\ttest-hr_err:21.68170\n",
      "[20]\ttrain-rmse:1.10471\ttrain-hr_err:3.37210\ttest-rmse:0.91074\ttest-hr_err:21.64520\n",
      "[25]\ttrain-rmse:1.10977\ttrain-hr_err:3.27863\ttest-rmse:0.91291\ttest-hr_err:18.93159\n",
      "[29]\ttrain-rmse:1.11383\ttrain-hr_err:3.18495\ttest-rmse:0.91467\ttest-hr_err:19.33231\n",
      "\n",
      "\n",
      "Fine-tuning...\n",
      "[18:23:49] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:1.66071\ttrain-hr_err:3.18495\ttest-rmse:0.91593\ttest-hr_err:19.33231\n",
      "[5]\ttrain-rmse:1.66901\ttrain-hr_err:3.09106\ttest-rmse:0.92231\ttest-hr_err:19.38072\n",
      "[7]\ttrain-rmse:1.67234\ttrain-hr_err:3.09106\ttest-rmse:0.92492\ttest-hr_err:19.38072\n",
      "Finished training in 0:01:02.335629\n",
      "\n",
      "\n",
      "Training excluding subject 6...\n",
      "\n",
      "Rows per batch: 960\n",
      "[18:23:55] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:0.84836\ttrain-hr_err:1.76556\ttest-rmse:0.79069\ttest-hr_err:19.68379\n",
      "[5]\ttrain-rmse:0.85242\ttrain-hr_err:1.76556\ttest-rmse:0.79275\ttest-hr_err:19.68379\n",
      "[10]\ttrain-rmse:0.85648\ttrain-hr_err:0.98553\ttest-rmse:0.79485\ttest-hr_err:19.68379\n",
      "[15]\ttrain-rmse:0.86054\ttrain-hr_err:0.98553\ttest-rmse:0.79699\ttest-hr_err:19.68379\n",
      "[16]\ttrain-rmse:0.86135\ttrain-hr_err:0.98553\ttest-rmse:0.79742\ttest-hr_err:19.68379\n",
      "\n",
      "\n",
      "Fine-tuning...\n",
      "[18:23:59] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:1.23580\ttrain-hr_err:0.98553\ttest-rmse:0.79793\ttest-hr_err:25.20867\n",
      "[5]\ttrain-rmse:1.24197\ttrain-hr_err:1.06266\ttest-rmse:0.80001\ttest-hr_err:26.96157\n",
      "[7]\ttrain-rmse:1.24448\ttrain-hr_err:1.13998\ttest-rmse:0.80086\ttest-hr_err:28.92022\n",
      "[18:24:02] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:0.54495\ttrain-hr_err:28.03309\ttest-rmse:0.80178\ttest-hr_err:30.94980\n",
      "[5]\ttrain-rmse:0.54943\ttrain-hr_err:32.14884\ttest-rmse:0.80426\ttest-hr_err:27.85970\n",
      "[10]\ttrain-rmse:0.55394\ttrain-hr_err:32.14884\ttest-rmse:0.80679\ttest-hr_err:26.94168\n",
      "[15]\ttrain-rmse:0.55850\ttrain-hr_err:32.14884\ttest-rmse:0.80933\ttest-hr_err:26.97530\n",
      "[20]\ttrain-rmse:0.56308\ttrain-hr_err:28.03309\ttest-rmse:0.81187\ttest-hr_err:26.51177\n",
      "[22]\ttrain-rmse:0.56493\ttrain-hr_err:28.03309\ttest-rmse:0.81289\ttest-hr_err:26.51177\n",
      "\n",
      "\n",
      "Fine-tuning...\n",
      "[18:24:08] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:1.08498\ttrain-hr_err:27.91364\ttest-rmse:0.81402\ttest-hr_err:26.51177\n",
      "[5]\ttrain-rmse:1.09353\ttrain-hr_err:27.91364\ttest-rmse:0.81969\ttest-hr_err:26.51177\n",
      "[8]\ttrain-rmse:1.09868\ttrain-hr_err:27.91364\ttest-rmse:0.82328\ttest-hr_err:26.51177\n",
      "[18:24:10] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:0.57852\ttrain-hr_err:23.07573\ttest-rmse:0.82390\ttest-hr_err:24.85172\n",
      "[5]\ttrain-rmse:0.58310\ttrain-hr_err:23.07573\ttest-rmse:0.82703\ttest-hr_err:26.30600\n",
      "[10]\ttrain-rmse:0.58772\ttrain-hr_err:23.07573\ttest-rmse:0.83019\ttest-hr_err:23.37798\n",
      "[15]\ttrain-rmse:0.59238\ttrain-hr_err:18.53672\ttest-rmse:0.83338\ttest-hr_err:23.35372\n",
      "[18]\ttrain-rmse:0.59520\ttrain-hr_err:18.61729\ttest-rmse:0.83530\ttest-hr_err:23.72022\n",
      "\n",
      "\n",
      "Fine-tuning...\n",
      "[18:24:15] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:1.14762\ttrain-hr_err:18.68114\ttest-rmse:0.83651\ttest-hr_err:23.72022\n",
      "[5]\ttrain-rmse:1.15645\ttrain-hr_err:18.68114\ttest-rmse:0.84258\ttest-hr_err:23.72022\n",
      "[7]\ttrain-rmse:1.16000\ttrain-hr_err:18.68114\ttest-rmse:0.84503\ttest-hr_err:23.72022\n",
      "[18:24:18] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:0.89896\ttrain-hr_err:10.48827\ttest-rmse:0.84680\ttest-hr_err:23.72022\n",
      "[5]\ttrain-rmse:0.90359\ttrain-hr_err:1.48779\ttest-rmse:0.84949\ttest-hr_err:22.78891\n",
      "[10]\ttrain-rmse:0.90822\ttrain-hr_err:2.92600\ttest-rmse:0.85221\ttest-hr_err:23.07801\n",
      "[15]\ttrain-rmse:0.91284\ttrain-hr_err:8.24851\ttest-rmse:0.85498\ttest-hr_err:26.33330\n",
      "[20]\ttrain-rmse:0.91744\ttrain-hr_err:3.61751\ttest-rmse:0.85770\ttest-hr_err:27.92315\n",
      "[23]\ttrain-rmse:0.92020\ttrain-hr_err:8.38658\ttest-rmse:0.85926\ttest-hr_err:26.49298\n",
      "\n",
      "\n",
      "Fine-tuning...\n",
      "[18:24:25] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:1.39506\ttrain-hr_err:8.38658\ttest-rmse:0.86032\ttest-hr_err:26.49298\n",
      "[5]\ttrain-rmse:1.40252\ttrain-hr_err:3.69221\ttest-rmse:0.86580\ttest-hr_err:28.11445\n",
      "[7]\ttrain-rmse:1.40552\ttrain-hr_err:3.69221\ttest-rmse:0.86804\ttest-hr_err:29.81441\n",
      "[18:24:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:0.92445\ttrain-hr_err:1.72365\ttest-rmse:0.86976\ttest-hr_err:31.55582\n",
      "[5]\ttrain-rmse:0.92903\ttrain-hr_err:1.64471\ttest-rmse:0.87276\ttest-hr_err:29.22482\n",
      "[10]\ttrain-rmse:0.93363\ttrain-hr_err:5.08895\ttest-rmse:0.87602\ttest-hr_err:29.26746\n",
      "[15]\ttrain-rmse:0.93805\ttrain-hr_err:0.49114\ttest-rmse:0.87889\ttest-hr_err:27.53499\n",
      "[20]\ttrain-rmse:0.94245\ttrain-hr_err:0.42148\ttest-rmse:0.88248\ttest-hr_err:28.54744\n",
      "[25]\ttrain-rmse:0.94685\ttrain-hr_err:0.14116\ttest-rmse:0.88609\ttest-hr_err:29.48236\n",
      "[30]\ttrain-rmse:0.95125\ttrain-hr_err:0.07066\ttest-rmse:0.88970\ttest-hr_err:31.88866\n",
      "\n",
      "\n",
      "Fine-tuning...\n",
      "[18:24:39] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:1.45714\ttrain-hr_err:0.00000\ttest-rmse:0.89157\ttest-hr_err:29.92935\n",
      "[5]\ttrain-rmse:1.46502\ttrain-hr_err:0.00000\ttest-rmse:0.89740\ttest-hr_err:28.45120\n",
      "[10]\ttrain-rmse:1.47297\ttrain-hr_err:0.00000\ttest-rmse:0.90341\ttest-hr_err:26.29729\n",
      "[15]\ttrain-rmse:1.48097\ttrain-hr_err:0.07050\ttest-rmse:0.90952\ttest-hr_err:25.94564\n",
      "[20]\ttrain-rmse:1.48901\ttrain-hr_err:0.07050\ttest-rmse:0.91575\ttest-hr_err:27.46043\n",
      "[25]\ttrain-rmse:1.49710\ttrain-hr_err:4.69599\ttest-rmse:0.92204\ttest-hr_err:25.94384\n",
      "[29]\ttrain-rmse:1.50361\ttrain-hr_err:4.69599\ttest-rmse:0.92706\ttest-hr_err:25.94384\n",
      "Finished training in 0:00:53.508914\n",
      "\n",
      "\n",
      "Training excluding subject 6...\n",
      "\n",
      "Rows per batch: 960\n",
      "[18:24:53] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:0.85164\ttrain-hr_err:2.99163\ttest-rmse:0.64636\ttest-hr_err:28.00256\n",
      "[5]\ttrain-rmse:0.85546\ttrain-hr_err:3.06463\ttest-rmse:0.64780\ttest-hr_err:17.34450\n",
      "[10]\ttrain-rmse:0.85925\ttrain-hr_err:3.92652\ttest-rmse:0.64918\ttest-hr_err:17.26027\n",
      "[15]\ttrain-rmse:0.86305\ttrain-hr_err:8.74967\ttest-rmse:0.65060\ttest-hr_err:15.92259\n",
      "[20]\ttrain-rmse:0.86685\ttrain-hr_err:8.74967\ttest-rmse:0.65207\ttest-hr_err:15.89044\n",
      "[25]\ttrain-rmse:0.87071\ttrain-hr_err:8.74967\ttest-rmse:0.65334\ttest-hr_err:13.11564\n",
      "[30]\ttrain-rmse:0.87458\ttrain-hr_err:8.74967\ttest-rmse:0.65420\ttest-hr_err:15.89044\n",
      "[35]\ttrain-rmse:0.87838\ttrain-hr_err:8.74967\ttest-rmse:0.65468\ttest-hr_err:18.69132\n",
      "[40]\ttrain-rmse:0.88216\ttrain-hr_err:8.74967\ttest-rmse:0.65560\ttest-hr_err:18.66248\n",
      "\n",
      "\n",
      "Fine-tuning...\n",
      "[18:25:05] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:1.27797\ttrain-hr_err:10.37941\ttest-rmse:0.65695\ttest-hr_err:18.66248\n",
      "[5]\ttrain-rmse:1.28456\ttrain-hr_err:14.92845\ttest-rmse:0.66235\ttest-hr_err:20.19175\n",
      "[8]\ttrain-rmse:1.28852\ttrain-hr_err:14.92845\ttest-rmse:0.66564\ttest-hr_err:20.19175\n",
      "[18:25:07] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:0.56927\ttrain-hr_err:17.82003\ttest-rmse:0.66622\ttest-hr_err:20.19175\n",
      "[5]\ttrain-rmse:0.57374\ttrain-hr_err:17.82003\ttest-rmse:0.66936\ttest-hr_err:20.19175\n",
      "[10]\ttrain-rmse:0.57825\ttrain-hr_err:17.82003\ttest-rmse:0.67287\ttest-hr_err:20.19175\n",
      "[15]\ttrain-rmse:0.58279\ttrain-hr_err:15.85307\ttest-rmse:0.67642\ttest-hr_err:20.34087\n",
      "[16]\ttrain-rmse:0.58371\ttrain-hr_err:15.85307\ttest-rmse:0.67714\ttest-hr_err:20.34087\n",
      "\n",
      "\n",
      "Fine-tuning...\n",
      "[18:25:12] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:1.12201\ttrain-hr_err:15.85307\ttest-rmse:0.67850\ttest-hr_err:20.34087\n",
      "[5]\ttrain-rmse:1.13067\ttrain-hr_err:15.85307\ttest-rmse:0.68533\ttest-hr_err:20.34087\n",
      "[7]\ttrain-rmse:1.13415\ttrain-hr_err:15.85307\ttest-rmse:0.68809\ttest-hr_err:20.34087\n",
      "[18:25:14] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:0.66509\ttrain-hr_err:13.55071\ttest-rmse:0.68965\ttest-hr_err:18.82607\n",
      "[5]\ttrain-rmse:0.66955\ttrain-hr_err:12.24228\ttest-rmse:0.69058\ttest-hr_err:18.78954\n",
      "[10]\ttrain-rmse:0.67403\ttrain-hr_err:12.24228\ttest-rmse:0.69156\ttest-hr_err:17.12999\n",
      "[15]\ttrain-rmse:0.67855\ttrain-hr_err:12.24228\ttest-rmse:0.69261\ttest-hr_err:18.63950\n",
      "[20]\ttrain-rmse:0.68309\ttrain-hr_err:12.24228\ttest-rmse:0.69370\ttest-hr_err:17.08690\n",
      "[25]\ttrain-rmse:0.68762\ttrain-hr_err:12.24228\ttest-rmse:0.69472\ttest-hr_err:15.63194\n",
      "[30]\ttrain-rmse:0.69211\ttrain-hr_err:7.98508\ttest-rmse:0.69643\ttest-hr_err:17.07166\n",
      "[35]\ttrain-rmse:0.69663\ttrain-hr_err:3.72787\ttest-rmse:0.69821\ttest-hr_err:17.30311\n",
      "[40]\ttrain-rmse:0.70115\ttrain-hr_err:0.52933\ttest-rmse:0.70001\ttest-hr_err:15.88966\n",
      "\n",
      "\n",
      "Fine-tuning...\n",
      "[18:25:27] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:1.24625\ttrain-hr_err:4.55003\ttest-rmse:0.70127\ttest-hr_err:15.88966\n",
      "[5]\ttrain-rmse:1.25392\ttrain-hr_err:4.55003\ttest-rmse:0.70755\ttest-hr_err:15.88966\n",
      "[7]\ttrain-rmse:1.25698\ttrain-hr_err:4.55003\ttest-rmse:0.71012\ttest-hr_err:15.88966\n",
      "[18:25:29] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:0.88592\ttrain-hr_err:16.05017\ttest-rmse:0.71192\ttest-hr_err:14.52694\n",
      "[5]\ttrain-rmse:0.89070\ttrain-hr_err:15.98540\ttest-rmse:0.71450\ttest-hr_err:16.63257\n",
      "[10]\ttrain-rmse:0.89550\ttrain-hr_err:11.93221\ttest-rmse:0.71715\ttest-hr_err:16.51880\n",
      "[15]\ttrain-rmse:0.90012\ttrain-hr_err:6.39192\ttest-rmse:0.71976\ttest-hr_err:15.01667\n",
      "[16]\ttrain-rmse:0.90104\ttrain-hr_err:5.69252\ttest-rmse:0.72028\ttest-hr_err:15.04375\n",
      "\n",
      "\n",
      "Fine-tuning...\n",
      "[18:25:34] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:1.38473\ttrain-hr_err:5.15466\ttest-rmse:0.72172\ttest-hr_err:15.04375\n",
      "[5]\ttrain-rmse:1.39243\ttrain-hr_err:0.56270\ttest-rmse:0.72899\ttest-hr_err:15.04375\n",
      "[7]\ttrain-rmse:1.39553\ttrain-hr_err:0.56270\ttest-rmse:0.73193\ttest-hr_err:15.04375\n",
      "[18:25:37] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:1.02770\ttrain-hr_err:50.12868\ttest-rmse:0.73375\ttest-hr_err:18.07522\n",
      "[5]\ttrain-rmse:1.03231\ttrain-hr_err:50.91948\ttest-rmse:0.73557\ttest-hr_err:15.02505\n",
      "[10]\ttrain-rmse:1.03687\ttrain-hr_err:41.52566\ttest-rmse:0.73749\ttest-hr_err:15.61616\n",
      "[15]\ttrain-rmse:1.04145\ttrain-hr_err:45.89956\ttest-rmse:0.73945\ttest-hr_err:19.67977\n",
      "[20]\ttrain-rmse:1.04601\ttrain-hr_err:44.29570\ttest-rmse:0.74149\ttest-hr_err:19.63694\n",
      "\n",
      "\n",
      "Fine-tuning...\n",
      "[18:25:43] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:1.54373\ttrain-hr_err:41.61039\ttest-rmse:0.74279\ttest-hr_err:19.63694\n",
      "[5]\ttrain-rmse:1.55154\ttrain-hr_err:30.86913\ttest-rmse:0.74729\ttest-hr_err:18.05223\n",
      "[10]\ttrain-rmse:1.55938\ttrain-hr_err:28.40154\ttest-rmse:0.75189\ttest-hr_err:19.40208\n",
      "[15]\ttrain-rmse:1.56727\ttrain-hr_err:32.55290\ttest-rmse:0.75660\ttest-hr_err:19.83544\n",
      "Finished training in 0:00:54.336441\n",
      "\n",
      "\n",
      "Training excluding subject 6...\n",
      "\n",
      "Rows per batch: 960\n",
      "[18:25:50] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:0.53260\ttrain-hr_err:4.78155\ttest-rmse:0.79214\ttest-hr_err:28.71383\n",
      "[5]\ttrain-rmse:0.53679\ttrain-hr_err:4.78155\ttest-rmse:0.79456\ttest-hr_err:33.49714\n",
      "[10]\ttrain-rmse:0.54101\ttrain-hr_err:4.78155\ttest-rmse:0.79702\ttest-hr_err:30.76931\n",
      "[15]\ttrain-rmse:0.54526\ttrain-hr_err:0.19255\ttest-rmse:0.79951\ttest-hr_err:29.22236\n",
      "[20]\ttrain-rmse:0.54954\ttrain-hr_err:0.87919\ttest-rmse:0.80201\ttest-hr_err:28.29701\n",
      "[25]\ttrain-rmse:0.55387\ttrain-hr_err:0.81742\ttest-rmse:0.80456\ttest-hr_err:27.61429\n",
      "[30]\ttrain-rmse:0.55822\ttrain-hr_err:0.81742\ttest-rmse:0.80715\ttest-hr_err:25.98694\n",
      "[35]\ttrain-rmse:0.56261\ttrain-hr_err:0.75550\ttest-rmse:0.80979\ttest-hr_err:26.57340\n",
      "[40]\ttrain-rmse:0.56704\ttrain-hr_err:0.75550\ttest-rmse:0.81246\ttest-hr_err:26.54731\n",
      "[45]\ttrain-rmse:0.57150\ttrain-hr_err:0.75550\ttest-rmse:0.81517\ttest-hr_err:27.92810\n",
      "[46]\ttrain-rmse:0.57240\ttrain-hr_err:0.75550\ttest-rmse:0.81572\ttest-hr_err:27.92810\n",
      "\n",
      "\n",
      "Fine-tuning...\n",
      "[18:26:02] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:1.09651\ttrain-hr_err:0.75550\ttest-rmse:0.81685\ttest-hr_err:27.92810\n",
      "[5]\ttrain-rmse:1.10500\ttrain-hr_err:0.75550\ttest-rmse:0.82257\ttest-hr_err:27.92810\n",
      "[8]\ttrain-rmse:1.11012\ttrain-hr_err:0.75550\ttest-rmse:0.82604\ttest-hr_err:27.92810\n",
      "[18:26:04] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:0.87945\ttrain-hr_err:12.31119\ttest-rmse:0.82643\ttest-hr_err:27.90260\n",
      "[5]\ttrain-rmse:0.88376\ttrain-hr_err:12.13247\ttest-rmse:0.82866\ttest-hr_err:25.73378\n",
      "[10]\ttrain-rmse:0.88808\ttrain-hr_err:12.13247\ttest-rmse:0.83093\ttest-hr_err:31.22408\n",
      "[15]\ttrain-rmse:0.89240\ttrain-hr_err:11.22501\ttest-rmse:0.83323\ttest-hr_err:26.37805\n",
      "[20]\ttrain-rmse:0.89672\ttrain-hr_err:15.38462\ttest-rmse:0.83569\ttest-hr_err:27.74958\n",
      "[25]\ttrain-rmse:0.90103\ttrain-hr_err:15.33196\ttest-rmse:0.83826\ttest-hr_err:27.76907\n",
      "[30]\ttrain-rmse:0.90533\ttrain-hr_err:15.33196\ttest-rmse:0.84077\ttest-hr_err:29.23636\n",
      "[33]\ttrain-rmse:0.90793\ttrain-hr_err:11.28205\ttest-rmse:0.84225\ttest-hr_err:27.87484\n",
      "\n",
      "\n",
      "Fine-tuning...\n",
      "[18:26:13] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:1.35843\ttrain-hr_err:11.31313\ttest-rmse:0.84376\ttest-hr_err:26.41864\n",
      "[5]\ttrain-rmse:1.36550\ttrain-hr_err:11.31313\ttest-rmse:0.84891\ttest-hr_err:27.78181\n",
      "[8]\ttrain-rmse:1.36974\ttrain-hr_err:15.41569\ttest-rmse:0.85195\ttest-hr_err:28.08422\n",
      "[18:26:15] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:0.69970\ttrain-hr_err:20.19429\ttest-rmse:0.85231\ttest-hr_err:28.05369\n",
      "[5]\ttrain-rmse:0.70425\ttrain-hr_err:20.11306\ttest-rmse:0.85412\ttest-hr_err:25.72833\n",
      "[10]\ttrain-rmse:0.70884\ttrain-hr_err:20.11306\ttest-rmse:0.85598\ttest-hr_err:24.88319\n",
      "[15]\ttrain-rmse:0.71346\ttrain-hr_err:24.39400\ttest-rmse:0.85788\ttest-hr_err:23.44526\n",
      "[20]\ttrain-rmse:0.71813\ttrain-hr_err:28.67494\ttest-rmse:0.85989\ttest-hr_err:23.41732\n",
      "[25]\ttrain-rmse:0.72284\ttrain-hr_err:20.11306\ttest-rmse:0.86202\ttest-hr_err:23.39007\n",
      "[27]\ttrain-rmse:0.72474\ttrain-hr_err:20.11306\ttest-rmse:0.86288\ttest-hr_err:23.49759\n",
      "\n",
      "\n",
      "Fine-tuning...\n",
      "[18:26:22] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:1.30541\ttrain-hr_err:15.78962\ttest-rmse:0.86443\ttest-hr_err:23.49759\n",
      "[5]\ttrain-rmse:1.31351\ttrain-hr_err:20.07055\ttest-rmse:0.87234\ttest-hr_err:23.19391\n",
      "[10]\ttrain-rmse:1.32162\ttrain-hr_err:20.07055\ttest-rmse:0.88059\ttest-hr_err:23.19427\n",
      "[12]\ttrain-rmse:1.32488\ttrain-hr_err:20.07055\ttest-rmse:0.88399\ttest-hr_err:26.07437\n",
      "[18:26:25] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:0.93937\ttrain-hr_err:3.63895\ttest-rmse:0.88449\ttest-hr_err:26.07437\n",
      "[5]\ttrain-rmse:0.94379\ttrain-hr_err:3.71014\ttest-rmse:0.88703\ttest-hr_err:28.14045\n",
      "[10]\ttrain-rmse:0.94823\ttrain-hr_err:1.06004\ttest-rmse:0.88961\ttest-hr_err:28.91985\n",
      "[15]\ttrain-rmse:0.95268\ttrain-hr_err:1.06004\ttest-rmse:0.89219\ttest-hr_err:29.90510\n",
      "[16]\ttrain-rmse:0.95358\ttrain-hr_err:1.06004\ttest-rmse:0.89257\ttest-hr_err:29.90510\n",
      "\n",
      "\n",
      "Fine-tuning...\n",
      "[18:26:30] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:1.47819\ttrain-hr_err:1.06004\ttest-rmse:0.89419\ttest-hr_err:31.33208\n",
      "[5]\ttrain-rmse:1.48619\ttrain-hr_err:1.06004\ttest-rmse:0.90046\ttest-hr_err:29.87333\n",
      "[10]\ttrain-rmse:1.49426\ttrain-hr_err:1.06004\ttest-rmse:0.90682\ttest-hr_err:28.37098\n",
      "[15]\ttrain-rmse:1.50238\ttrain-hr_err:1.06004\ttest-rmse:0.91359\ttest-hr_err:26.86863\n",
      "[19]\ttrain-rmse:1.50894\ttrain-hr_err:1.06004\ttest-rmse:0.91919\ttest-hr_err:26.94400\n",
      "[18:26:35] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:0.97082\ttrain-hr_err:2.08209\ttest-rmse:0.91989\ttest-hr_err:25.44165\n",
      "[5]\ttrain-rmse:0.97551\ttrain-hr_err:2.16412\ttest-rmse:0.92342\ttest-hr_err:25.37110\n",
      "[10]\ttrain-rmse:0.98023\ttrain-hr_err:1.10820\ttest-rmse:0.92702\ttest-hr_err:23.87051\n",
      "[15]\ttrain-rmse:0.98497\ttrain-hr_err:1.10820\ttest-rmse:0.93064\ttest-hr_err:21.94214\n",
      "[20]\ttrain-rmse:0.98970\ttrain-hr_err:3.29943\ttest-rmse:0.93429\ttest-hr_err:18.97935\n",
      "[25]\ttrain-rmse:0.99446\ttrain-hr_err:1.17609\ttest-rmse:0.93797\ttest-hr_err:21.78257\n",
      "[30]\ttrain-rmse:0.99921\ttrain-hr_err:1.17609\ttest-rmse:0.94163\ttest-hr_err:20.23242\n",
      "[35]\ttrain-rmse:1.00406\ttrain-hr_err:1.17609\ttest-rmse:0.94521\ttest-hr_err:19.71034\n",
      "[40]\ttrain-rmse:1.00896\ttrain-hr_err:1.17609\ttest-rmse:0.94883\ttest-hr_err:21.13573\n",
      "[45]\ttrain-rmse:1.01388\ttrain-hr_err:1.17609\ttest-rmse:0.95248\ttest-hr_err:24.53452\n",
      "[50]\ttrain-rmse:1.01879\ttrain-hr_err:1.17609\ttest-rmse:0.95617\ttest-hr_err:23.06663\n",
      "[51]\ttrain-rmse:1.01978\ttrain-hr_err:1.11305\ttest-rmse:0.95691\ttest-hr_err:24.53452\n",
      "\n",
      "\n",
      "Fine-tuning...\n",
      "[18:26:49] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:1.62963\ttrain-hr_err:0.97223\ttest-rmse:0.95926\ttest-hr_err:26.25329\n",
      "[5]\ttrain-rmse:1.63839\ttrain-hr_err:1.03526\ttest-rmse:0.96707\ttest-hr_err:27.72118\n",
      "[8]\ttrain-rmse:1.64368\ttrain-hr_err:1.03526\ttest-rmse:0.97176\ttest-hr_err:27.72118\n",
      "Finished training in 0:01:01.461587\n",
      "\n",
      "\n",
      "Training excluding subject 6...\n",
      "\n",
      "Rows per batch: 960\n",
      "[18:26:56] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:0.84628\ttrain-hr_err:0.39590\ttest-rmse:0.74923\ttest-hr_err:6.70270\n",
      "[5]\ttrain-rmse:0.85062\ttrain-hr_err:0.46936\ttest-rmse:0.75147\ttest-hr_err:7.33556\n",
      "[10]\ttrain-rmse:0.85492\ttrain-hr_err:0.46936\ttest-rmse:0.75388\ttest-hr_err:8.35011\n",
      "[15]\ttrain-rmse:0.85918\ttrain-hr_err:0.46936\ttest-rmse:0.75638\ttest-hr_err:6.23327\n",
      "[20]\ttrain-rmse:0.86344\ttrain-hr_err:0.46936\ttest-rmse:0.75893\ttest-hr_err:6.19076\n",
      "[23]\ttrain-rmse:0.86599\ttrain-hr_err:0.46936\ttest-rmse:0.76052\ttest-hr_err:6.23226\n",
      "\n",
      "\n",
      "Fine-tuning...\n",
      "[18:27:03] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:1.24633\ttrain-hr_err:0.46936\ttest-rmse:0.76192\ttest-hr_err:4.77274\n",
      "[5]\ttrain-rmse:1.25279\ttrain-hr_err:0.46936\ttest-rmse:0.76627\ttest-hr_err:6.25941\n",
      "[9]\ttrain-rmse:1.25797\ttrain-hr_err:0.54825\ttest-rmse:0.76979\ttest-hr_err:9.29421\n",
      "[18:27:06] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:0.55744\ttrain-hr_err:26.44696\ttest-rmse:0.77120\ttest-hr_err:9.29421\n",
      "[5]\ttrain-rmse:0.56181\ttrain-hr_err:26.44696\ttest-rmse:0.77384\ttest-hr_err:12.85320\n",
      "[10]\ttrain-rmse:0.56621\ttrain-hr_err:26.44696\ttest-rmse:0.77652\ttest-hr_err:12.85320\n",
      "[15]\ttrain-rmse:0.57065\ttrain-hr_err:21.97664\ttest-rmse:0.77925\ttest-hr_err:12.85320\n",
      "[16]\ttrain-rmse:0.57155\ttrain-hr_err:21.97664\ttest-rmse:0.77980\ttest-hr_err:12.85320\n",
      "\n",
      "\n",
      "Fine-tuning...\n",
      "[18:27:10] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:1.09429\ttrain-hr_err:22.10418\ttest-rmse:0.78097\ttest-hr_err:12.85320\n",
      "[5]\ttrain-rmse:1.10276\ttrain-hr_err:22.10418\ttest-rmse:0.78688\ttest-hr_err:12.85320\n",
      "[8]\ttrain-rmse:1.10787\ttrain-hr_err:22.10418\ttest-rmse:0.79046\ttest-hr_err:12.85320\n",
      "[18:27:13] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:0.57438\ttrain-hr_err:6.20696\ttest-rmse:0.79095\ttest-hr_err:12.85320\n",
      "[5]\ttrain-rmse:0.57911\ttrain-hr_err:1.46129\ttest-rmse:0.79341\ttest-hr_err:11.30169\n",
      "[10]\ttrain-rmse:0.58388\ttrain-hr_err:1.46129\ttest-rmse:0.79592\ttest-hr_err:11.33181\n",
      "[15]\ttrain-rmse:0.58869\ttrain-hr_err:1.46129\ttest-rmse:0.79848\ttest-hr_err:11.33181\n",
      "[19]\ttrain-rmse:0.59256\ttrain-hr_err:1.46129\ttest-rmse:0.80056\ttest-hr_err:11.33181\n",
      "\n",
      "\n",
      "Fine-tuning...\n",
      "[18:27:18] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:1.14533\ttrain-hr_err:1.46129\ttest-rmse:0.80186\ttest-hr_err:11.33181\n",
      "[5]\ttrain-rmse:1.15423\ttrain-hr_err:1.46129\ttest-rmse:0.80845\ttest-hr_err:11.33181\n",
      "[8]\ttrain-rmse:1.15960\ttrain-hr_err:1.46129\ttest-rmse:0.81245\ttest-hr_err:11.33181\n",
      "[18:27:21] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:1.02475\ttrain-hr_err:52.08578\ttest-rmse:0.81267\ttest-hr_err:11.28474\n",
      "[5]\ttrain-rmse:1.02953\ttrain-hr_err:51.19080\ttest-rmse:0.81378\ttest-hr_err:10.60421\n",
      "[10]\ttrain-rmse:1.03431\ttrain-hr_err:29.54481\ttest-rmse:0.81493\ttest-hr_err:8.18013\n",
      "[15]\ttrain-rmse:1.03910\ttrain-hr_err:16.45460\ttest-rmse:0.81612\ttest-hr_err:10.21002\n",
      "[20]\ttrain-rmse:1.04389\ttrain-hr_err:16.35175\ttest-rmse:0.81737\ttest-hr_err:8.77846\n",
      "[25]\ttrain-rmse:1.04869\ttrain-hr_err:7.56090\ttest-rmse:0.81867\ttest-hr_err:13.75450\n",
      "[26]\ttrain-rmse:1.04964\ttrain-hr_err:7.56090\ttest-rmse:0.81893\ttest-hr_err:13.75450\n",
      "\n",
      "\n",
      "Fine-tuning...\n",
      "[18:27:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:1.52127\ttrain-hr_err:7.56090\ttest-rmse:0.82014\ttest-hr_err:13.75450\n",
      "[5]\ttrain-rmse:1.52879\ttrain-hr_err:1.12689\ttest-rmse:0.82622\ttest-hr_err:13.21792\n",
      "[10]\ttrain-rmse:1.53635\ttrain-hr_err:1.12689\ttest-rmse:0.83237\ttest-hr_err:11.43270\n",
      "[15]\ttrain-rmse:1.54395\ttrain-hr_err:1.12689\ttest-rmse:0.83859\ttest-hr_err:12.00610\n",
      "[20]\ttrain-rmse:1.55157\ttrain-hr_err:1.12689\ttest-rmse:0.84490\ttest-hr_err:12.26901\n",
      "[24]\ttrain-rmse:1.55768\ttrain-hr_err:1.24987\ttest-rmse:0.85001\ttest-hr_err:13.20215\n",
      "[18:27:36] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:0.74065\ttrain-hr_err:24.05190\ttest-rmse:0.85186\ttest-hr_err:14.73461\n",
      "[5]\ttrain-rmse:0.74554\ttrain-hr_err:19.78997\ttest-rmse:0.85454\ttest-hr_err:14.30473\n",
      "[10]\ttrain-rmse:0.75048\ttrain-hr_err:19.78997\ttest-rmse:0.85727\ttest-hr_err:12.75535\n",
      "[15]\ttrain-rmse:0.75546\ttrain-hr_err:19.78997\ttest-rmse:0.86004\ttest-hr_err:13.53484\n",
      "[20]\ttrain-rmse:0.76047\ttrain-hr_err:19.78997\ttest-rmse:0.86286\ttest-hr_err:12.65229\n",
      "[25]\ttrain-rmse:0.76554\ttrain-hr_err:19.78997\ttest-rmse:0.86583\ttest-hr_err:14.59361\n",
      "[30]\ttrain-rmse:0.77065\ttrain-hr_err:15.52804\ttest-rmse:0.86886\ttest-hr_err:13.16695\n",
      "[35]\ttrain-rmse:0.77580\ttrain-hr_err:15.52804\ttest-rmse:0.87170\ttest-hr_err:11.76944\n",
      "[40]\ttrain-rmse:0.78100\ttrain-hr_err:11.26611\ttest-rmse:0.87460\ttest-hr_err:11.28581\n",
      "[45]\ttrain-rmse:0.78623\ttrain-hr_err:11.26611\ttest-rmse:0.87756\ttest-hr_err:9.82295\n",
      "[50]\ttrain-rmse:0.79150\ttrain-hr_err:7.00418\ttest-rmse:0.88056\ttest-hr_err:11.05194\n",
      "[55]\ttrain-rmse:0.79680\ttrain-hr_err:2.74225\ttest-rmse:0.88375\ttest-hr_err:10.77518\n",
      "[56]\ttrain-rmse:0.79787\ttrain-hr_err:2.74225\ttest-rmse:0.88439\ttest-hr_err:10.77518\n",
      "\n",
      "\n",
      "Fine-tuning...\n",
      "[18:27:52] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:1.46783\ttrain-hr_err:3.79402\ttest-rmse:0.88689\ttest-hr_err:10.77518\n",
      "[5]\ttrain-rmse:1.47632\ttrain-hr_err:20.84175\ttest-rmse:0.89644\ttest-hr_err:8.00762\n",
      "[10]\ttrain-rmse:1.48484\ttrain-hr_err:33.62754\ttest-rmse:0.90643\ttest-hr_err:11.37446\n",
      "[13]\ttrain-rmse:1.48998\ttrain-hr_err:33.62754\ttest-rmse:0.91264\ttest-hr_err:9.93464\n",
      "Finished training in 0:01:00.382972\n",
      "\n",
      "\n",
      "Training excluding subject 6...\n",
      "\n",
      "Rows per batch: 960\n",
      "[18:28:00] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:0.53109\ttrain-hr_err:0.05923\ttest-rmse:0.88441\ttest-hr_err:49.29508\n",
      "[5]\ttrain-rmse:0.53546\ttrain-hr_err:0.05923\ttest-rmse:0.88635\ttest-hr_err:49.29508\n",
      "[10]\ttrain-rmse:0.53987\ttrain-hr_err:0.05923\ttest-rmse:0.88832\ttest-hr_err:49.29508\n",
      "[15]\ttrain-rmse:0.54432\ttrain-hr_err:0.05923\ttest-rmse:0.89032\ttest-hr_err:49.29508\n",
      "[20]\ttrain-rmse:0.54880\ttrain-hr_err:0.05923\ttest-rmse:0.89235\ttest-hr_err:50.18451\n",
      "[25]\ttrain-rmse:0.55332\ttrain-hr_err:0.05923\ttest-rmse:0.89440\ttest-hr_err:50.19875\n",
      "[30]\ttrain-rmse:0.55787\ttrain-hr_err:0.05923\ttest-rmse:0.89642\ttest-hr_err:50.19875\n",
      "[31]\ttrain-rmse:0.55879\ttrain-hr_err:0.05923\ttest-rmse:0.89683\ttest-hr_err:50.19875\n",
      "\n",
      "\n",
      "Fine-tuning...\n",
      "[18:28:09] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:1.07644\ttrain-hr_err:0.11832\ttest-rmse:0.89822\ttest-hr_err:50.19875\n",
      "[5]\ttrain-rmse:1.08494\ttrain-hr_err:0.11832\ttest-rmse:0.90321\ttest-hr_err:50.19875\n",
      "[7]\ttrain-rmse:1.08836\ttrain-hr_err:0.11832\ttest-rmse:0.90522\ttest-hr_err:50.19875\n",
      "[18:28:11] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:0.57166\ttrain-hr_err:27.44409\ttest-rmse:0.90674\ttest-hr_err:48.65844\n",
      "[5]\ttrain-rmse:0.57620\ttrain-hr_err:27.54070\ttest-rmse:0.90930\ttest-hr_err:44.60055\n",
      "[10]\ttrain-rmse:0.58078\ttrain-hr_err:17.90456\ttest-rmse:0.91194\ttest-hr_err:43.38904\n",
      "[15]\ttrain-rmse:0.58539\ttrain-hr_err:17.98930\ttest-rmse:0.91462\ttest-hr_err:38.32461\n",
      "[20]\ttrain-rmse:0.59004\ttrain-hr_err:20.26979\ttest-rmse:0.91733\ttest-hr_err:34.87912\n",
      "[25]\ttrain-rmse:0.59472\ttrain-hr_err:20.36758\ttest-rmse:0.92008\ttest-hr_err:30.65234\n",
      "[30]\ttrain-rmse:0.59944\ttrain-hr_err:15.96342\ttest-rmse:0.92287\ttest-hr_err:29.97317\n",
      "[35]\ttrain-rmse:0.60419\ttrain-hr_err:10.92405\ttest-rmse:0.92597\ttest-hr_err:34.72410\n",
      "[40]\ttrain-rmse:0.60898\ttrain-hr_err:10.92405\ttest-rmse:0.92912\ttest-hr_err:34.48846\n",
      "[43]\ttrain-rmse:0.61187\ttrain-hr_err:9.80952\ttest-rmse:0.93104\ttest-hr_err:34.22572\n",
      "\n",
      "\n",
      "Fine-tuning...\n",
      "[18:28:23] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:1.18005\ttrain-hr_err:9.80952\ttest-rmse:0.93280\ttest-hr_err:34.24426\n",
      "[5]\ttrain-rmse:1.18904\ttrain-hr_err:9.80952\ttest-rmse:0.93845\ttest-hr_err:34.24426\n",
      "[7]\ttrain-rmse:1.19265\ttrain-hr_err:9.80952\ttest-rmse:0.94074\ttest-hr_err:34.24426\n",
      "[18:28:25] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:0.69704\ttrain-hr_err:6.57978\ttest-rmse:0.94239\ttest-hr_err:32.75207\n",
      "[5]\ttrain-rmse:0.70161\ttrain-hr_err:1.19409\ttest-rmse:0.94495\ttest-hr_err:25.71731\n",
      "[10]\ttrain-rmse:0.70622\ttrain-hr_err:2.96874\ttest-rmse:0.94754\ttest-hr_err:22.60144\n",
      "[15]\ttrain-rmse:0.71088\ttrain-hr_err:2.96874\ttest-rmse:0.95024\ttest-hr_err:20.62649\n",
      "[20]\ttrain-rmse:0.71561\ttrain-hr_err:7.48639\ttest-rmse:0.95305\ttest-hr_err:19.43419\n",
      "[25]\ttrain-rmse:0.72038\ttrain-hr_err:12.00403\ttest-rmse:0.95589\ttest-hr_err:17.84413\n",
      "[30]\ttrain-rmse:0.72519\ttrain-hr_err:16.52168\ttest-rmse:0.95879\ttest-hr_err:17.87010\n",
      "[35]\ttrain-rmse:0.73006\ttrain-hr_err:16.96565\ttest-rmse:0.96168\ttest-hr_err:16.27370\n",
      "[40]\ttrain-rmse:0.73500\ttrain-hr_err:16.96565\ttest-rmse:0.96447\ttest-hr_err:14.82737\n",
      "[45]\ttrain-rmse:0.73998\ttrain-hr_err:16.96565\ttest-rmse:0.96724\ttest-hr_err:14.79573\n",
      "[50]\ttrain-rmse:0.74498\ttrain-hr_err:16.96565\ttest-rmse:0.97016\ttest-hr_err:12.95255\n",
      "[55]\ttrain-rmse:0.74999\ttrain-hr_err:17.80658\ttest-rmse:0.97359\ttest-hr_err:12.95255\n",
      "[60]\ttrain-rmse:0.75503\ttrain-hr_err:17.80658\ttest-rmse:0.97704\ttest-hr_err:12.78287\n",
      "[64]\ttrain-rmse:0.75909\ttrain-hr_err:17.75377\ttest-rmse:0.97981\ttest-hr_err:12.81649\n",
      "\n",
      "\n",
      "Fine-tuning...\n",
      "[18:28:42] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:1.37857\ttrain-hr_err:13.41801\ttest-rmse:0.98090\ttest-hr_err:12.81649\n",
      "[5]\ttrain-rmse:1.38671\ttrain-hr_err:23.46007\ttest-rmse:0.98635\ttest-hr_err:12.81649\n",
      "[10]\ttrain-rmse:1.39490\ttrain-hr_err:29.66362\ttest-rmse:0.99184\ttest-hr_err:11.37016\n",
      "[15]\ttrain-rmse:1.40311\ttrain-hr_err:29.63351\ttest-rmse:0.99749\ttest-hr_err:10.02316\n",
      "[20]\ttrain-rmse:1.41135\ttrain-hr_err:29.63351\ttest-rmse:1.00337\ttest-hr_err:21.67370\n",
      "[23]\ttrain-rmse:1.41631\ttrain-hr_err:27.99260\ttest-rmse:1.00695\ttest-hr_err:34.33671\n",
      "[18:28:49] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:0.94397\ttrain-hr_err:6.64065\ttest-rmse:1.00767\ttest-hr_err:35.93671\n",
      "[5]\ttrain-rmse:0.94895\ttrain-hr_err:6.64065\ttest-rmse:1.01130\ttest-hr_err:36.00329\n",
      "[10]\ttrain-rmse:0.95396\ttrain-hr_err:6.55797\ttest-rmse:1.01495\ttest-hr_err:30.35974\n",
      "[15]\ttrain-rmse:0.95898\ttrain-hr_err:5.45021\ttest-rmse:1.01864\ttest-hr_err:27.00016\n",
      "[20]\ttrain-rmse:0.96401\ttrain-hr_err:4.75124\ttest-rmse:1.02237\ttest-hr_err:23.92879\n",
      "[25]\ttrain-rmse:0.96905\ttrain-hr_err:8.98965\ttest-rmse:1.02617\ttest-hr_err:25.36861\n",
      "[30]\ttrain-rmse:0.97405\ttrain-hr_err:8.98965\ttest-rmse:1.02952\ttest-hr_err:25.31531\n",
      "[35]\ttrain-rmse:0.97906\ttrain-hr_err:4.75124\ttest-rmse:1.03292\ttest-hr_err:22.93361\n",
      "[40]\ttrain-rmse:0.98407\ttrain-hr_err:8.98965\ttest-rmse:1.03636\ttest-hr_err:22.93361\n",
      "[45]\ttrain-rmse:0.98909\ttrain-hr_err:9.80454\ttest-rmse:1.04014\ttest-hr_err:25.68765\n",
      "[49]\ttrain-rmse:0.99312\ttrain-hr_err:9.80454\ttest-rmse:1.04355\ttest-hr_err:24.28106\n",
      "\n",
      "\n",
      "Fine-tuning...\n",
      "[18:29:03] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:1.59916\ttrain-hr_err:8.54297\ttest-rmse:1.04501\ttest-hr_err:24.28106\n",
      "[5]\ttrain-rmse:1.60817\ttrain-hr_err:8.54297\ttest-rmse:1.05232\ttest-hr_err:25.71539\n",
      "[10]\ttrain-rmse:1.61723\ttrain-hr_err:3.94417\ttest-rmse:1.05971\ttest-hr_err:25.23678\n",
      "[15]\ttrain-rmse:1.62635\ttrain-hr_err:4.02118\ttest-rmse:1.06718\ttest-hr_err:23.77504\n",
      "[16]\ttrain-rmse:1.62817\ttrain-hr_err:4.02118\ttest-rmse:1.06869\ttest-hr_err:23.77504\n",
      "[18:29:08] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:1.03836\ttrain-hr_err:10.36389\ttest-rmse:1.06927\ttest-hr_err:23.77504\n",
      "[5]\ttrain-rmse:1.04333\ttrain-hr_err:14.71270\ttest-rmse:1.07223\ttest-hr_err:25.16767\n",
      "[10]\ttrain-rmse:1.04832\ttrain-hr_err:14.71270\ttest-rmse:1.07535\ttest-hr_err:26.60588\n",
      "[15]\ttrain-rmse:1.05333\ttrain-hr_err:14.71270\ttest-rmse:1.07853\ttest-hr_err:24.91887\n",
      "\n",
      "\n",
      "Fine-tuning...\n",
      "[18:29:13] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:1.72383\ttrain-hr_err:14.69923\ttest-rmse:1.08078\ttest-hr_err:24.91887\n",
      "[5]\ttrain-rmse:1.73321\ttrain-hr_err:14.78286\ttest-rmse:1.08889\ttest-hr_err:22.09326\n",
      "[10]\ttrain-rmse:1.74263\ttrain-hr_err:10.43406\ttest-rmse:1.09706\ttest-hr_err:20.60352\n",
      "[15]\ttrain-rmse:1.75215\ttrain-hr_err:10.43406\ttest-rmse:1.10566\ttest-hr_err:23.35080\n",
      "[17]\ttrain-rmse:1.75598\ttrain-hr_err:10.43406\ttest-rmse:1.10913\ttest-hr_err:23.35080\n",
      "Finished training in 0:01:18.666427\n",
      "\n",
      "\n",
      "Training excluding subject 7...\n",
      "\n",
      "Rows per batch: 960\n",
      "[18:29:23] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:0.96825\ttrain-hr_err:34.40102\ttest-rmse:0.88360\ttest-hr_err:21.03517\n",
      "[5]\ttrain-rmse:0.97126\ttrain-hr_err:34.40102\ttest-rmse:0.88374\ttest-hr_err:22.76256\n",
      "[10]\ttrain-rmse:0.97430\ttrain-hr_err:34.40102\ttest-rmse:0.88392\ttest-hr_err:19.70355\n",
      "[15]\ttrain-rmse:0.97735\ttrain-hr_err:40.31781\ttest-rmse:0.88415\ttest-hr_err:19.07360\n",
      "[20]\ttrain-rmse:0.98066\ttrain-hr_err:34.40102\ttest-rmse:0.88471\ttest-hr_err:20.32251\n",
      "[25]\ttrain-rmse:0.98447\ttrain-hr_err:28.48422\ttest-rmse:0.88580\ttest-hr_err:21.83333\n",
      "[27]\ttrain-rmse:0.98601\ttrain-hr_err:26.25682\ttest-rmse:0.88623\ttest-hr_err:20.21926\n",
      "\n",
      "\n",
      "Fine-tuning...\n",
      "[18:29:30] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:1.34568\ttrain-hr_err:26.16746\ttest-rmse:0.88653\ttest-hr_err:20.21926\n",
      "[5]\ttrain-rmse:1.35212\ttrain-hr_err:26.69979\ttest-rmse:0.88803\ttest-hr_err:15.76594\n",
      "[10]\ttrain-rmse:1.35860\ttrain-hr_err:25.64525\ttest-rmse:0.88967\ttest-hr_err:17.34177\n",
      "[12]\ttrain-rmse:1.36120\ttrain-hr_err:21.13947\ttest-rmse:0.89035\ttest-hr_err:16.61070\n",
      "[18:29:34] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:0.97696\ttrain-hr_err:49.62567\ttest-rmse:0.89088\ttest-hr_err:16.61070\n",
      "[5]\ttrain-rmse:0.98155\ttrain-hr_err:40.57144\ttest-rmse:0.89178\ttest-hr_err:17.35072\n",
      "[10]\ttrain-rmse:0.98615\ttrain-hr_err:31.38648\ttest-rmse:0.89271\ttest-hr_err:18.40512\n",
      "[15]\ttrain-rmse:0.99075\ttrain-hr_err:26.81696\ttest-rmse:0.89372\ttest-hr_err:16.19195\n",
      "[20]\ttrain-rmse:0.99537\ttrain-hr_err:22.23675\ttest-rmse:0.89498\ttest-hr_err:14.74837\n",
      "[23]\ttrain-rmse:0.99814\ttrain-hr_err:20.59257\ttest-rmse:0.89575\ttest-hr_err:15.55522\n",
      "\n",
      "\n",
      "Fine-tuning...\n",
      "[18:29:41] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:1.38143\ttrain-hr_err:20.59257\ttest-rmse:0.89639\ttest-hr_err:15.55522\n",
      "[5]\ttrain-rmse:1.38811\ttrain-hr_err:11.79656\ttest-rmse:0.89961\ttest-hr_err:18.86516\n",
      "[8]\ttrain-rmse:1.39214\ttrain-hr_err:11.79656\ttest-rmse:0.90155\ttest-hr_err:18.27240\n",
      "[18:29:43] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:1.00404\ttrain-hr_err:12.55670\ttest-rmse:0.90183\ttest-hr_err:18.27240\n",
      "[5]\ttrain-rmse:1.00843\ttrain-hr_err:1.99804\ttest-rmse:0.90322\ttest-hr_err:14.99001\n",
      "[10]\ttrain-rmse:1.01282\ttrain-hr_err:7.67130\ttest-rmse:0.90451\ttest-hr_err:19.41166\n",
      "[15]\ttrain-rmse:1.01721\ttrain-hr_err:0.51634\ttest-rmse:0.90563\ttest-hr_err:16.64299\n",
      "[20]\ttrain-rmse:1.02157\ttrain-hr_err:3.57748\ttest-rmse:0.90672\ttest-hr_err:21.78750\n",
      "[21]\ttrain-rmse:1.02243\ttrain-hr_err:3.57748\ttest-rmse:0.90693\ttest-hr_err:21.37049\n",
      "\n",
      "\n",
      "Fine-tuning...\n",
      "[18:29:50] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:1.41864\ttrain-hr_err:3.57748\ttest-rmse:0.90755\ttest-hr_err:22.81682\n",
      "[5]\ttrain-rmse:1.42546\ttrain-hr_err:1.28494\ttest-rmse:0.91074\ttest-hr_err:21.80240\n",
      "[10]\ttrain-rmse:1.43233\ttrain-hr_err:1.38537\ttest-rmse:0.91401\ttest-hr_err:19.64423\n",
      "[15]\ttrain-rmse:1.43922\ttrain-hr_err:1.38537\ttest-rmse:0.91731\ttest-hr_err:18.81821\n",
      "[20]\ttrain-rmse:1.44615\ttrain-hr_err:1.38537\ttest-rmse:0.92060\ttest-hr_err:15.67441\n",
      "[25]\ttrain-rmse:1.45312\ttrain-hr_err:1.38537\ttest-rmse:0.92397\ttest-hr_err:12.79804\n",
      "[30]\ttrain-rmse:1.46013\ttrain-hr_err:1.38537\ttest-rmse:0.92742\ttest-hr_err:11.09968\n",
      "[34]\ttrain-rmse:1.46575\ttrain-hr_err:1.38537\ttest-rmse:0.93020\ttest-hr_err:11.50129\n",
      "[18:29:59] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:0.70540\ttrain-hr_err:21.09986\ttest-rmse:0.93143\ttest-hr_err:11.50129\n",
      "[5]\ttrain-rmse:0.70999\ttrain-hr_err:25.52719\ttest-rmse:0.93403\ttest-hr_err:11.50129\n",
      "[10]\ttrain-rmse:0.71462\ttrain-hr_err:25.52719\ttest-rmse:0.93667\ttest-hr_err:12.97943\n",
      "[15]\ttrain-rmse:0.71929\ttrain-hr_err:25.52719\ttest-rmse:0.93936\ttest-hr_err:14.46067\n",
      "\n",
      "\n",
      "Fine-tuning...\n",
      "[18:30:04] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:1.30165\ttrain-hr_err:25.58731\ttest-rmse:0.94093\ttest-hr_err:14.46067\n",
      "[5]\ttrain-rmse:1.30975\ttrain-hr_err:25.58731\ttest-rmse:0.94610\ttest-hr_err:14.46067\n",
      "[8]\ttrain-rmse:1.31462\ttrain-hr_err:25.58731\ttest-rmse:0.94924\ttest-hr_err:14.46067\n",
      "[18:30:07] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:0.92275\ttrain-hr_err:0.66976\ttest-rmse:0.94977\ttest-hr_err:14.49134\n",
      "[5]\ttrain-rmse:0.92698\ttrain-hr_err:0.66976\ttest-rmse:0.95244\ttest-hr_err:14.43702\n",
      "[10]\ttrain-rmse:0.93122\ttrain-hr_err:0.66976\ttest-rmse:0.95508\ttest-hr_err:14.46356\n",
      "[15]\ttrain-rmse:0.93547\ttrain-hr_err:5.54286\ttest-rmse:0.95774\ttest-hr_err:16.14931\n",
      "[17]\ttrain-rmse:0.93717\ttrain-hr_err:5.75179\ttest-rmse:0.95881\ttest-hr_err:16.14931\n",
      "\n",
      "\n",
      "Fine-tuning...\n",
      "[18:30:12] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:1.43359\ttrain-hr_err:5.75179\ttest-rmse:0.95969\ttest-hr_err:16.14931\n",
      "[5]\ttrain-rmse:1.44110\ttrain-hr_err:5.68984\ttest-rmse:0.96415\ttest-hr_err:14.78992\n",
      "[10]\ttrain-rmse:1.44867\ttrain-hr_err:5.68984\ttest-rmse:0.96866\ttest-hr_err:14.78992\n",
      "[13]\ttrain-rmse:1.45323\ttrain-hr_err:5.62776\ttest-rmse:0.97140\ttest-hr_err:16.26118\n",
      "Finished training in 0:00:53.207958\n",
      "\n",
      "\n",
      "Training excluding subject 7...\n",
      "\n",
      "Rows per batch: 960\n",
      "[18:30:19] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:0.50686\ttrain-hr_err:55.97688\ttest-rmse:0.92430\ttest-hr_err:49.66484\n",
      "[5]\ttrain-rmse:0.51075\ttrain-hr_err:55.97688\ttest-rmse:0.92657\ttest-hr_err:49.66484\n",
      "[10]\ttrain-rmse:0.51468\ttrain-hr_err:55.97688\ttest-rmse:0.92887\ttest-hr_err:49.66484\n",
      "[15]\ttrain-rmse:0.51864\ttrain-hr_err:55.97688\ttest-rmse:0.93120\ttest-hr_err:49.66484\n",
      "[16]\ttrain-rmse:0.51944\ttrain-hr_err:55.97688\ttest-rmse:0.93167\ttest-hr_err:49.66484\n",
      "\n",
      "\n",
      "Fine-tuning...\n",
      "[18:30:24] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:1.01162\ttrain-hr_err:55.97688\ttest-rmse:0.93256\ttest-hr_err:49.66484\n",
      "[5]\ttrain-rmse:1.01954\ttrain-hr_err:55.97688\ttest-rmse:0.93707\ttest-hr_err:49.66484\n",
      "[7]\ttrain-rmse:1.02273\ttrain-hr_err:55.97688\ttest-rmse:0.93889\ttest-hr_err:49.66484\n",
      "[18:30:26] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:0.87153\ttrain-hr_err:33.42504\ttest-rmse:0.94032\ttest-hr_err:32.30597\n",
      "[5]\ttrain-rmse:0.87613\ttrain-hr_err:0.08455\ttest-rmse:0.94273\ttest-hr_err:24.22243\n",
      "[10]\ttrain-rmse:0.88075\ttrain-hr_err:0.30539\ttest-rmse:0.94502\ttest-hr_err:23.13846\n",
      "[15]\ttrain-rmse:0.88533\ttrain-hr_err:0.37864\ttest-rmse:0.94730\ttest-hr_err:25.08193\n",
      "[20]\ttrain-rmse:0.88991\ttrain-hr_err:0.30539\ttest-rmse:0.94967\ttest-hr_err:28.49047\n",
      "[21]\ttrain-rmse:0.89075\ttrain-hr_err:0.30539\ttest-rmse:0.94999\ttest-hr_err:23.83344\n",
      "\n",
      "\n",
      "Fine-tuning...\n",
      "[18:30:32] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:1.30409\ttrain-hr_err:0.30539\ttest-rmse:0.95082\ttest-hr_err:23.80613\n",
      "[5]\ttrain-rmse:1.31080\ttrain-hr_err:0.30539\ttest-rmse:0.95345\ttest-hr_err:25.28384\n",
      "[10]\ttrain-rmse:1.31756\ttrain-hr_err:0.30539\ttest-rmse:0.95616\ttest-hr_err:23.76960\n",
      "[15]\ttrain-rmse:1.32435\ttrain-hr_err:4.95993\ttest-rmse:0.95892\ttest-hr_err:24.69802\n",
      "[20]\ttrain-rmse:1.33112\ttrain-hr_err:4.89215\ttest-rmse:0.96174\ttest-hr_err:23.84260\n",
      "[22]\ttrain-rmse:1.33385\ttrain-hr_err:4.89215\ttest-rmse:0.96289\ttest-hr_err:23.84260\n",
      "[18:30:39] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:0.65061\ttrain-hr_err:26.69420\ttest-rmse:0.96326\ttest-hr_err:23.84260\n",
      "[5]\ttrain-rmse:0.65481\ttrain-hr_err:26.69420\ttest-rmse:0.96514\ttest-hr_err:23.54720\n",
      "[10]\ttrain-rmse:0.65903\ttrain-hr_err:22.28548\ttest-rmse:0.96706\ttest-hr_err:21.88113\n",
      "[15]\ttrain-rmse:0.66329\ttrain-hr_err:13.39219\ttest-rmse:0.96901\ttest-hr_err:21.85807\n",
      "[20]\ttrain-rmse:0.66756\ttrain-hr_err:4.58485\ttest-rmse:0.97111\ttest-hr_err:23.59349\n",
      "[25]\ttrain-rmse:0.67187\ttrain-hr_err:3.80773\ttest-rmse:0.97327\ttest-hr_err:24.58246\n",
      "[30]\ttrain-rmse:0.67621\ttrain-hr_err:3.80773\ttest-rmse:0.97546\ttest-hr_err:23.64976\n",
      "[35]\ttrain-rmse:0.68058\ttrain-hr_err:0.89815\ttest-rmse:0.97769\ttest-hr_err:24.50520\n",
      "[40]\ttrain-rmse:0.68498\ttrain-hr_err:0.89815\ttest-rmse:0.97995\ttest-hr_err:25.85731\n",
      "[45]\ttrain-rmse:0.68941\ttrain-hr_err:4.30014\ttest-rmse:0.98228\ttest-hr_err:24.38774\n",
      "[49]\ttrain-rmse:0.69299\ttrain-hr_err:10.98036\ttest-rmse:0.98418\ttest-hr_err:23.00222\n",
      "\n",
      "\n",
      "Fine-tuning...\n",
      "[18:30:52] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:1.23719\ttrain-hr_err:11.80210\ttest-rmse:0.98516\ttest-hr_err:23.00222\n",
      "[5]\ttrain-rmse:1.24523\ttrain-hr_err:12.49789\ttest-rmse:0.99010\ttest-hr_err:23.00222\n",
      "[8]\ttrain-rmse:1.25007\ttrain-hr_err:12.49789\ttest-rmse:0.99310\ttest-hr_err:23.72290\n",
      "[18:30:55] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:0.93635\ttrain-hr_err:0.62406\ttest-rmse:0.99357\ttest-hr_err:23.67542\n",
      "[5]\ttrain-rmse:0.94066\ttrain-hr_err:17.38297\ttest-rmse:0.99612\ttest-hr_err:20.80443\n",
      "[10]\ttrain-rmse:0.94497\ttrain-hr_err:19.55858\ttest-rmse:0.99859\ttest-hr_err:17.12226\n",
      "[15]\ttrain-rmse:0.94929\ttrain-hr_err:15.41619\ttest-rmse:1.00083\ttest-hr_err:17.09324\n",
      "[20]\ttrain-rmse:0.95363\ttrain-hr_err:15.41619\ttest-rmse:1.00312\ttest-hr_err:15.62871\n",
      "[25]\ttrain-rmse:0.95798\ttrain-hr_err:15.33584\ttest-rmse:1.00543\ttest-hr_err:15.54495\n",
      "[30]\ttrain-rmse:0.96234\ttrain-hr_err:10.83030\ttest-rmse:1.00779\ttest-hr_err:19.75972\n",
      "[35]\ttrain-rmse:0.96670\ttrain-hr_err:6.45672\ttest-rmse:1.01015\ttest-hr_err:18.29351\n",
      "[38]\ttrain-rmse:0.96933\ttrain-hr_err:6.45672\ttest-rmse:1.01158\ttest-hr_err:18.26738\n",
      "\n",
      "\n",
      "Fine-tuning...\n",
      "[18:31:05] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:1.50216\ttrain-hr_err:6.45672\ttest-rmse:1.01294\ttest-hr_err:19.67089\n",
      "[5]\ttrain-rmse:1.50998\ttrain-hr_err:5.35476\ttest-rmse:1.01741\ttest-hr_err:19.67089\n",
      "[7]\ttrain-rmse:1.51313\ttrain-hr_err:5.35476\ttest-rmse:1.01922\ttest-hr_err:21.07440\n",
      "[18:31:08] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:1.07321\ttrain-hr_err:71.78201\ttest-rmse:1.02053\ttest-hr_err:21.09745\n",
      "[5]\ttrain-rmse:1.07844\ttrain-hr_err:58.35544\ttest-rmse:1.02283\ttest-hr_err:21.12046\n",
      "[10]\ttrain-rmse:1.08367\ttrain-hr_err:49.33650\ttest-rmse:1.02546\ttest-hr_err:21.58382\n",
      "[15]\ttrain-rmse:1.08887\ttrain-hr_err:26.83854\ttest-rmse:1.02759\ttest-hr_err:21.24539\n",
      "[17]\ttrain-rmse:1.09094\ttrain-hr_err:17.86658\ttest-rmse:1.02848\ttest-hr_err:21.22097\n",
      "\n",
      "\n",
      "Fine-tuning...\n",
      "[18:31:13] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:1.63900\ttrain-hr_err:17.86658\ttest-rmse:1.02980\ttest-hr_err:21.22097\n",
      "[5]\ttrain-rmse:1.64748\ttrain-hr_err:12.98374\ttest-rmse:1.03647\ttest-hr_err:21.27528\n",
      "[8]\ttrain-rmse:1.65259\ttrain-hr_err:8.57275\ttest-rmse:1.04045\ttest-hr_err:21.27528\n",
      "Finished training in 0:00:56.067222\n",
      "\n",
      "\n",
      "Training excluding subject 7...\n",
      "\n",
      "Rows per batch: 960\n",
      "[18:31:19] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:0.84201\ttrain-hr_err:0.24948\ttest-rmse:0.82788\ttest-hr_err:14.04410\n",
      "[5]\ttrain-rmse:0.84609\ttrain-hr_err:0.24948\ttest-rmse:0.83077\ttest-hr_err:14.04410\n",
      "[10]\ttrain-rmse:0.85016\ttrain-hr_err:0.24948\ttest-rmse:0.83364\ttest-hr_err:14.04410\n",
      "[15]\ttrain-rmse:0.85423\ttrain-hr_err:0.24948\ttest-rmse:0.83654\ttest-hr_err:14.04410\n",
      "[16]\ttrain-rmse:0.85505\ttrain-hr_err:0.24948\ttest-rmse:0.83711\ttest-hr_err:14.04410\n",
      "\n",
      "\n",
      "Fine-tuning...\n",
      "[18:31:24] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:1.22453\ttrain-hr_err:0.24948\ttest-rmse:0.83773\ttest-hr_err:13.59463\n",
      "[5]\ttrain-rmse:1.23090\ttrain-hr_err:0.32261\ttest-rmse:0.84095\ttest-hr_err:14.59962\n",
      "[9]\ttrain-rmse:1.23600\ttrain-hr_err:4.00659\ttest-rmse:0.84379\ttest-hr_err:13.11060\n",
      "[18:31:26] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:0.96229\ttrain-hr_err:36.83162\ttest-rmse:0.84415\ttest-hr_err:13.24705\n",
      "[5]\ttrain-rmse:0.96659\ttrain-hr_err:41.64448\ttest-rmse:0.84593\ttest-hr_err:8.98657\n",
      "[10]\ttrain-rmse:0.97091\ttrain-hr_err:35.26474\ttest-rmse:0.84771\ttest-hr_err:6.88517\n",
      "[15]\ttrain-rmse:0.97525\ttrain-hr_err:22.68896\ttest-rmse:0.84953\ttest-hr_err:9.74983\n",
      "[20]\ttrain-rmse:0.97959\ttrain-hr_err:10.02962\ttest-rmse:0.85138\ttest-hr_err:12.44647\n",
      "[24]\ttrain-rmse:0.98303\ttrain-hr_err:10.14079\ttest-rmse:0.85275\ttest-hr_err:16.77252\n",
      "\n",
      "\n",
      "Fine-tuning...\n",
      "[18:31:33] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:1.36878\ttrain-hr_err:10.14079\ttest-rmse:0.85377\ttest-hr_err:19.77721\n",
      "[5]\ttrain-rmse:1.37538\ttrain-hr_err:10.14079\ttest-rmse:0.85716\ttest-hr_err:25.73684\n",
      "[8]\ttrain-rmse:1.37937\ttrain-hr_err:10.14079\ttest-rmse:0.85927\ttest-hr_err:25.62038\n",
      "[18:31:36] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:0.98885\ttrain-hr_err:17.61057\ttest-rmse:0.85948\ttest-hr_err:27.37519\n",
      "[5]\ttrain-rmse:0.99264\ttrain-hr_err:13.48134\ttest-rmse:0.86054\ttest-hr_err:27.02802\n",
      "[10]\ttrain-rmse:0.99644\ttrain-hr_err:11.84057\ttest-rmse:0.86163\ttest-hr_err:24.46222\n",
      "[15]\ttrain-rmse:1.00025\ttrain-hr_err:11.84057\ttest-rmse:0.86263\ttest-hr_err:20.74528\n",
      "[20]\ttrain-rmse:1.00406\ttrain-hr_err:16.38867\ttest-rmse:0.86347\ttest-hr_err:19.28212\n",
      "[25]\ttrain-rmse:1.00788\ttrain-hr_err:7.46881\ttest-rmse:0.86435\ttest-hr_err:17.21925\n",
      "[30]\ttrain-rmse:1.01171\ttrain-hr_err:7.46881\ttest-rmse:0.86523\ttest-hr_err:17.21925\n",
      "[35]\ttrain-rmse:1.01554\ttrain-hr_err:1.45105\ttest-rmse:0.86613\ttest-hr_err:15.71691\n",
      "[40]\ttrain-rmse:1.01939\ttrain-hr_err:1.45105\ttest-rmse:0.86714\ttest-hr_err:16.55979\n",
      "[45]\ttrain-rmse:1.02324\ttrain-hr_err:3.00888\ttest-rmse:0.86843\ttest-hr_err:16.40086\n",
      "[50]\ttrain-rmse:1.02710\ttrain-hr_err:7.56194\ttest-rmse:0.86975\ttest-hr_err:14.83223\n",
      "[55]\ttrain-rmse:1.03097\ttrain-hr_err:7.56194\ttest-rmse:0.87112\ttest-hr_err:11.83503\n",
      "[60]\ttrain-rmse:1.03484\ttrain-hr_err:7.56194\ttest-rmse:0.87247\ttest-hr_err:9.37526\n",
      "[65]\ttrain-rmse:1.03872\ttrain-hr_err:7.56194\ttest-rmse:0.87382\ttest-hr_err:10.69287\n",
      "[70]\ttrain-rmse:1.04261\ttrain-hr_err:7.56194\ttest-rmse:0.87518\ttest-hr_err:9.15837\n",
      "[75]\ttrain-rmse:1.04651\ttrain-hr_err:7.56194\ttest-rmse:0.87652\ttest-hr_err:9.18472\n",
      "[80]\ttrain-rmse:1.05040\ttrain-hr_err:12.01669\ttest-rmse:0.87791\ttest-hr_err:7.73183\n",
      "[85]\ttrain-rmse:1.05431\ttrain-hr_err:11.92874\ttest-rmse:0.87934\ttest-hr_err:6.30326\n",
      "[90]\ttrain-rmse:1.05822\ttrain-hr_err:12.01669\ttest-rmse:0.88078\ttest-hr_err:6.30326\n",
      "[95]\ttrain-rmse:1.06214\ttrain-hr_err:16.47145\ttest-rmse:0.88226\ttest-hr_err:4.87469\n",
      "[100]\ttrain-rmse:1.06605\ttrain-hr_err:16.47145\ttest-rmse:0.88375\ttest-hr_err:4.87469\n",
      "[105]\ttrain-rmse:1.06997\ttrain-hr_err:16.47145\ttest-rmse:0.88531\ttest-hr_err:6.30326\n",
      "[110]\ttrain-rmse:1.07369\ttrain-hr_err:16.47145\ttest-rmse:0.88661\ttest-hr_err:3.39132\n",
      "[115]\ttrain-rmse:1.07727\ttrain-hr_err:16.47145\ttest-rmse:0.88788\ttest-hr_err:4.87981\n",
      "[120]\ttrain-rmse:1.08087\ttrain-hr_err:16.47145\ttest-rmse:0.88919\ttest-hr_err:4.90268\n",
      "[125]\ttrain-rmse:1.08449\ttrain-hr_err:16.47145\ttest-rmse:0.89053\ttest-hr_err:5.60622\n",
      "[126]\ttrain-rmse:1.08521\ttrain-hr_err:16.47145\ttest-rmse:0.89080\ttest-hr_err:5.58552\n",
      "\n",
      "\n",
      "Fine-tuning...\n",
      "[18:32:11] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:1.58296\ttrain-hr_err:16.56704\ttest-rmse:0.89147\ttest-hr_err:5.60622\n",
      "[5]\ttrain-rmse:1.59005\ttrain-hr_err:16.56704\ttest-rmse:0.89498\ttest-hr_err:5.00051\n",
      "[10]\ttrain-rmse:1.59719\ttrain-hr_err:16.56704\ttest-rmse:0.89854\ttest-hr_err:3.36158\n",
      "[14]\ttrain-rmse:1.60292\ttrain-hr_err:16.56704\ttest-rmse:0.90142\ttest-hr_err:3.36158\n",
      "[18:32:16] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:0.57889\ttrain-hr_err:18.00942\ttest-rmse:0.90281\ttest-hr_err:3.36158\n",
      "[5]\ttrain-rmse:0.58319\ttrain-hr_err:18.00942\ttest-rmse:0.90614\ttest-hr_err:3.36158\n",
      "[10]\ttrain-rmse:0.58752\ttrain-hr_err:18.00942\ttest-rmse:0.90951\ttest-hr_err:3.36158\n",
      "[15]\ttrain-rmse:0.59189\ttrain-hr_err:22.59176\ttest-rmse:0.91292\ttest-hr_err:3.36158\n",
      "\n",
      "\n",
      "Fine-tuning...\n",
      "[18:32:21] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:1.16737\ttrain-hr_err:10.52086\ttest-rmse:0.91493\ttest-hr_err:3.36158\n",
      "[5]\ttrain-rmse:1.17573\ttrain-hr_err:10.52086\ttest-rmse:0.92164\ttest-hr_err:3.36158\n",
      "[8]\ttrain-rmse:1.18078\ttrain-hr_err:10.52086\ttest-rmse:0.92571\ttest-hr_err:3.36158\n",
      "[18:32:24] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:0.94917\ttrain-hr_err:11.06405\ttest-rmse:0.92628\ttest-hr_err:3.36158\n",
      "[5]\ttrain-rmse:0.95368\ttrain-hr_err:0.56600\ttest-rmse:0.92915\ttest-hr_err:4.92066\n",
      "[10]\ttrain-rmse:0.95820\ttrain-hr_err:0.56600\ttest-rmse:0.93198\ttest-hr_err:5.72154\n",
      "[15]\ttrain-rmse:0.96274\ttrain-hr_err:4.02730\ttest-rmse:0.93484\ttest-hr_err:7.79822\n",
      "[17]\ttrain-rmse:0.96455\ttrain-hr_err:4.02730\ttest-rmse:0.93595\ttest-hr_err:7.19251\n",
      "\n",
      "\n",
      "Fine-tuning...\n",
      "[18:32:30] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:1.49973\ttrain-hr_err:3.95731\ttest-rmse:0.93716\ttest-hr_err:7.19251\n",
      "[5]\ttrain-rmse:1.50718\ttrain-hr_err:3.95731\ttest-rmse:0.94048\ttest-hr_err:7.19251\n",
      "[7]\ttrain-rmse:1.51018\ttrain-hr_err:3.95731\ttest-rmse:0.94178\ttest-hr_err:7.19251\n",
      "Finished training in 0:01:13.516323\n",
      "\n",
      "\n",
      "Training excluding subject 7...\n",
      "\n",
      "Rows per batch: 960\n",
      "[18:32:36] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:0.50731\ttrain-hr_err:58.37858\ttest-rmse:0.91769\ttest-hr_err:50.71783\n",
      "[5]\ttrain-rmse:0.51118\ttrain-hr_err:58.37858\ttest-rmse:0.91997\ttest-hr_err:50.71783\n",
      "[10]\ttrain-rmse:0.51510\ttrain-hr_err:58.37858\ttest-rmse:0.92227\ttest-hr_err:50.71783\n",
      "[15]\ttrain-rmse:0.51905\ttrain-hr_err:58.37858\ttest-rmse:0.92462\ttest-hr_err:50.71783\n",
      "\n",
      "\n",
      "Fine-tuning...\n",
      "[18:32:41] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:1.01196\ttrain-hr_err:58.37858\ttest-rmse:0.92598\ttest-hr_err:50.71783\n",
      "[5]\ttrain-rmse:1.01988\ttrain-hr_err:58.37858\ttest-rmse:0.93048\ttest-hr_err:50.71783\n",
      "[7]\ttrain-rmse:1.02306\ttrain-hr_err:58.37858\ttest-rmse:0.93230\ttest-hr_err:50.71783\n",
      "[18:32:44] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:0.63176\ttrain-hr_err:17.14841\ttest-rmse:0.93366\ttest-hr_err:45.06945\n",
      "[5]\ttrain-rmse:0.63595\ttrain-hr_err:9.09722\ttest-rmse:0.93587\ttest-hr_err:31.28890\n",
      "[10]\ttrain-rmse:0.64016\ttrain-hr_err:15.44153\ttest-rmse:0.93808\ttest-hr_err:33.07255\n",
      "[15]\ttrain-rmse:0.64441\ttrain-hr_err:15.44153\ttest-rmse:0.94031\ttest-hr_err:32.38470\n",
      "[20]\ttrain-rmse:0.64867\ttrain-hr_err:15.50157\ttest-rmse:0.94246\ttest-hr_err:33.40248\n",
      "[25]\ttrain-rmse:0.65293\ttrain-hr_err:15.44153\ttest-rmse:0.94422\ttest-hr_err:28.02073\n",
      "[30]\ttrain-rmse:0.65717\ttrain-hr_err:21.69512\ttest-rmse:0.94589\ttest-hr_err:29.22671\n",
      "[35]\ttrain-rmse:0.66140\ttrain-hr_err:21.74498\ttest-rmse:0.94795\ttest-hr_err:25.88875\n",
      "[40]\ttrain-rmse:0.66565\ttrain-hr_err:21.74498\ttest-rmse:0.95034\ttest-hr_err:25.83123\n",
      "[45]\ttrain-rmse:0.66992\ttrain-hr_err:21.74498\ttest-rmse:0.95277\ttest-hr_err:25.74536\n",
      "[50]\ttrain-rmse:0.67421\ttrain-hr_err:21.74498\ttest-rmse:0.95525\ttest-hr_err:27.25621\n",
      "[55]\ttrain-rmse:0.67854\ttrain-hr_err:21.74498\ttest-rmse:0.95747\ttest-hr_err:25.84973\n",
      "[60]\ttrain-rmse:0.68290\ttrain-hr_err:21.74498\ttest-rmse:0.95951\ttest-hr_err:25.87926\n",
      "[61]\ttrain-rmse:0.68378\ttrain-hr_err:21.79469\ttest-rmse:0.95993\ttest-hr_err:25.87926\n",
      "\n",
      "\n",
      "Fine-tuning...\n",
      "[18:33:00] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:1.21873\ttrain-hr_err:23.57975\ttest-rmse:0.96127\ttest-hr_err:25.87926\n",
      "[5]\ttrain-rmse:1.22659\ttrain-hr_err:29.72356\ttest-rmse:0.96604\ttest-hr_err:25.87926\n",
      "[8]\ttrain-rmse:1.23132\ttrain-hr_err:29.72356\ttest-rmse:0.96887\ttest-hr_err:25.87926\n",
      "[18:33:02] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:0.88834\ttrain-hr_err:6.05516\ttest-rmse:0.96930\ttest-hr_err:27.72364\n",
      "[5]\ttrain-rmse:0.89299\ttrain-hr_err:1.40625\ttest-rmse:0.97169\ttest-hr_err:26.99097\n",
      "[10]\ttrain-rmse:0.89758\ttrain-hr_err:6.62093\ttest-rmse:0.97428\ttest-hr_err:16.96537\n",
      "[15]\ttrain-rmse:0.90217\ttrain-hr_err:6.70708\ttest-rmse:0.97689\ttest-hr_err:14.61720\n",
      "[20]\ttrain-rmse:0.90683\ttrain-hr_err:0.32268\ttest-rmse:0.97936\ttest-hr_err:16.24746\n",
      "[25]\ttrain-rmse:0.91162\ttrain-hr_err:0.13650\ttest-rmse:0.98163\ttest-hr_err:14.20453\n",
      "[30]\ttrain-rmse:0.91640\ttrain-hr_err:0.13650\ttest-rmse:0.98388\ttest-hr_err:11.25874\n",
      "[35]\ttrain-rmse:0.92117\ttrain-hr_err:0.13650\ttest-rmse:0.98610\ttest-hr_err:9.93933\n",
      "[40]\ttrain-rmse:0.92594\ttrain-hr_err:0.13650\ttest-rmse:0.98836\ttest-hr_err:12.58466\n",
      "[45]\ttrain-rmse:0.93070\ttrain-hr_err:0.13650\ttest-rmse:0.99066\ttest-hr_err:11.24958\n",
      "[50]\ttrain-rmse:0.93546\ttrain-hr_err:0.13650\ttest-rmse:0.99300\ttest-hr_err:12.77885\n",
      "\n",
      "\n",
      "Fine-tuning...\n",
      "[18:33:15] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:1.43263\ttrain-hr_err:0.13650\ttest-rmse:0.99410\ttest-hr_err:12.77885\n",
      "[5]\ttrain-rmse:1.44029\ttrain-hr_err:0.32268\ttest-rmse:0.99962\ttest-hr_err:11.35912\n",
      "[10]\ttrain-rmse:1.44800\ttrain-hr_err:0.32268\ttest-rmse:1.00552\ttest-hr_err:11.29592\n",
      "[15]\ttrain-rmse:1.45574\ttrain-hr_err:0.32268\ttest-rmse:1.01150\ttest-hr_err:9.85933\n",
      "[18]\ttrain-rmse:1.46041\ttrain-hr_err:0.32268\ttest-rmse:1.01513\ttest-hr_err:9.85933\n",
      "[18:33:20] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:1.05236\ttrain-hr_err:10.77112\ttest-rmse:1.01679\ttest-hr_err:9.85933\n",
      "[5]\ttrain-rmse:1.05652\ttrain-hr_err:5.49551\ttest-rmse:1.01903\ttest-hr_err:8.29354\n",
      "[10]\ttrain-rmse:1.06098\ttrain-hr_err:1.16142\ttest-rmse:1.02153\ttest-hr_err:9.66693\n",
      "[15]\ttrain-rmse:1.06553\ttrain-hr_err:0.04530\ttest-rmse:1.02410\ttest-hr_err:11.41327\n",
      "[20]\ttrain-rmse:1.07008\ttrain-hr_err:4.56603\ttest-rmse:1.02670\ttest-hr_err:17.13604\n",
      "\n",
      "\n",
      "Fine-tuning...\n",
      "[18:33:27] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:1.59828\ttrain-hr_err:4.56603\ttest-rmse:1.02814\ttest-hr_err:18.48221\n",
      "[5]\ttrain-rmse:1.60628\ttrain-hr_err:9.09766\ttest-rmse:1.03283\ttest-hr_err:19.00560\n",
      "[9]\ttrain-rmse:1.61271\ttrain-hr_err:9.09766\ttest-rmse:1.03665\ttest-hr_err:22.05112\n",
      "[18:33:29] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:1.08533\ttrain-hr_err:1.90499\ttest-rmse:1.03699\ttest-hr_err:20.54701\n",
      "[5]\ttrain-rmse:1.09019\ttrain-hr_err:10.36314\ttest-rmse:1.03872\ttest-hr_err:13.43548\n",
      "[10]\ttrain-rmse:1.09507\ttrain-hr_err:14.51295\ttest-rmse:1.04048\ttest-hr_err:6.06774\n",
      "[15]\ttrain-rmse:1.09996\ttrain-hr_err:14.59221\ttest-rmse:1.04227\ttest-hr_err:11.00806\n",
      "[20]\ttrain-rmse:1.10487\ttrain-hr_err:14.59221\ttest-rmse:1.04413\ttest-hr_err:16.66192\n",
      "[24]\ttrain-rmse:1.10880\ttrain-hr_err:9.32337\ttest-rmse:1.04564\ttest-hr_err:19.67467\n",
      "\n",
      "\n",
      "Fine-tuning...\n",
      "[18:33:37] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:1.66551\ttrain-hr_err:4.68767\ttest-rmse:1.04724\ttest-hr_err:19.67467\n",
      "[5]\ttrain-rmse:1.67405\ttrain-hr_err:4.68767\ttest-rmse:1.05315\ttest-hr_err:15.24126\n",
      "[10]\ttrain-rmse:1.68260\ttrain-hr_err:13.77643\ttest-rmse:1.05850\ttest-hr_err:11.47049\n",
      "[15]\ttrain-rmse:1.69123\ttrain-hr_err:18.32081\ttest-rmse:1.06398\ttest-hr_err:12.40400\n",
      "[18]\ttrain-rmse:1.69646\ttrain-hr_err:18.32081\ttest-rmse:1.06752\ttest-hr_err:12.52781\n",
      "Finished training in 0:01:05.651057\n",
      "\n",
      "\n",
      "Training excluding subject 7...\n",
      "\n",
      "Rows per batch: 960\n",
      "[18:33:45] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:0.95538\ttrain-hr_err:1.32865\ttest-rmse:0.85244\ttest-hr_err:24.47908\n",
      "[5]\ttrain-rmse:0.95987\ttrain-hr_err:1.32865\ttest-rmse:0.85349\ttest-hr_err:24.47908\n",
      "[10]\ttrain-rmse:0.96438\ttrain-hr_err:1.32865\ttest-rmse:0.85462\ttest-hr_err:24.47908\n",
      "[15]\ttrain-rmse:0.96889\ttrain-hr_err:1.32865\ttest-rmse:0.85583\ttest-hr_err:26.07509\n",
      "\n",
      "\n",
      "Fine-tuning...\n",
      "[18:33:50] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:1.32332\ttrain-hr_err:1.32865\ttest-rmse:0.85679\ttest-hr_err:22.70465\n",
      "[5]\ttrain-rmse:1.32986\ttrain-hr_err:1.32865\ttest-rmse:0.86058\ttest-hr_err:20.88757\n",
      "[10]\ttrain-rmse:1.33642\ttrain-hr_err:1.32865\ttest-rmse:0.86443\ttest-hr_err:22.22826\n",
      "[15]\ttrain-rmse:1.34301\ttrain-hr_err:1.32865\ttest-rmse:0.86835\ttest-hr_err:20.85266\n",
      "[20]\ttrain-rmse:1.34960\ttrain-hr_err:1.32865\ttest-rmse:0.87231\ttest-hr_err:17.98812\n",
      "[25]\ttrain-rmse:1.35620\ttrain-hr_err:1.45102\ttest-rmse:0.87625\ttest-hr_err:22.25310\n",
      "[18:33:57] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:0.86143\ttrain-hr_err:15.01595\ttest-rmse:0.87715\ttest-hr_err:22.25310\n",
      "[5]\ttrain-rmse:0.86579\ttrain-hr_err:15.10780\ttest-rmse:0.87796\ttest-hr_err:23.73760\n",
      "[10]\ttrain-rmse:0.87016\ttrain-hr_err:26.92216\ttest-rmse:0.87880\ttest-hr_err:19.40520\n",
      "[15]\ttrain-rmse:0.87450\ttrain-hr_err:10.84313\ttest-rmse:0.87967\ttest-hr_err:19.40520\n",
      "[20]\ttrain-rmse:0.87887\ttrain-hr_err:12.78663\ttest-rmse:0.88076\ttest-hr_err:19.40520\n",
      "[25]\ttrain-rmse:0.88325\ttrain-hr_err:12.78663\ttest-rmse:0.88192\ttest-hr_err:20.02404\n",
      "[30]\ttrain-rmse:0.88761\ttrain-hr_err:17.17834\ttest-rmse:0.88314\ttest-hr_err:21.43373\n",
      "[35]\ttrain-rmse:0.89200\ttrain-hr_err:12.87340\ttest-rmse:0.88444\ttest-hr_err:21.31605\n",
      "[39]\ttrain-rmse:0.89551\ttrain-hr_err:4.34084\ttest-rmse:0.88552\ttest-hr_err:19.89749\n",
      "\n",
      "\n",
      "Fine-tuning...\n",
      "[18:34:08] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:1.33699\ttrain-hr_err:4.34084\ttest-rmse:0.88632\ttest-hr_err:21.30718\n",
      "[5]\ttrain-rmse:1.34400\ttrain-hr_err:4.34084\ttest-rmse:0.89037\ttest-hr_err:22.81839\n",
      "[7]\ttrain-rmse:1.34681\ttrain-hr_err:4.34084\ttest-rmse:0.89201\ttest-hr_err:25.79629\n",
      "[18:34:10] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:1.01875\ttrain-hr_err:2.42137\ttest-rmse:0.89308\ttest-hr_err:24.38815\n",
      "[5]\ttrain-rmse:1.02322\ttrain-hr_err:7.93290\ttest-rmse:0.89405\ttest-hr_err:30.25359\n",
      "[10]\ttrain-rmse:1.02769\ttrain-hr_err:16.57102\ttest-rmse:0.89477\ttest-hr_err:30.32811\n",
      "[15]\ttrain-rmse:1.03218\ttrain-hr_err:16.57102\ttest-rmse:0.89573\ttest-hr_err:28.43245\n",
      "\n",
      "\n",
      "Fine-tuning...\n",
      "[18:34:15] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:1.44702\ttrain-hr_err:16.66831\ttest-rmse:0.89673\ttest-hr_err:28.39965\n",
      "[5]\ttrain-rmse:1.45394\ttrain-hr_err:12.30467\ttest-rmse:0.90074\ttest-hr_err:32.71344\n",
      "[8]\ttrain-rmse:1.45811\ttrain-hr_err:12.30467\ttest-rmse:0.90317\ttest-hr_err:31.26547\n",
      "[18:34:18] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:0.90468\ttrain-hr_err:4.02970\ttest-rmse:0.90365\ttest-hr_err:31.26547\n",
      "[5]\ttrain-rmse:0.90891\ttrain-hr_err:4.02970\ttest-rmse:0.90627\ttest-hr_err:29.75959\n",
      "[10]\ttrain-rmse:0.91315\ttrain-hr_err:4.02970\ttest-rmse:0.90896\ttest-hr_err:28.26214\n",
      "[15]\ttrain-rmse:0.91741\ttrain-hr_err:1.13159\ttest-rmse:0.91172\ttest-hr_err:31.81329\n",
      "[20]\ttrain-rmse:0.92167\ttrain-hr_err:1.13159\ttest-rmse:0.91446\ttest-hr_err:29.98123\n",
      "[25]\ttrain-rmse:0.92591\ttrain-hr_err:0.74974\ttest-rmse:0.91719\ttest-hr_err:28.47535\n",
      "\n",
      "\n",
      "Fine-tuning...\n",
      "[18:34:25] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:1.39665\ttrain-hr_err:0.82371\ttest-rmse:0.91822\ttest-hr_err:28.47535\n",
      "[5]\ttrain-rmse:1.40401\ttrain-hr_err:0.82371\ttest-rmse:0.92387\ttest-hr_err:28.47535\n",
      "[7]\ttrain-rmse:1.40696\ttrain-hr_err:0.82371\ttest-rmse:0.92621\ttest-hr_err:28.47535\n",
      "[18:34:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:0.92581\ttrain-hr_err:1.07021\ttest-rmse:0.92769\ttest-hr_err:28.47535\n",
      "[5]\ttrain-rmse:0.93007\ttrain-hr_err:3.49475\ttest-rmse:0.92897\ttest-hr_err:28.47535\n",
      "[10]\ttrain-rmse:0.93437\ttrain-hr_err:1.14294\ttest-rmse:0.92990\ttest-hr_err:29.94662\n",
      "[15]\ttrain-rmse:0.93871\ttrain-hr_err:1.14294\ttest-rmse:0.93077\ttest-hr_err:31.51283\n",
      "[16]\ttrain-rmse:0.93958\ttrain-hr_err:1.14294\ttest-rmse:0.93095\ttest-hr_err:31.51283\n",
      "\n",
      "\n",
      "Fine-tuning...\n",
      "[18:34:33] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:1.43509\ttrain-hr_err:1.21293\ttest-rmse:0.93188\ttest-hr_err:31.51283\n",
      "[5]\ttrain-rmse:1.44281\ttrain-hr_err:1.21293\ttest-rmse:0.93685\ttest-hr_err:31.51283\n",
      "[10]\ttrain-rmse:1.45059\ttrain-hr_err:5.85061\ttest-rmse:0.94189\ttest-hr_err:30.80495\n",
      "[14]\ttrain-rmse:1.45686\ttrain-hr_err:1.21293\ttest-rmse:0.94583\ttest-hr_err:30.80495\n",
      "Finished training in 0:00:51.480524\n"
     ]
    }
   ],
   "source": [
    "options = [\n",
    "    {\n",
    "        'minmax': False,\n",
    "        'use_wavelet': True,\n",
    "        'use_bandpass': False\n",
    "    }\n",
    "]\n",
    "rpm = 5\n",
    "\n",
    "scores = []\n",
    "\n",
    "for option in options:\n",
    "    \n",
    "    truths = []\n",
    "    for subject in range(1, 8):\n",
    "\n",
    "        truth = IeeeGroundTruth(subject, 1, directory = 'channel_data3')\n",
    "        truth.align_rgb_bvp()\n",
    "        truth.fill_nans()\n",
    "        truth.process_rgb(\n",
    "            minmax = option['minmax'],\n",
    "            use_wavelet = option['use_wavelet'],\n",
    "            use_bandpass = option['use_bandpass']\n",
    "        )\n",
    "        truth.process_bvp()\n",
    "        truths.append(truth)\n",
    "\n",
    "    # mod = LonePineGBM(\n",
    "    #     truths, model_type = 'gbdt', random_state = None, loss_type = 'combined',\n",
    "    #     n_estimators = 188, split_size = 960, learning_rate = 0.001,\n",
    "    #     early_stopping_rounds = 16, mse_weight = 0.2, dtw_weight = 0.8, data_beg = 8000, data_end = 10180,\n",
    "    #     batches = 5, min_bandpass_freq = 0.7, max_bandpass_freq = 4.0, bandpass_order = 4,\n",
    "    #     #predicted_peaks_prominence = 0.17087564911262462,\n",
    "    #     predicted_peaks_prominence = 0.28,\n",
    "    #     true_peaks_prominence = 0.322741927274642, \n",
    "    #     max_depth = 6,\n",
    "    #     num_leaves = 34, max_bin = 235, num_feats_per_channel = 8, skip_amount = 12, finetune = True\n",
    "    # )\n",
    "\n",
    "\n",
    "    res = subjectwise_kfold(\n",
    "        truths, model_type = 'gbdt', random_state = None, loss_type = 'combined', rounds_per_model = rpm,\n",
    "        n_estimators = 188, split_size = 960, learning_rate = 0.001,\n",
    "        early_stopping_rounds = 16, mse_weight = 0.2, dtw_weight = 0.8, data_beg = 8000, data_end = 10180,\n",
    "        batches = 5, min_bandpass_freq = 0.7, max_bandpass_freq = 4.0, bandpass_order = 4,\n",
    "        # predicted_peaks_prominence = 0.24, true_peaks_prominence = 0.17,\n",
    "        #predicted_peaks_prominence = 0.17087564911262462,\n",
    "        predicted_peaks_prominence = 0.28,\n",
    "        true_peaks_prominence = 0.322741927274642,\n",
    "        max_depth = 6, num_leaves = 30, max_bin = 235, num_feats_per_channel = 8, skip_amount = 12, collect = True\n",
    "    )\n",
    "\n",
    "    scores.append(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: [[{'mse': 0.07806290005404186,\n",
       "    'hr_err': 1.2499770548737246,\n",
       "    'hrv_err': 0.23492036295208174,\n",
       "    'peaks_err': 0},\n",
       "   {'mse': 0.1258250676843192,\n",
       "    'hr_err': 0.7585335018963519,\n",
       "    'hrv_err': 0.4106632583764034,\n",
       "    'peaks_err': 0},\n",
       "   {'mse': 0.07942646402666902,\n",
       "    'hr_err': 35.21504615433001,\n",
       "    'hrv_err': 0.08608256071952644,\n",
       "    'peaks_err': 9}],\n",
       "  [{'mse': 0.0685634984813018,\n",
       "    'hr_err': 15.24371939666839,\n",
       "    'hrv_err': 0.22366742391577477,\n",
       "    'peaks_err': 4},\n",
       "   {'mse': 0.08052203054480025,\n",
       "    'hr_err': 29.94713359079151,\n",
       "    'hrv_err': 0.5338852322390053,\n",
       "    'peaks_err': 7},\n",
       "   {'mse': 0.08574098849250096,\n",
       "    'hr_err': 9.708756746243978,\n",
       "    'hrv_err': 1.0755083342538563,\n",
       "    'peaks_err': 2}],\n",
       "  [{'mse': 0.07989253003581824,\n",
       "    'hr_err': 31.69811320754716,\n",
       "    'hrv_err': 0.6139852843465015,\n",
       "    'peaks_err': 7},\n",
       "   {'mse': 0.08888574974939692,\n",
       "    'hr_err': 46.03250149527241,\n",
       "    'hrv_err': 0.6401964764779219,\n",
       "    'peaks_err': 11},\n",
       "   {'mse': 0.11080315129249803,\n",
       "    'hr_err': 13.185942390744472,\n",
       "    'hrv_err': 0.531844761492546,\n",
       "    'peaks_err': 4}],\n",
       "  [{'mse': 0.09031109338026481,\n",
       "    'hr_err': 5.1653860297675465,\n",
       "    'hrv_err': 0.4989808625794424,\n",
       "    'peaks_err': 1},\n",
       "   {'mse': 0.11460651863953816,\n",
       "    'hr_err': 0.4021616187005037,\n",
       "    'hrv_err': 0.4109891599281497,\n",
       "    'peaks_err': 0},\n",
       "   {'mse': 0.08274716464488206,\n",
       "    'hr_err': 40.07970551810729,\n",
       "    'hrv_err': 0.22269566904684185,\n",
       "    'peaks_err': 11}],\n",
       "  [{'mse': 0.0905686750303075,\n",
       "    'hr_err': 0.5974575107767564,\n",
       "    'hrv_err': 0.49577477885637145,\n",
       "    'peaks_err': 3},\n",
       "   {'mse': 0.08903433219619254,\n",
       "    'hr_err': 50.17703768624014,\n",
       "    'hrv_err': 0.9487055460064735,\n",
       "    'peaks_err': 13},\n",
       "   {'mse': 0.08551926560692909,\n",
       "    'hr_err': 19.893230001533254,\n",
       "    'hrv_err': 0.3422332282300454,\n",
       "    'peaks_err': 5}]],\n",
       " 2: [[{'mse': 0.09387604464894789,\n",
       "    'hr_err': 3.483847035328182,\n",
       "    'hrv_err': 0.6104295958425412,\n",
       "    'peaks_err': 1},\n",
       "   {'mse': 0.09828147923339943,\n",
       "    'hr_err': 28.710698541549334,\n",
       "    'hrv_err': 0.3185288524861831,\n",
       "    'peaks_err': 8},\n",
       "   {'mse': 0.08686556640066924,\n",
       "    'hr_err': 40.78049286102977,\n",
       "    'hrv_err': 0.1391124392782736,\n",
       "    'peaks_err': 11}],\n",
       "  [{'mse': 0.14801157131378628,\n",
       "    'hr_err': 6.809633784229632,\n",
       "    'hrv_err': 0.33997699074107174,\n",
       "    'peaks_err': 2},\n",
       "   {'mse': 0.09737224413406545,\n",
       "    'hr_err': 9.72406266951721,\n",
       "    'hrv_err': 0.2675349445803204,\n",
       "    'peaks_err': 4},\n",
       "   {'mse': 0.09608424025802709,\n",
       "    'hr_err': 21.24098124098124,\n",
       "    'hrv_err': 0.5389417720373082,\n",
       "    'peaks_err': 6}],\n",
       "  [{'mse': 0.12128309778692577,\n",
       "    'hr_err': 7.639406292055931,\n",
       "    'hrv_err': 0.5262014491318151,\n",
       "    'peaks_err': 1},\n",
       "   {'mse': 0.1273345171385834,\n",
       "    'hr_err': 25.805064500716668,\n",
       "    'hrv_err': 0.5037496022122809,\n",
       "    'peaks_err': 6},\n",
       "   {'mse': 0.0994226312224185,\n",
       "    'hr_err': 37.51797075105347,\n",
       "    'hrv_err': 0.43646861425449146,\n",
       "    'peaks_err': 10}],\n",
       "  [{'mse': 0.08988580270032885,\n",
       "    'hr_err': 17.320162881379574,\n",
       "    'hrv_err': 0.25234722162455997,\n",
       "    'peaks_err': 5},\n",
       "   {'mse': 0.12327296961937657,\n",
       "    'hr_err': 19.851736246586043,\n",
       "    'hrv_err': 0.36985932862412974,\n",
       "    'peaks_err': 8},\n",
       "   {'mse': 0.07282787584217504,\n",
       "    'hr_err': 40.974827875122934,\n",
       "    'hrv_err': 0.16199797641390737,\n",
       "    'peaks_err': 10}],\n",
       "  [{'mse': 0.0933607889654187,\n",
       "    'hr_err': 1.9550120383784417,\n",
       "    'hrv_err': 0.4762204387499386,\n",
       "    'peaks_err': 1},\n",
       "   {'mse': 0.12489039785567181,\n",
       "    'hr_err': 23.240968373682236,\n",
       "    'hrv_err': 0.36542194255651156,\n",
       "    'peaks_err': 8},\n",
       "   {'mse': 0.08431484419061033,\n",
       "    'hr_err': 31.19927645462768,\n",
       "    'hrv_err': 0.08912534634492505,\n",
       "    'peaks_err': 8}]],\n",
       " 3: [[{'mse': 0.12538023424509018,\n",
       "    'hr_err': 17.06369533312568,\n",
       "    'hrv_err': 0.3366300663488606,\n",
       "    'peaks_err': 5},\n",
       "   {'mse': 0.14876746214803402,\n",
       "    'hr_err': 11.273394495412845,\n",
       "    'hrv_err': 0.37593433789147535,\n",
       "    'peaks_err': 2},\n",
       "   {'mse': 0.12001059964413986,\n",
       "    'hr_err': 7.63265897349234,\n",
       "    'hrv_err': 0.43754741798658775,\n",
       "    'peaks_err': 3}],\n",
       "  [{'mse': 0.09161513805087432,\n",
       "    'hr_err': 9.219121009746708,\n",
       "    'hrv_err': 0.8378342256193643,\n",
       "    'peaks_err': 2},\n",
       "   {'mse': 0.1071994677513962,\n",
       "    'hr_err': 3.9303753063772007,\n",
       "    'hrv_err': 0.5988555072502119,\n",
       "    'peaks_err': 1},\n",
       "   {'mse': 0.12037140057897358,\n",
       "    'hr_err': 18.820198311092923,\n",
       "    'hrv_err': 0.5939820927450071,\n",
       "    'peaks_err': 4}],\n",
       "  [{'mse': 0.11442506008011953,\n",
       "    'hr_err': 7.856681350954489,\n",
       "    'hrv_err': 0.22939772288275379,\n",
       "    'peaks_err': 2},\n",
       "   {'mse': 0.11660922606203336,\n",
       "    'hr_err': 7.269881487852402,\n",
       "    'hrv_err': 0.3462471896601652,\n",
       "    'peaks_err': 2},\n",
       "   {'mse': 0.15253446696912976,\n",
       "    'hr_err': 9.865931227980695,\n",
       "    'hrv_err': 0.3405027794076846,\n",
       "    'peaks_err': 1}],\n",
       "  [{'mse': 0.08663614382007385,\n",
       "    'hr_err': 7.961621174524396,\n",
       "    'hrv_err': 0.411053236216067,\n",
       "    'peaks_err': 0},\n",
       "   {'mse': 0.09718006105050442,\n",
       "    'hr_err': 18.004582132053017,\n",
       "    'hrv_err': 0.3940096633585588,\n",
       "    'peaks_err': 4},\n",
       "   {'mse': 0.05653468013681218,\n",
       "    'hr_err': 11.852028568446478,\n",
       "    'hrv_err': 0.8539850012430653,\n",
       "    'peaks_err': 4}],\n",
       "  [{'mse': 0.08628707670731899,\n",
       "    'hr_err': 0.8136185765647639,\n",
       "    'hrv_err': 0.39723620113571995,\n",
       "    'peaks_err': 0},\n",
       "   {'mse': 0.10062478234870409,\n",
       "    'hr_err': 19.099657595963237,\n",
       "    'hrv_err': 0.12156426638003409,\n",
       "    'peaks_err': 6},\n",
       "   {'mse': 0.0935505650083279,\n",
       "    'hr_err': 9.896407094850673,\n",
       "    'hrv_err': 1.093123401977896,\n",
       "    'peaks_err': 2}]],\n",
       " 4: [[{'mse': 0.0979698918289572,\n",
       "    'hr_err': 1.4463644339750914,\n",
       "    'hrv_err': 0.42975647648772464,\n",
       "    'peaks_err': 0},\n",
       "   {'mse': 0.11293200961840369,\n",
       "    'hr_err': 16.353457779310602,\n",
       "    'hrv_err': 0.36345922722336,\n",
       "    'peaks_err': 3},\n",
       "   {'mse': 0.0948937212614526,\n",
       "    'hr_err': 6.750416934191023,\n",
       "    'hrv_err': 0.32310939398766986,\n",
       "    'peaks_err': 2},\n",
       "   {'mse': 0.1067169483559235,\n",
       "    'hr_err': 2.236315497814161,\n",
       "    'hrv_err': 0.32524068469523126,\n",
       "    'peaks_err': 1}],\n",
       "  [{'mse': 0.10618134014409224,\n",
       "    'hr_err': 0.891546485641193,\n",
       "    'hrv_err': 0.6916309145818536,\n",
       "    'peaks_err': 1},\n",
       "   {'mse': 0.1259759237170463,\n",
       "    'hr_err': 15.552970589699953,\n",
       "    'hrv_err': 0.391035467439924,\n",
       "    'peaks_err': 4},\n",
       "   {'mse': 0.16060313353705227,\n",
       "    'hr_err': 8.464084301940744,\n",
       "    'hrv_err': 0.3464258639378047,\n",
       "    'peaks_err': 3},\n",
       "   {'mse': 0.09381575474976014,\n",
       "    'hr_err': 17.317284545016847,\n",
       "    'hrv_err': 0.22957483416078656,\n",
       "    'peaks_err': 4}],\n",
       "  [{'mse': 0.11589523589386054,\n",
       "    'hr_err': 0.0,\n",
       "    'hrv_err': 0.5785904599113962,\n",
       "    'peaks_err': 1},\n",
       "   {'mse': 0.11339947608250256,\n",
       "    'hr_err': 1.027998121926501,\n",
       "    'hrv_err': 0.8752389246824758,\n",
       "    'peaks_err': 0},\n",
       "   {'mse': 0.07985139169778405,\n",
       "    'hr_err': 6.76534092993117,\n",
       "    'hrv_err': 0.49220762777120686,\n",
       "    'peaks_err': 1},\n",
       "   {'mse': 0.10210159514204566,\n",
       "    'hr_err': 20.027481051371836,\n",
       "    'hrv_err': 0.3525658712761748,\n",
       "    'peaks_err': 6}],\n",
       "  [{'mse': 0.08926719256868564,\n",
       "    'hr_err': 5.5248907840008314,\n",
       "    'hrv_err': 0.1570374636423778,\n",
       "    'peaks_err': 1},\n",
       "   {'mse': 0.06685798415905962,\n",
       "    'hr_err': 19.42110177404296,\n",
       "    'hrv_err': 0.30094685190293147,\n",
       "    'peaks_err': 6},\n",
       "   {'mse': 0.10491412765695612,\n",
       "    'hr_err': 35.0969617148826,\n",
       "    'hrv_err': 0.10035815563020747,\n",
       "    'peaks_err': 10},\n",
       "   {'mse': 0.08488978906952566,\n",
       "    'hr_err': 25.09950226447244,\n",
       "    'hrv_err': 0.1711869901882356,\n",
       "    'peaks_err': 7}],\n",
       "  [{'mse': 0.13441924602180352,\n",
       "    'hr_err': 8.349641226353555,\n",
       "    'hrv_err': 0.7810698490473491,\n",
       "    'peaks_err': 1},\n",
       "   {'mse': 0.08105148126461835,\n",
       "    'hr_err': 3.501966346278323,\n",
       "    'hrv_err': 0.1535804450003344,\n",
       "    'peaks_err': 3},\n",
       "   {'mse': 0.0946907159175821,\n",
       "    'hr_err': 29.260940395209722,\n",
       "    'hrv_err': 0.24928038348432321,\n",
       "    'peaks_err': 7},\n",
       "   {'mse': 0.07288550467638787,\n",
       "    'hr_err': 33.162969391956544,\n",
       "    'hrv_err': 0.2259970473807069,\n",
       "    'peaks_err': 9}]],\n",
       " 5: [[{'mse': 0.11528504824995155,\n",
       "    'hr_err': 22.14800612188003,\n",
       "    'hrv_err': 1.0215030216938505,\n",
       "    'peaks_err': 5},\n",
       "   {'mse': 0.12357051301459426,\n",
       "    'hr_err': 5.0623923145199115,\n",
       "    'hrv_err': 0.565866732795263,\n",
       "    'peaks_err': 2},\n",
       "   {'mse': 0.08683502333273356,\n",
       "    'hr_err': 33.61341380363056,\n",
       "    'hrv_err': 0.2178493383065014,\n",
       "    'peaks_err': 9}],\n",
       "  [{'mse': 0.11989013785870117,\n",
       "    'hr_err': 7.160244081962155,\n",
       "    'hrv_err': 0.4600578121935767,\n",
       "    'peaks_err': 2},\n",
       "   {'mse': 0.05253463376905661,\n",
       "    'hr_err': 16.070778037991154,\n",
       "    'hrv_err': 0.46366994308502074,\n",
       "    'peaks_err': 5},\n",
       "   {'mse': 0.08256972088539875,\n",
       "    'hr_err': 10.952380952380949,\n",
       "    'hrv_err': 0.9069617368969989,\n",
       "    'peaks_err': 4}],\n",
       "  [{'mse': 0.12994164199381236,\n",
       "    'hr_err': 9.726139782005703,\n",
       "    'hrv_err': 0.3556916279079724,\n",
       "    'peaks_err': 3},\n",
       "   {'mse': 0.09022400987144129,\n",
       "    'hr_err': 1.2163796578932207,\n",
       "    'hrv_err': 0.4510498082910295,\n",
       "    'peaks_err': 1},\n",
       "   {'mse': 0.08467074184367464,\n",
       "    'hr_err': 20.571407968704456,\n",
       "    'hrv_err': 0.48756704739666845,\n",
       "    'peaks_err': 6}],\n",
       "  [{'mse': 0.20473163190622182,\n",
       "    'hr_err': 2.619480081858754,\n",
       "    'hrv_err': 0.20297348376382354,\n",
       "    'peaks_err': 1},\n",
       "   {'mse': 0.16543425577431065,\n",
       "    'hr_err': 2.237492465340573,\n",
       "    'hrv_err': 0.4424018619077304,\n",
       "    'peaks_err': 0},\n",
       "   {'mse': 0.15480884638110565,\n",
       "    'hr_err': 4.203912608881893,\n",
       "    'hrv_err': 0.4418317648625822,\n",
       "    'peaks_err': 1}],\n",
       "  [{'mse': 0.1114149404266211,\n",
       "    'hr_err': 5.555847109245178,\n",
       "    'hrv_err': 0.37415604602612973,\n",
       "    'peaks_err': 2},\n",
       "   {'mse': 0.10143717805300209,\n",
       "    'hr_err': 8.973105134474324,\n",
       "    'hrv_err': 0.5877058534603445,\n",
       "    'peaks_err': 1},\n",
       "   {'mse': 0.055963046114075626,\n",
       "    'hr_err': 23.5752599890531,\n",
       "    'hrv_err': 0.4862615335390243,\n",
       "    'peaks_err': 7}]],\n",
       " 6: [[{'mse': 0.13913394692851103,\n",
       "    'hr_err': 10.948091790403723,\n",
       "    'hrv_err': 0.3742548336815125,\n",
       "    'peaks_err': 2},\n",
       "   {'mse': 0.08975051159654307,\n",
       "    'hr_err': 8.623720270908805,\n",
       "    'hrv_err': 1.050406815641352,\n",
       "    'peaks_err': 1},\n",
       "   {'mse': 0.0804437901487143,\n",
       "    'hr_err': 6.353068670303074,\n",
       "    'hrv_err': 0.4016970372801171,\n",
       "    'peaks_err': 3}],\n",
       "  [{'mse': 0.14864668519533927,\n",
       "    'hr_err': 26.947678770917562,\n",
       "    'hrv_err': 0.320108730959477,\n",
       "    'peaks_err': 8},\n",
       "   {'mse': 0.07164867639063258,\n",
       "    'hr_err': 1.323161143788937,\n",
       "    'hrv_err': 0.4927043908318536,\n",
       "    'peaks_err': 1},\n",
       "   {'mse': 0.1284456344795975,\n",
       "    'hr_err': 32.06235115825936,\n",
       "    'hrv_err': 0.2171016833324496,\n",
       "    'peaks_err': 9}],\n",
       "  [{'mse': 0.1500114945171377,\n",
       "    'hr_err': 9.335519213083302,\n",
       "    'hrv_err': 0.6075771808967653,\n",
       "    'peaks_err': 3},\n",
       "   {'mse': 0.12099196167362715,\n",
       "    'hr_err': 6.416040100250626,\n",
       "    'hrv_err': 0.47247558198720385,\n",
       "    'peaks_err': 1},\n",
       "   {'mse': 0.07329135378654221,\n",
       "    'hr_err': 3.2859399684044277,\n",
       "    'hrv_err': 0.5136272970406339,\n",
       "    'peaks_err': 0}],\n",
       "  [{'mse': 0.10030112276954913,\n",
       "    'hr_err': 30.093135563987587,\n",
       "    'hrv_err': 0.4986117527503535,\n",
       "    'peaks_err': 8},\n",
       "   {'mse': 0.10642131352411352,\n",
       "    'hr_err': 21.974949488508884,\n",
       "    'hrv_err': 0.323025573673559,\n",
       "    'peaks_err': 6},\n",
       "   {'mse': 0.10702650964738955,\n",
       "    'hr_err': 6.163167865697744,\n",
       "    'hrv_err': 0.6416301577110665,\n",
       "    'peaks_err': 2}],\n",
       "  [{'mse': 0.0981222745600124,\n",
       "    'hr_err': 9.523712840295772,\n",
       "    'hrv_err': 0.49059587627099827,\n",
       "    'peaks_err': 4},\n",
       "   {'mse': 0.10596972793314118,\n",
       "    'hr_err': 33.54526458787839,\n",
       "    'hrv_err': 0.5023253293374095,\n",
       "    'peaks_err': 8},\n",
       "   {'mse': 0.10224153135990746,\n",
       "    'hr_err': 10.301689391990386,\n",
       "    'hrv_err': 1.236553248926692,\n",
       "    'peaks_err': 2}]],\n",
       " 7: [[{'mse': 0.0851828753402566,\n",
       "    'hr_err': 0.7049033205515229,\n",
       "    'hrv_err': 0.8942482542589644,\n",
       "    'peaks_err': 0},\n",
       "   {'mse': 0.09240186118570787,\n",
       "    'hr_err': 33.195736769013905,\n",
       "    'hrv_err': 0.4524127350570671,\n",
       "    'peaks_err': 16},\n",
       "   {'mse': 0.0850201252084724,\n",
       "    'hr_err': 23.68018675226145,\n",
       "    'hrv_err': 0.39722358424021315,\n",
       "    'peaks_err': 9}],\n",
       "  [{'mse': 0.11339372288696999,\n",
       "    'hr_err': 5.762622257467626,\n",
       "    'hrv_err': 0.2708015377081732,\n",
       "    'peaks_err': 2},\n",
       "   {'mse': 0.08096649318478129,\n",
       "    'hr_err': 19.529024669961856,\n",
       "    'hrv_err': 0.6160281833897665,\n",
       "    'peaks_err': 4},\n",
       "   {'mse': 0.11406303775727013,\n",
       "    'hr_err': 35.13718070009462,\n",
       "    'hrv_err': 0.4483401864473531,\n",
       "    'peaks_err': 8}],\n",
       "  [{'mse': 0.11871704073088368,\n",
       "    'hr_err': 9.47951085642542,\n",
       "    'hrv_err': 0.2736851051283423,\n",
       "    'peaks_err': 2},\n",
       "   {'mse': 0.1245029819269244,\n",
       "    'hr_err': 13.056969270053713,\n",
       "    'hrv_err': 0.4284009848893262,\n",
       "    'peaks_err': 3},\n",
       "   {'mse': 0.07472719317913006,\n",
       "    'hr_err': 29.97005424954792,\n",
       "    'hrv_err': 0.17964332010926432,\n",
       "    'peaks_err': 5}],\n",
       "  [{'mse': 0.1171405466646622,\n",
       "    'hr_err': 1.318681318681314,\n",
       "    'hrv_err': 0.6125580089139419,\n",
       "    'peaks_err': 1},\n",
       "   {'mse': 0.09430637006950254,\n",
       "    'hr_err': 64.86162573531615,\n",
       "    'hrv_err': 1.3294634611396066,\n",
       "    'peaks_err': 15},\n",
       "   {'mse': 0.09032580883885653,\n",
       "    'hr_err': 7.401818294266803,\n",
       "    'hrv_err': 0.36105062881902394,\n",
       "    'peaks_err': 2}],\n",
       "  [{'mse': 0.145995898129224,\n",
       "    'hr_err': 3.4962333040624856,\n",
       "    'hrv_err': 0.5222052570846328,\n",
       "    'peaks_err': 2},\n",
       "   {'mse': 0.09048218482249863,\n",
       "    'hr_err': 17.793307759504742,\n",
       "    'hrv_err': 0.28975776642356277,\n",
       "    'peaks_err': 5},\n",
       "   {'mse': 0.16179146310395598,\n",
       "    'hr_err': 12.984183428684318,\n",
       "    'hrv_err': 0.34489337875218373,\n",
       "    'peaks_err': 4}]]}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# min_bandpass_freq = 0.9421772128909808\n",
    "# max_bandpass_freq = 3.6351090994830813\n",
    "scores[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject 1:\n",
      "\t- HR: 18.2; HRV: 0.59; Peaks: 4.67\n",
      "\t- HR: 25.91; HRV: 0.36; Peaks: 6.33\n",
      "\t- HR: 28.86; HRV: 0.59; Peaks: 7.0\n",
      "\t- HR: 14.37; HRV: 0.22; Peaks: 4.33\n",
      "\t- HR: 9.64; HRV: 0.34; Peaks: 2.33\n",
      "\tMean HR: 19.4; Mean HRV: 0.42; Mean Peaks: 4.93\n",
      "\n",
      "Subject 2:\n",
      "\t- HR: 5.86; HRV: 0.31; Peaks: 1.67\n",
      "\t- HR: 23.87; HRV: 1.02; Peaks: 11.0\n",
      "\t- HR: 16.97; HRV: 0.35; Peaks: 5.0\n",
      "\t- HR: 8.3; HRV: 0.61; Peaks: 3.0\n",
      "\t- HR: 28.07; HRV: 0.58; Peaks: 8.33\n",
      "\tMean HR: 16.61; Mean HRV: 0.57; Mean Peaks: 5.8\n",
      "\n",
      "Subject 3:\n",
      "\t- HR: 40.06; HRV: 0.44; Peaks: 10.0\n",
      "\t- HR: 11.91; HRV: 0.36; Peaks: 3.33\n",
      "\t- HR: 28.66; HRV: 0.3; Peaks: 7.33\n",
      "\t- HR: 17.21; HRV: 0.33; Peaks: 3.67\n",
      "\t- HR: 10.28; HRV: 0.4; Peaks: 2.67\n",
      "\tMean HR: 21.62; Mean HRV: 0.37; Mean Peaks: 5.4\n",
      "\n",
      "Subject 4:\n",
      "\t- HR: 8.72; HRV: 0.63; Peaks: 2.0\n",
      "\t- HR: 17.88; HRV: 0.44; Peaks: 5.0\n",
      "\t- HR: 13.77; HRV: 0.29; Peaks: 3.5\n",
      "\t- HR: 8.81; HRV: 0.37; Peaks: 2.5\n",
      "\t- HR: 18.74; HRV: 0.58; Peaks: 5.0\n",
      "\tMean HR: 13.58; Mean HRV: 0.46; Mean Peaks: 3.6\n",
      "\n",
      "Subject 5:\n",
      "\t- HR: 8.19; HRV: 0.5; Peaks: 2.33\n",
      "\t- HR: 3.25; HRV: 0.42; Peaks: 1.0\n",
      "\t- HR: 12.51; HRV: 0.4; Peaks: 2.67\n",
      "\t- HR: 16.33; HRV: 0.5; Peaks: 4.0\n",
      "\t- HR: 17.81; HRV: 0.39; Peaks: 4.33\n",
      "\tMean HR: 11.62; Mean HRV: 0.44; Mean Peaks: 2.87\n",
      "\n",
      "Subject 6:\n",
      "\t- HR: 27.9; HRV: 1.14; Peaks: 9.0\n",
      "\t- HR: 14.74; HRV: 0.38; Peaks: 4.0\n",
      "\t- HR: 32.16; HRV: 0.44; Peaks: 8.67\n",
      "\t- HR: 11.26; HRV: 0.49; Peaks: 2.67\n",
      "\t- HR: 29.21; HRV: 0.91; Peaks: 6.67\n",
      "\tMean HR: 23.05; Mean HRV: 0.67; Mean Peaks: 6.2\n",
      "\n",
      "Subject 7:\n",
      "\t- HR: 16.42; HRV: 0.47; Peaks: 4.0\n",
      "\t- HR: 19.37; HRV: 0.45; Peaks: 5.0\n",
      "\t- HR: 9.09; HRV: 0.53; Peaks: 2.33\n",
      "\t- HR: 18.59; HRV: 0.49; Peaks: 4.0\n",
      "\t- HR: 28.24; HRV: 0.33; Peaks: 6.67\n",
      "\tMean HR: 18.34; Mean HRV: 0.45; Mean Peaks: 4.4\n",
      "\n"
     ]
    }
   ],
   "source": [
    "res = scores[0]\n",
    "for sub in res:\n",
    "    print(f'Subject {sub}:')\n",
    "    sub_errs = {'hr': [], 'hrv': [], 'peaks': []}\n",
    "    for subres in res[sub]:\n",
    "        hr = round(np.nanmean([d['hr_err'] for d in subres]), 2)\n",
    "        hrv = round(np.nanmean([d['hrv_err'] for d in subres]), 2)\n",
    "        peaks = round(np.nanmean([d['peaks_err'] for d in subres]), 2)\n",
    "        sub_errs['hr'].append(hr)\n",
    "        sub_errs['hrv'].append(hrv)\n",
    "        sub_errs['peaks'].append(peaks)\n",
    "\n",
    "        print(f'\\t- HR: {hr}; HRV: {hrv}; Peaks: {peaks}')\n",
    "    \n",
    "    print(f'\\tMean HR: {round(np.mean(sub_errs[\"hr\"]), 2)}; Mean HRV: {round(np.mean(sub_errs[\"hrv\"]), 2)}; Mean Peaks: {round(np.mean(sub_errs[\"peaks\"]), 2)}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows per batch: 960\n",
      "[17:11:30] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:0.84513\ttrain-hr_err:4.91392\ttest-rmse:0.75984\ttest-hr_err:13.73589\n",
      "[5]\ttrain-rmse:0.84915\ttrain-hr_err:4.91392\ttest-rmse:0.76075\ttest-hr_err:16.42539\n",
      "[10]\ttrain-rmse:0.85317\ttrain-hr_err:4.91392\ttest-rmse:0.76191\ttest-hr_err:15.38251\n",
      "[15]\ttrain-rmse:0.85719\ttrain-hr_err:4.97659\ttest-rmse:0.76312\ttest-hr_err:15.38251\n",
      "[16]\ttrain-rmse:0.85800\ttrain-hr_err:4.97659\ttest-rmse:0.76336\ttest-hr_err:15.38251\n",
      "\n",
      "\n",
      "Fine-tuning...\n",
      "[17:11:34] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:1.22455\ttrain-hr_err:4.97659\ttest-rmse:0.76426\ttest-hr_err:15.34549\n",
      "[5]\ttrain-rmse:1.23069\ttrain-hr_err:4.97659\ttest-rmse:0.76877\ttest-hr_err:14.76492\n",
      "[10]\ttrain-rmse:1.23687\ttrain-hr_err:9.55363\ttest-rmse:0.77335\ttest-hr_err:14.55925\n",
      "[15]\ttrain-rmse:1.24308\ttrain-hr_err:9.55363\ttest-rmse:0.77769\ttest-hr_err:11.08796\n",
      "[20]\ttrain-rmse:1.24932\ttrain-hr_err:14.21948\ttest-rmse:0.78210\ttest-hr_err:16.44530\n",
      "[23]\ttrain-rmse:1.25308\ttrain-hr_err:14.21948\ttest-rmse:0.78479\ttest-hr_err:18.61724\n",
      "[17:11:39] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:0.97760\ttrain-hr_err:35.13338\ttest-rmse:0.78514\ttest-hr_err:18.46703\n",
      "[5]\ttrain-rmse:0.98200\ttrain-hr_err:25.97547\ttest-rmse:0.78690\ttest-hr_err:14.39298\n",
      "[10]\ttrain-rmse:0.98641\ttrain-hr_err:20.90449\ttest-rmse:0.78868\ttest-hr_err:7.90110\n",
      "[15]\ttrain-rmse:0.99082\ttrain-hr_err:17.02017\ttest-rmse:0.79047\ttest-hr_err:8.62878\n",
      "[20]\ttrain-rmse:0.99521\ttrain-hr_err:1.25733\ttest-rmse:0.79222\ttest-hr_err:8.38925\n",
      "[25]\ttrain-rmse:0.99960\ttrain-hr_err:1.38088\ttest-rmse:0.79402\ttest-hr_err:8.20456\n",
      "[28]\ttrain-rmse:1.00223\ttrain-hr_err:1.38088\ttest-rmse:0.79511\ttest-hr_err:8.71617\n",
      "\n",
      "\n",
      "Fine-tuning...\n",
      "[17:11:46] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:1.41120\ttrain-hr_err:1.38088\ttest-rmse:0.79637\ttest-hr_err:8.84848\n",
      "[5]\ttrain-rmse:1.41815\ttrain-hr_err:1.38088\ttest-rmse:0.80083\ttest-hr_err:11.47673\n",
      "[7]\ttrain-rmse:1.42094\ttrain-hr_err:1.38088\ttest-rmse:0.80264\ttest-hr_err:11.52721\n",
      "[17:11:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:0.97800\ttrain-hr_err:1.22893\ttest-rmse:0.80365\ttest-hr_err:14.79496\n",
      "[5]\ttrain-rmse:0.98231\ttrain-hr_err:3.23618\ttest-rmse:0.80415\ttest-hr_err:16.49698\n",
      "[10]\ttrain-rmse:0.98664\ttrain-hr_err:3.56297\ttest-rmse:0.80468\ttest-hr_err:15.83609\n",
      "[15]\ttrain-rmse:0.99099\ttrain-hr_err:2.43959\ttest-rmse:0.80523\ttest-hr_err:15.52493\n",
      "\n",
      "\n",
      "Fine-tuning...\n",
      "[17:11:52] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:1.40322\ttrain-hr_err:2.06745\ttest-rmse:0.80584\ttest-hr_err:15.83122\n",
      "[5]\ttrain-rmse:1.40989\ttrain-hr_err:8.16588\ttest-rmse:0.80842\ttest-hr_err:17.33871\n",
      "[10]\ttrain-rmse:1.41660\ttrain-hr_err:8.35021\ttest-rmse:0.81130\ttest-hr_err:18.36898\n",
      "[12]\ttrain-rmse:1.41929\ttrain-hr_err:8.35021\ttest-rmse:0.81260\ttest-hr_err:18.44729\n",
      "[17:11:55] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:0.90804\ttrain-hr_err:11.82370\ttest-rmse:0.81289\ttest-hr_err:16.38941\n",
      "[5]\ttrain-rmse:0.91236\ttrain-hr_err:17.29379\ttest-rmse:0.81422\ttest-hr_err:16.38279\n",
      "[10]\ttrain-rmse:0.91670\ttrain-hr_err:11.72255\ttest-rmse:0.81610\ttest-hr_err:16.40621\n",
      "[15]\ttrain-rmse:0.92102\ttrain-hr_err:0.53331\ttest-rmse:0.81806\ttest-hr_err:15.87296\n",
      "[20]\ttrain-rmse:0.92531\ttrain-hr_err:0.53331\ttest-rmse:0.82000\ttest-hr_err:17.01393\n",
      "[25]\ttrain-rmse:0.92962\ttrain-hr_err:0.53331\ttest-rmse:0.82181\ttest-hr_err:12.61684\n",
      "[30]\ttrain-rmse:0.93394\ttrain-hr_err:0.53331\ttest-rmse:0.82358\ttest-hr_err:9.27867\n",
      "[35]\ttrain-rmse:0.93826\ttrain-hr_err:0.46903\ttest-rmse:0.82538\ttest-hr_err:8.18157\n",
      "[40]\ttrain-rmse:0.94259\ttrain-hr_err:0.46903\ttest-rmse:0.82719\ttest-hr_err:8.21700\n",
      "[45]\ttrain-rmse:0.94692\ttrain-hr_err:0.46903\ttest-rmse:0.82905\ttest-hr_err:9.77042\n",
      "[49]\ttrain-rmse:0.95039\ttrain-hr_err:0.46903\ttest-rmse:0.83057\ttest-hr_err:12.05978\n",
      "\n",
      "\n",
      "Fine-tuning...\n",
      "[17:12:06] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:1.44219\ttrain-hr_err:0.46903\ttest-rmse:0.83156\ttest-hr_err:12.05978\n",
      "[5]\ttrain-rmse:1.44983\ttrain-hr_err:0.53331\ttest-rmse:0.83670\ttest-hr_err:12.05978\n",
      "[10]\ttrain-rmse:1.45754\ttrain-hr_err:0.53331\ttest-rmse:0.84159\ttest-hr_err:12.05978\n",
      "[11]\ttrain-rmse:1.45909\ttrain-hr_err:0.53331\ttest-rmse:0.84254\ttest-hr_err:12.05978\n",
      "[17:12:09] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:0.69642\ttrain-hr_err:13.78892\ttest-rmse:0.84333\ttest-hr_err:12.05978\n",
      "[5]\ttrain-rmse:0.70184\ttrain-hr_err:13.78892\ttest-rmse:0.84733\ttest-hr_err:10.94480\n",
      "[10]\ttrain-rmse:0.70731\ttrain-hr_err:13.78892\ttest-rmse:0.85138\ttest-hr_err:12.05978\n",
      "[15]\ttrain-rmse:0.71282\ttrain-hr_err:13.78892\ttest-rmse:0.85547\ttest-hr_err:12.05978\n",
      "[18]\ttrain-rmse:0.71616\ttrain-hr_err:13.78892\ttest-rmse:0.85795\ttest-hr_err:10.94480\n",
      "\n",
      "\n",
      "Fine-tuning...\n",
      "[17:12:14] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:1.38516\ttrain-hr_err:13.86333\ttest-rmse:0.85939\ttest-hr_err:10.94480\n",
      "[5]\ttrain-rmse:1.39509\ttrain-hr_err:13.86333\ttest-rmse:0.86666\ttest-hr_err:12.05978\n",
      "[8]\ttrain-rmse:1.40107\ttrain-hr_err:13.86333\ttest-rmse:0.87106\ttest-hr_err:12.05978\n",
      "Finished training in 0:00:45.786678\n"
     ]
    }
   ],
   "source": [
    "test_subject = 7\n",
    "test_subject_truth = truths[test_subject - 1]\n",
    "import xgboost as xgb\n",
    "mod = LonePineGBM(\n",
    "    truths, model_type = 'gbdt', random_state = None, loss_type = 'combined',\n",
    "    n_estimators = 188, split_size = 960, learning_rate = 0.001,\n",
    "    early_stopping_rounds = 16, mse_weight = 0.2, dtw_weight = 0.8, data_beg = 8000, data_end = 10180,\n",
    "    batches = 5, min_bandpass_freq = 0.7, max_bandpass_freq = 4.0, bandpass_order = 4,\n",
    "    #predicted_peaks_prominence = 0.17087564911262462,\n",
    "    predicted_peaks_prominence = 0.28,\n",
    "    true_peaks_prominence = 0.322741927274642, \n",
    "    max_depth = 6,\n",
    "    num_leaves = 34, max_bin = 235, num_feats_per_channel = 8, skip_amount = 12, finetune = True\n",
    ")\n",
    "mod.fit_xgb()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "MSE: 0.09495280437492427\n",
      "HR error: 11.044319857958639\n",
      "HR error squared: 207.1220259623228\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "dump_model() missing 1 required positional argument: 'fout'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/rg/h0swnf611kvgnhnj7mb2m6300000gn/T/ipykernel_22907/3065721389.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'HR error squared: {hr_err_sq}\\n\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mmod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_model_stats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mmod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/rg/h0swnf611kvgnhnj7mb2m6300000gn/T/ipykernel_22907/2512815905.py\u001b[0m in \u001b[0;36mget_model_stats\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    405\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_model_stats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m         \u001b[0mmodel_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgbm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m         \u001b[0mtree_depths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: dump_model() missing 1 required positional argument: 'fout'"
     ]
    }
   ],
   "source": [
    "mse, hr_err, hr_err_sq = mod.xgb_eval()\n",
    "\n",
    "print(f'\\n\\nMSE: {mse}')\n",
    "print(f'HR error: {hr_err}')\n",
    "print(f'HR error squared: {hr_err_sq}\\n\\n')\n",
    "\n",
    "mod.get_model_stats()\n",
    "mod.plot_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 0:00:00.016862\n",
      "True HR: 50.086956521739125; Pred HR: 106.19469026548674\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "beg = 3000\n",
    "end = beg + 960\n",
    "\n",
    "model = mod\n",
    "\n",
    "data = test_subject_truth.prepare_data_for_ml(8, 12)\n",
    "x = xgb.DMatrix(data.drop(columns = ['bvp']).to_numpy())\n",
    "y = data['bvp'].to_numpy()\n",
    "\n",
    "def measure_code_block():\n",
    "    t = datetime.today()\n",
    "    targ = y[beg: end]\n",
    "    pred = model.predict(x)\n",
    "    pred = pred[beg: end]\n",
    "    targ, pred = mod.process_signal(targ, pred, use_bandpass=True)\n",
    "    print(f'Elapsed time: {datetime.today() - t}')\n",
    "    return targ, pred\n",
    "\n",
    "targ, pred = measure_code_block()\n",
    "\n",
    "pred_peaks, _ = mod.get_predicted_peaks(pred)\n",
    "true_peaks, _ = mod.get_true_peaks(targ)\n",
    "\n",
    "plt.plot(targ)\n",
    "plt.plot(pred)\n",
    "plt.scatter(pred_peaks, pred[pred_peaks], c='r')\n",
    "plt.scatter(true_peaks, targ[true_peaks], c='g')\n",
    "\n",
    "pred_ibis = np.diff(pred_peaks) / 64\n",
    "true_ibis = np.diff(true_peaks) / 64\n",
    "pred_hr = get_hr(pred_ibis)\n",
    "true_hr = get_hr(true_ibis)\n",
    "print(f'True HR: {true_hr}; Pred HR: {pred_hr}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "def normalized_lomb_periodogram(time, ibis, frequency_range):\n",
    "    \"\"\"\n",
    "    Calculate the normalized Lomb periodogram of detrended IBIs.\n",
    "\n",
    "    Args:\n",
    "    time (numpy array): The time values of the IBIs\n",
    "    ibis (numpy array): The detrended IBIs\n",
    "    frequency_range (tuple): A tuple with the minimum and maximum frequencies to consider (min_freq, max_freq)\n",
    "\n",
    "    Returns:\n",
    "    (numpy array, numpy array): The frequencies and corresponding Lomb periodogram values\n",
    "    \"\"\"\n",
    "\n",
    "    # Calculate the Lomb periodogram\n",
    "    angular_frequencies = np.linspace(frequency_range[0] * 2 * np.pi, frequency_range[1] * 2 * np.pi, len(time))\n",
    "    periodogram = scipy.signal.lombscargle(time, ibis, angular_frequencies, normalize=True)\n",
    "\n",
    "    # Convert angular frequencies to regular frequencies\n",
    "    frequencies = angular_frequencies / (2 * np.pi)\n",
    "\n",
    "    return frequencies, periodogram\n",
    "\n",
    "def plot_normalized_lomb_periodogram(time, ibis, frequency_range):\n",
    "    # Calculate the Lomb periodogram using the normalized_lomb_periodogram function\n",
    "    frequencies, periodogram = normalized_lomb_periodogram(time, ibis, frequency_range)\n",
    "\n",
    "    # Create a plot using matplotlib\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(frequencies, periodogram)\n",
    "\n",
    "    # Label the axes and add a title\n",
    "    plt.xlabel(\"Frequency (Hz)\")\n",
    "    plt.ylabel(\"Power\")\n",
    "    plt.title(\"Normalized Lomb Periodogram of Detrended IBIs\")\n",
    "\n",
    "    # Display the plot\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "true_time = np.cumsum(true_ibis)\n",
    "pred_time = np.cumsum(pred_ibis)\n",
    "\n",
    "plot_normalized_lomb_periodogram(true_time, true_ibis, (0.7, 4.0))\n",
    "plot_normalized_lomb_periodogram(pred_time, pred_ibis, (0.7, 4.0))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def pearson_correlation(x, y):\n",
    "    \"\"\"\n",
    "    Calculate the Pearson correlation coefficient between two 1D NumPy arrays.\n",
    "\n",
    "    Args:\n",
    "    x (numpy array): The first 1D NumPy array\n",
    "    y (numpy array): The second 1D NumPy array\n",
    "\n",
    "    Returns:\n",
    "    float: The Pearson correlation coefficient\n",
    "    \"\"\"\n",
    "\n",
    "    # Compute the correlation matrix using numpy.corrcoef\n",
    "    corr_matrix = np.corrcoef(x, y)\n",
    "\n",
    "    # Extract the correlation coefficient (off-diagonal element)\n",
    "    correlation_coefficient = corr_matrix[0, 1]\n",
    "\n",
    "    return correlation_coefficient\n",
    "\n",
    "# Example usage:\n",
    "# x = np.array([...])  # Your first 1D NumPy array\n",
    "# y = np.array([...])  # Your second 1D NumPy array\n",
    "# correlation = pearson_correlation(x, y)\n",
    "print(pred.shape)\n",
    "pearson_correlation(targ, pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
